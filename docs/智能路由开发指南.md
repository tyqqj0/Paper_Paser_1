# æ™ºèƒ½è·¯ç”±ç³»ç»Ÿå¼€å‘æŒ‡å—

## ğŸ¯ æ¦‚è¿°
æ™ºèƒ½è·¯ç”±ç³»ç»Ÿå¯ä»¥ä¸ºä¸åŒçš„æ–‡çŒ®æºæä¾›é’ˆå¯¹æ€§çš„å¿«é€Ÿå¤„ç†è·¯å¾„ã€‚æœ¬æ–‡æ¡£è¯´æ˜å¦‚ä½•ä¸ºæ–°çš„æ–‡çŒ®æºæ·»åŠ é€‚é…å™¨å’Œé…ç½®è·¯ç”±ã€‚

## ğŸ”§ æ·»åŠ æ–°æ–‡çŒ®æºçš„å®Œæ•´æµç¨‹

### 1ï¸âƒ£ ç¬¬ä¸€æ­¥ï¼šåˆ›å»ºURLé€‚é…å™¨ï¼ˆå¦‚éœ€è¦ï¼‰
**ä½ç½®**ï¼š`literature_parser_backend/services/url_mapping/adapters/`

```python
# ç¤ºä¾‹ï¼šä¸ºæ–°æœŸåˆŠ "Nature" åˆ›å»ºé€‚é…å™¨
class NatureAdapter(URLAdapter):
    def can_handle(self, url: str) -> bool:
        return 'nature.com' in url.lower()
    
    def extract_identifiers(self, url: str) -> URLMappingResult:
        # æå–DOIã€æ ‡é¢˜ã€ä½œè€…ç­‰ä¿¡æ¯
        return URLMappingResult(
            doi=extracted_doi,
            title=extracted_title,
            authors=extracted_authors,
            venue="Nature"
        )
```

### 2ï¸âƒ£ ç¬¬äºŒæ­¥ï¼šåˆ›å»ºå…ƒæ•°æ®å¤„ç†å™¨ï¼ˆå¦‚éœ€è¦ï¼‰
**ä½ç½®**ï¼š`literature_parser_backend/worker/metadata/processors/`

```python
# ç¤ºä¾‹ï¼šåˆ›å»ºNatureä¸“ç”¨å¤„ç†å™¨
class NatureProcessor(MetadataProcessor):
    @property
    def name(self) -> str:
        return "Nature Specialized"
    
    def can_handle(self, identifier_data: IdentifierData) -> bool:
        return identifier_data.venue == "Nature" and identifier_data.doi
    
    async def process(self, identifier_data: IdentifierData) -> MetadataResult:
        # ä½¿ç”¨Natureçš„APIæˆ–é¡µé¢è§£æè·å–å…ƒæ•°æ®
        pass
```

**ğŸ“ é‡è¦ï¼šå¤„ç†å™¨å¿…é¡»åœ¨ `__init__.py` ä¸­æ³¨å†Œï¼š**
```python
# literature_parser_backend/worker/metadata/processors/__init__.py
from .nature import NatureProcessor
registry.register(NatureProcessor)
```

### 3ï¸âƒ£ ç¬¬ä¸‰æ­¥ï¼šé…ç½®æ™ºèƒ½è·¯ç”±
**ä½ç½®**ï¼š`literature_parser_backend/worker/execution/routing.py`

```python
# åœ¨ _load_builtin_routes() æ–¹æ³•ä¸­æ·»åŠ æ–°è·¯ç”±
Route(
    name="nature_fast_path",
    patterns=["nature.com/articles", "nature.com/nature"],
    processors=["Nature Specialized", "CrossRef"],  # ä½¿ç”¨å‡†ç¡®çš„å¤„ç†å™¨åç§°
    priority=2  # æ•°å­—è¶Šå°ä¼˜å…ˆçº§è¶Šé«˜
)
```

### 4ï¸âƒ£ ç¬¬å››æ­¥ï¼šæ›´æ–°å¿«é€Ÿè·¯å¾„åˆ¤æ–­ï¼ˆå·²åºŸå¼ƒï¼Œç°åœ¨åªè¦æ³¨å†Œå³è‡ªåŠ¨åˆ¤æ–­ï¼‰
**ä½ç½®**ï¼š`literature_parser_backend/worker/tasks.py`

```python
# åœ¨ should_use_smart_routing() å‡½æ•°ä¸­æ·»åŠ æ–°æ¨¡å¼
fast_patterns = [
    'arxiv.org/abs',
    'proceedings.neurips.cc',
    'nature.com/articles',  # æ–°å¢
    # ...
]
```

## ğŸ® ä¸åŒåœºæ™¯çš„é…ç½®ç­–ç•¥

### ğŸ“° é«˜ç½®ä¿¡åº¦æºï¼ˆå¦‚ArXivï¼‰
```python
Route(
    name="arxiv_fast_path",
    patterns=["arxiv.org/abs", "arxiv.org/pdf"],
    processors=["Semantic Scholar"],  # å•ä¸ªé«˜æ•ˆå¤„ç†å™¨
    priority=1  # æœ€é«˜ä¼˜å…ˆçº§
)
```

### ğŸ›ï¸ éœ€è¦å¢å¼ºå¤„ç†çš„æºï¼ˆå¦‚ä¼šè®®ç½‘ç«™ï¼‰
```python
Route(
    name="neurips_enhanced_path", 
    patterns=["proceedings.neurips.cc"],
    processors=["CrossRef"],  # ä½¿ç”¨ç²¾ç¡®æœç´¢
    priority=2
)
```

### ğŸŒ é€šç”¨å›é€€è·¯å¾„
```python
Route(
    name="standard_waterfall",
    patterns=["*"],  # åŒ¹é…æ‰€æœ‰å…¶ä»–URL
    processors=["Semantic Scholar", "CrossRef", "Site Parser V2"],  # å¤šå¤„ç†å™¨å¹¶è¡Œ
    priority=10  # æœ€ä½ä¼˜å…ˆçº§
)
```

## ğŸš€ è·¯ç”±ç³»ç»Ÿå·¥ä½œåŸç†

### æ‰§è¡Œæµç¨‹
1. **URLæ˜ å°„** â†’ æå–åŸºç¡€æ ‡è¯†ç¬¦ï¼ˆDOIã€æ ‡é¢˜ç­‰ï¼‰
2. **è·¯ç”±å†³ç­–** â†’ æ ¹æ®URLæ¨¡å¼é€‰æ‹©æœ€ä¼˜è·¯ç”±
3. **æ™ºèƒ½æ‰§è¡Œ** â†’ å¹¶è¡Œæˆ–åºåˆ—æ‰§è¡Œå¤„ç†å™¨
4. **Hookå¤„ç†** â†’ è‡ªåŠ¨å»é‡ã€åˆ«ååˆ›å»ºã€è´¨é‡è¯„ä¼°
5. **ç»“æœè¿”å›** â†’ æˆ–å›é€€åˆ°ä¼ ç»Ÿç€‘å¸ƒæµ

### è·¯ç”±ä¼˜å…ˆçº§
- `priority=1` â†’ æœ€é«˜ä¼˜å…ˆçº§ï¼ˆå¿«é€Ÿè·¯å¾„ï¼‰
- `priority=2-5` â†’ ä¸­ç­‰ä¼˜å…ˆçº§ï¼ˆå¢å¼ºè·¯å¾„ï¼‰  
- `priority=10` â†’ æœ€ä½ä¼˜å…ˆçº§ï¼ˆé€šç”¨å›é€€ï¼‰

## ğŸ¯ å¤„ç†å™¨é€‰æ‹©é€»è¾‘

### å¿«é€Ÿè·¯å¾„ (`*_fast_path`)
- åªæ‰§è¡Œç¬¬ä¸€ä¸ªå¯ç”¨å¤„ç†å™¨
- é€‚åˆé«˜ç½®ä¿¡åº¦æºï¼ˆArXivã€DOIç›´é“¾ï¼‰
- è¿½æ±‚æè‡´é€Ÿåº¦

### æ ‡å‡†è·¯å¾„ (`*_waterfall`) 
- å¹¶è¡Œæ‰§è¡Œå¤šä¸ªå¤„ç†å™¨
- é€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„ç»“æœ
- ä¿è¯æˆåŠŸç‡

## ğŸ” è°ƒè¯•å’ŒéªŒè¯

### æŸ¥çœ‹è·¯ç”±å†³ç­–æ—¥å¿—
```bash
sudo docker compose logs worker | grep "URLè·¯ç”±å†³ç­–"
```

### æµ‹è¯•æ–°é€‚é…å™¨
```python
# åœ¨æµ‹è¯•æ–‡ä»¶ä¸­éªŒè¯
python3 test_various_links.py
```

### æ£€æŸ¥å¤„ç†å™¨æ³¨å†Œ
```python
# æŸ¥çœ‹å·²æ³¨å†Œçš„å¤„ç†å™¨
from literature_parser_backend.worker.metadata.registry import get_global_registry
registry = get_global_registry()
print(registry.get_available_processors())
```

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **å¤„ç†å™¨åç§°å¿…é¡»ç²¾ç¡®åŒ¹é…**ï¼šè·¯ç”±é…ç½®ä¸­çš„å¤„ç†å™¨åç§°å¿…é¡»ä¸å¤„ç†å™¨ç±»çš„ `name` å±æ€§å®Œå…¨ä¸€è‡´

2. **ä¼˜å…ˆçº§è®¾è®¡**ï¼šæ•°å­—è¶Šå°ä¼˜å…ˆçº§è¶Šé«˜ï¼Œé¿å…å†²çª

3. **URLæ¨¡å¼åŒ¹é…**ï¼šä½¿ç”¨å­å­—ç¬¦ä¸²åŒ¹é…ï¼Œç¡®ä¿æ¨¡å¼è¶³å¤Ÿå…·ä½“

4. **Hookç³»ç»Ÿè‡ªåŠ¨è§¦å‘**ï¼šæ— éœ€æ‰‹åŠ¨é…ç½®ï¼Œä¼šè‡ªåŠ¨å¤„ç†å»é‡å’Œåˆ«å

5. **å›é€€æœºåˆ¶**ï¼šæ™ºèƒ½è·¯ç”±å¤±è´¥æ—¶ä¼šè‡ªåŠ¨å›é€€åˆ°ä¼ ç»Ÿç€‘å¸ƒæµ

## ğŸ“‹ å¿«é€Ÿæ£€æŸ¥æ¸…å•

- [ ] URLé€‚é…å™¨èƒ½æ­£ç¡®æå–æ ‡è¯†ç¬¦
- [ ] å…ƒæ•°æ®å¤„ç†å™¨å·²æ³¨å†Œä¸” `can_handle()` é€»è¾‘æ­£ç¡®
- [ ] è·¯ç”±é…ç½®ä¸­çš„å¤„ç†å™¨åç§°ç²¾ç¡®åŒ¹é…
- [ ] è·¯ç”±ä¼˜å…ˆçº§è®¾ç½®åˆç†
- [ ] æµ‹è¯•éªŒè¯åŠŸèƒ½æ­£å¸¸

---

**ğŸ‰ æ·»åŠ æ–°æ–‡çŒ®æºå°±æ˜¯è¿™ä¹ˆç®€å•ï¼å¤§å¤šæ•°æƒ…å†µä¸‹åªéœ€è¦ä¿®æ”¹è·¯ç”±é…ç½®å³å¯å¤ç”¨ç°æœ‰å¤„ç†å™¨ã€‚**

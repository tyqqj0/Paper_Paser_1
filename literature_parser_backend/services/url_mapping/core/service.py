"""
URLæ˜ å°„æœåŠ¡

æä¾›URLåˆ°æ ‡è¯†ç¬¦æ˜ å°„çš„ä¸»è¦æœåŠ¡ç±»ã€‚
"""

import asyncio
import logging
import requests
from typing import List, Optional, Dict, Any

from .base import URLAdapter
from .result import URLMappingResult

logger = logging.getLogger(__name__)


class URLMappingService:
    """URLæ˜ å°„æœåŠ¡ä¸»ç±»"""

    def __init__(self, adapters: Optional[List[URLAdapter]] = None, enable_url_validation: bool = False):
        """
        åˆå§‹åŒ–URLæ˜ å°„æœåŠ¡

        Args:
            adapters: é€‚é…å™¨åˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤é€‚é…å™¨
            enable_url_validation: æ˜¯å¦å¯ç”¨URLæœ‰æ•ˆæ€§éªŒè¯
        """
        self.adapters = adapters or []
        self.enable_url_validation = enable_url_validation
        if not self.adapters:
            self._register_default_adapters()

    def _register_default_adapters(self):
        """æ³¨å†Œé»˜è®¤é€‚é…å™¨"""
        try:
            # å¯¼å…¥é€‚é…å™¨åˆ›å»ºå‡½æ•°
            from ..adapters import create_all_adapters

            self.adapters = create_all_adapters()

            logger.info(f"æ³¨å†Œäº† {len(self.adapters)} ä¸ªé»˜è®¤é€‚é…å™¨: {[a.name for a in self.adapters]}")
        except Exception as e:
            logger.error(f"æ³¨å†Œé»˜è®¤é€‚é…å™¨å¤±è´¥: {e}")
            # ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆï¼Œè‡³å°‘æ³¨å†ŒIEEEé€‚é…å™¨
            try:
                from ..adapters.ieee import IEEEAdapter
                self.adapters = [IEEEAdapter()]
                logger.warning("ä½¿ç”¨å¤‡é€‰æ–¹æ¡ˆï¼Œåªæ³¨å†Œäº†IEEEé€‚é…å™¨")
            except Exception as fallback_error:
                logger.error(f"å¤‡é€‰æ–¹æ¡ˆä¹Ÿå¤±è´¥: {fallback_error}")
                self.adapters = []

    def _validate_url(self, url: str, timeout: int = 10) -> bool:
        """
        éªŒè¯URLæ˜¯å¦å¯è®¿é—®

        Args:
            url: è¦éªŒè¯çš„URL
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

        Returns:
            URLæ˜¯å¦å¯è®¿é—®
        """
        try:
            logger.debug(f"éªŒè¯URLå¯è®¿é—®æ€§: {url}")

            # è®¾ç½®è¯·æ±‚å¤´ï¼Œæ¨¡æ‹Ÿæµè§ˆå™¨è®¿é—®
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                'Accept-Language': 'en-US,en;q=0.5',
                'Accept-Encoding': 'gzip, deflate',
                'Connection': 'keep-alive',
            }

            # å‘é€HEADè¯·æ±‚ï¼ˆæ›´å¿«ï¼Œåªè·å–å“åº”å¤´ï¼‰
            response = requests.head(url, headers=headers, timeout=timeout, allow_redirects=True)

            # æ£€æŸ¥çŠ¶æ€ç 
            if response.status_code == 200:
                logger.debug(f"âœ… URLéªŒè¯æˆåŠŸ: {url}")
                return True
            elif response.status_code == 405:  # Method Not Allowedï¼Œå°è¯•GETè¯·æ±‚
                logger.debug(f"HEADè¯·æ±‚è¢«æ‹’ç»ï¼Œå°è¯•GETè¯·æ±‚: {url}")
                response = requests.get(url, headers=headers, timeout=timeout, allow_redirects=True)
                if response.status_code == 200:
                    logger.debug(f"âœ… URLéªŒè¯æˆåŠŸ(GET): {url}")
                    return True

            logger.warning(f"âŒ URLéªŒè¯å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}, URL: {url}")
            return False

        except requests.exceptions.Timeout:
            logger.warning(f"âŒ URLéªŒè¯è¶…æ—¶: {url}")
            return False
        except requests.exceptions.ConnectionError:
            logger.warning(f"âŒ URLè¿æ¥å¤±è´¥: {url}")
            return False
        except requests.exceptions.RequestException as e:
            logger.warning(f"âŒ URLéªŒè¯è¯·æ±‚å¼‚å¸¸: {e}, URL: {url}")
            return False
        except Exception as e:
            logger.error(f"âŒ URLéªŒè¯æœªçŸ¥é”™è¯¯: {e}, URL: {url}")
            return False

    def _check_pdf_redirect(self, url: str) -> Optional[Dict[str, Any]]:
        """
        æ£€æŸ¥PDFé‡å®šå‘

        Args:
            url: è¦æ£€æŸ¥çš„URL

        Returns:
            é‡å®šå‘ä¿¡æ¯å­—å…¸ï¼Œå¦‚æœä¸éœ€è¦é‡å®šå‘åˆ™è¿”å›None
        """
        try:
            from .pdf_redirector import get_pdf_redirector
            redirector = get_pdf_redirector()
            return redirector.check_redirect(url)
        except Exception as e:
            logger.warning(f"PDFé‡å®šå‘æ£€æŸ¥å¤±è´¥: {e}")
            return None

    async def map_url(self, url: str, enable_validation: bool = False, strict_validation: bool = False, skip_url_validation: bool = False) -> URLMappingResult:
        """
        å°†URLæ˜ å°„ä¸ºæ ‡è¯†ç¬¦å’Œç›¸å…³ä¿¡æ¯ï¼ˆå¼‚æ­¥ç‰ˆæœ¬ï¼‰

        Args:
            url: è¦è§£æçš„URL
            enable_validation: æ˜¯å¦å¯ç”¨æ ‡è¯†ç¬¦éªŒè¯
            strict_validation: æ˜¯å¦ä½¿ç”¨ä¸¥æ ¼éªŒè¯æ¨¡å¼
            skip_url_validation: æ˜¯å¦è·³è¿‡URLæœ‰æ•ˆæ€§éªŒè¯

        Returns:
            URLMappingResult: æ˜ å°„ç»“æœ
        """
        logger.debug(f"å¼€å§‹æ˜ å°„URL: {url}")
        original_url = url

        # 1. æå‰åˆ†ç¦»ä¸“é—¨é€‚é…å™¨å’Œé€šç”¨é€‚é…å™¨ï¼ˆä¿®å¤å˜é‡æœªå®šä¹‰bugï¼‰
        specialized_adapters = [a for a in self.adapters if a.name != "generic"]
        generic_adapters = [a for a in self.adapters if a.name == "generic"]

        # 2. PDFæ™ºèƒ½é‡å®šå‘æ£€æŸ¥
        redirect_info = self._check_pdf_redirect(url)
        if redirect_info:
            logger.info(f"ğŸ”„ PDFé‡å®šå‘: {url} â†’ {redirect_info['canonical_url']}")
            logger.info(f"ğŸ“ é‡å®šå‘åŸå› : {redirect_info['redirect_reason']}")
            url = redirect_info['canonical_url']  # ä½¿ç”¨é‡å®šå‘åçš„URLç»§ç»­å¤„ç†

        # 3. URLæœ‰æ•ˆæ€§éªŒè¯
        # å¯¹äºæŸäº›é€‚é…å™¨ï¼ˆå¦‚ACMï¼‰ï¼Œæˆ‘ä»¬å¯èƒ½å¸Œæœ›ç›´æ¥ä»URLæå–æ ‡è¯†ç¬¦ï¼Œè€Œä¸æ˜¯è¿›è¡ŒHTTPéªŒè¯
        # æ£€æŸ¥é€‚é…å™¨æ˜¯å¦æœ‰ä¼˜å…ˆçš„ extract_identifier_from_url æ–¹æ³•
        for adapter in specialized_adapters + generic_adapters:
            if adapter.can_handle(url) and hasattr(adapter, 'extract_identifier_from_url'):
                logger.debug(f"å°è¯•ä½¿ç”¨é€‚é…å™¨ {adapter.name} çš„ extract_identifier_from_url æ–¹æ³•")
                direct_extraction_result = await adapter.extract_identifier_from_url(url)
                if direct_extraction_result and direct_extraction_result.is_successful():
                    logger.info(f"âœ… æˆåŠŸé€šè¿‡ {adapter.name} ç›´æ¥ä»URLæå–æ ‡è¯†ç¬¦")
                    if redirect_info:
                        direct_extraction_result.original_url = original_url
                        direct_extraction_result.canonical_url = redirect_info['canonical_url']
                        direct_extraction_result.redirect_reason = redirect_info['redirect_reason']
                    return direct_extraction_result
                else:
                    logger.debug(f"é€‚é…å™¨ {adapter.name} æœªèƒ½ç›´æ¥ä»URLæå–æ ‡è¯†ç¬¦æˆ–æå–å¤±è´¥")

        if self.enable_url_validation and not skip_url_validation:
            logger.info(f"ğŸ” éªŒè¯URLæœ‰æ•ˆæ€§: {url}")
            if not self._validate_url(url):
                logger.warning(f"âŒ URLéªŒè¯å¤±è´¥ï¼Œè¿”å›ç©ºç»“æœ: {url}")
                result = URLMappingResult()
                result.metadata['url_validation_failed'] = True
                result.metadata['error'] = f"URL {url} æ— æ³•è®¿é—®æˆ–ä¸å­˜åœ¨"
                # å¦‚æœæœ‰é‡å®šå‘ä¿¡æ¯ï¼Œä¹Ÿè¦è®°å½•
                if redirect_info:
                    result.original_url = original_url
                    result.canonical_url = redirect_info['canonical_url']
                    result.redirect_reason = redirect_info['redirect_reason']
                return result
            else:
                logger.info(f"âœ… URLéªŒè¯é€šè¿‡: {url}")

        # 4. é¦–å…ˆå°è¯•ä¸“é—¨é€‚é…å™¨
        for adapter in specialized_adapters:
            if adapter.can_handle(url):
                logger.debug(f"ä½¿ç”¨ä¸“é—¨é€‚é…å™¨ {adapter.name} å¤„ç†URL")
                try:
                    result = await adapter.extract_identifiers(url, enable_validation, strict_validation)

                    if result and result.is_successful():
                        # å¦‚æœæœ‰é‡å®šå‘ä¿¡æ¯ï¼Œæ·»åŠ åˆ°ç»“æœä¸­
                        if redirect_info:
                            result.original_url = original_url
                            result.canonical_url = redirect_info['canonical_url']
                            result.redirect_reason = redirect_info['redirect_reason']

                        logger.info(f"æˆåŠŸæ˜ å°„URL: {url} -> DOI:{result.doi}, ArXiv:{result.arxiv_id}, Venue:{result.venue}, ç­–ç•¥:{result.strategy_used}")
                        if redirect_info:
                            logger.info(f"ğŸ”„ åŒ…å«é‡å®šå‘ä¿¡æ¯: {original_url} â†’ {redirect_info['canonical_url']}")
                        return result
                    else:
                        logger.debug(f"é€‚é…å™¨ {adapter.name} æœªæ‰¾åˆ°æœ‰æ•ˆæ ‡è¯†ç¬¦æˆ–æœ‰ç”¨ä¿¡æ¯")
                except Exception as e:
                    # å¯¼å…¥è‡ªå®šä¹‰å¼‚å¸¸ç±»å‹
                    try:
                        from ....worker.execution.exceptions import URLNotFoundException, URLAccessFailedException, ParsingFailedException
                        # å¦‚æœæ˜¯ç‰¹å®šçš„é”™è¯¯ç±»å‹ï¼Œåº”è¯¥å‘ä¸Šä¼ é€’è€Œä¸æ˜¯ç»§ç»­å°è¯•å…¶ä»–é€‚é…å™¨
                        if isinstance(e, (URLNotFoundException, URLAccessFailedException, ParsingFailedException)):
                            logger.error(f"é€‚é…å™¨ {adapter.name} é‡åˆ°ç‰¹å®šé”™è¯¯ï¼Œå‘ä¸Šä¼ é€’: {e}")
                            raise e
                    except ImportError:
                        # å¦‚æœæ— æ³•å¯¼å…¥å¼‚å¸¸ç±»å‹ï¼Œç»§ç»­åŸæœ‰é€»è¾‘
                        pass
                    
                    logger.warning(f"é€‚é…å™¨ {adapter.name} å¤„ç†URLå¤±è´¥: {e}")
                    continue

        # 5. å¦‚æœä¸“é—¨é€‚é…å™¨éƒ½å¤±è´¥ï¼Œå°è¯•é€šç”¨é€‚é…å™¨ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ
        if generic_adapters:
            logger.debug(f"ä¸“é—¨é€‚é…å™¨éƒ½å¤±è´¥ï¼Œå°è¯•é€šç”¨å¤‡é€‰æ–¹æ¡ˆ")
            for adapter in generic_adapters:
                logger.debug(f"ä½¿ç”¨é€šç”¨é€‚é…å™¨ {adapter.name} å¤„ç†URL")
                try:
                    result = await adapter.extract_identifiers(url, enable_validation, strict_validation)

                    if result and result.is_successful():
                        # å¦‚æœæœ‰é‡å®šå‘ä¿¡æ¯ï¼Œæ·»åŠ åˆ°ç»“æœä¸­
                        if redirect_info:
                            result.original_url = original_url
                            result.canonical_url = redirect_info['canonical_url']
                            result.redirect_reason = redirect_info['redirect_reason']

                        logger.info(f"é€šç”¨é€‚é…å™¨æˆåŠŸæ˜ å°„URL: {url} -> DOI:{result.doi}, ArXiv:{result.arxiv_id}, Venue:{result.venue}, ç­–ç•¥:{result.strategy_used}")
                        if redirect_info:
                            logger.info(f"ğŸ”„ åŒ…å«é‡å®šå‘ä¿¡æ¯: {original_url} â†’ {redirect_info['canonical_url']}")
                        return result
                    else:
                        logger.debug(f"é€šç”¨é€‚é…å™¨ {adapter.name} æœªæ‰¾åˆ°æœ‰æ•ˆæ ‡è¯†ç¬¦æˆ–æœ‰ç”¨ä¿¡æ¯")
                except Exception as e:
                    # å¯¼å…¥è‡ªå®šä¹‰å¼‚å¸¸ç±»å‹
                    try:
                        from ....worker.execution.exceptions import URLNotFoundException, URLAccessFailedException, ParsingFailedException
                        # å¦‚æœæ˜¯ç‰¹å®šçš„é”™è¯¯ç±»å‹ï¼Œåº”è¯¥å‘ä¸Šä¼ é€’è€Œä¸æ˜¯ç»§ç»­å°è¯•å…¶ä»–é€‚é…å™¨
                        if isinstance(e, (URLNotFoundException, URLAccessFailedException, ParsingFailedException)):
                            logger.error(f"é€šç”¨é€‚é…å™¨ {adapter.name} é‡åˆ°ç‰¹å®šé”™è¯¯ï¼Œå‘ä¸Šä¼ é€’: {e}")
                            raise e
                    except ImportError:
                        # å¦‚æœæ— æ³•å¯¼å…¥å¼‚å¸¸ç±»å‹ï¼Œç»§ç»­åŸæœ‰é€»è¾‘
                        pass
                    
                    logger.warning(f"é€šç”¨é€‚é…å™¨ {adapter.name} å¤„ç†URLå¤±è´¥: {e}")
                    continue

        # 6. å¦‚æœæ‰€æœ‰é€‚é…å™¨éƒ½å¤±è´¥ï¼Œè¿”å›ç©ºç»“æœï¼ˆä½†ä¿ç•™é‡å®šå‘ä¿¡æ¯ï¼‰
        logger.debug(f"æ‰€æœ‰é€‚é…å™¨éƒ½æ— æ³•å¤„ç†URL: {url}")
        result = URLMappingResult()
        if redirect_info:
            result.original_url = original_url
            result.canonical_url = redirect_info['canonical_url']
            result.redirect_reason = redirect_info['redirect_reason']
            logger.debug(f"è¿”å›ç©ºç»“æœä½†ä¿ç•™é‡å®šå‘ä¿¡æ¯: {original_url} â†’ {redirect_info['canonical_url']}")
        return result

    def map_url_sync(self, url: str) -> URLMappingResult:
        """
        å°†URLæ˜ å°„ä¸ºæ ‡è¯†ç¬¦å’Œç›¸å…³ä¿¡æ¯ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰

        Args:
            url: è¦è§£æçš„URL

        Returns:
            URLMappingResult: æ˜ å°„ç»“æœ
        """
        try:
            # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰è¿è¡Œä¸­çš„äº‹ä»¶å¾ªç¯
            try:
                loop = asyncio.get_running_loop()
                # å¦‚æœæœ‰è¿è¡Œä¸­çš„äº‹ä»¶å¾ªç¯ï¼Œä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œ
                import concurrent.futures
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(self._run_async_in_new_loop, url)
                    return future.result()
            except RuntimeError:
                # æ²¡æœ‰è¿è¡Œä¸­çš„äº‹ä»¶å¾ªç¯ï¼Œå¯ä»¥å®‰å…¨ä½¿ç”¨run_until_complete
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                try:
                    return loop.run_until_complete(self.map_url(url))
                finally:
                    loop.close()
        except Exception as e:
            logger.error(f"åŒæ­¥URLæ˜ å°„å¤±è´¥: {e}")
            return URLMappingResult()

    def _run_async_in_new_loop(self, url: str) -> URLMappingResult:
        """åœ¨æ–°çš„äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œå¼‚æ­¥æ–¹æ³•"""
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            return loop.run_until_complete(self.map_url(url))
        finally:
            loop.close()

    def map_url_with_validation(self, url: str, strict: bool = False) -> URLMappingResult:
        """
        å¸¦éªŒè¯çš„URLæ˜ å°„ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰

        Args:
            url: è¦è§£æçš„URL
            strict: æ˜¯å¦ä½¿ç”¨ä¸¥æ ¼éªŒè¯æ¨¡å¼ï¼ˆéªŒè¯å¤±è´¥æ—¶ä¸è¿”å›ç»“æœï¼‰

        Returns:
            URLMappingResult: æ˜ å°„ç»“æœ
        """
        try:
            loop = asyncio.get_event_loop()
        except RuntimeError:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)

        try:
            return loop.run_until_complete(self.map_url(url, enable_validation=True, strict_validation=strict))
        except Exception as e:
            logger.error(f"å¸¦éªŒè¯çš„URLæ˜ å°„å¤±è´¥: {e}")
            return URLMappingResult()

    def map_url_with_url_validation(self, url: str) -> URLMappingResult:
        """
        å¸¦URLæœ‰æ•ˆæ€§éªŒè¯çš„æ˜ å°„ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰

        Args:
            url: è¦è§£æçš„URL

        Returns:
            URLMappingResult: æ˜ å°„ç»“æœ
        """
        # ä¸´æ—¶å¯ç”¨URLéªŒè¯
        original_validation = self.enable_url_validation
        self.enable_url_validation = True

        try:
            result = self.map_url_sync(url)
            return result
        finally:
            # æ¢å¤åŸå§‹è®¾ç½®
            self.enable_url_validation = original_validation

    def validate_url_only(self, url: str) -> bool:
        """
        ä»…éªŒè¯URLæ˜¯å¦å¯è®¿é—®ï¼ˆä¸è¿›è¡Œæ˜ å°„ï¼‰

        Args:
            url: è¦éªŒè¯çš„URL

        Returns:
            URLæ˜¯å¦å¯è®¿é—®
        """
        return self._validate_url(url)

    def add_adapter(self, adapter: URLAdapter):
        """
        æ·»åŠ æ–°çš„é€‚é…å™¨
        
        Args:
            adapter: è¦æ·»åŠ çš„é€‚é…å™¨
        """
        self.adapters.append(adapter)
        logger.info(f"æ·»åŠ é€‚é…å™¨: {adapter.name}")

    def remove_adapter(self, adapter_name: str):
        """
        ç§»é™¤é€‚é…å™¨
        
        Args:
            adapter_name: è¦ç§»é™¤çš„é€‚é…å™¨åç§°
        """
        self.adapters = [a for a in self.adapters if a.name != adapter_name]
        logger.info(f"ç§»é™¤é€‚é…å™¨: {adapter_name}")

    def get_supported_domains(self) -> dict:
        """
        è·å–æ‰€æœ‰æ”¯æŒçš„åŸŸå
        
        Returns:
            é€‚é…å™¨åç§°åˆ°æ”¯æŒåŸŸååˆ—è¡¨çš„æ˜ å°„
        """
        domains = {}
        for adapter in self.adapters:
            domains[adapter.name] = adapter.supported_domains
        return domains

    def get_adapter_by_name(self, name: str) -> Optional[URLAdapter]:
        """
        æ ¹æ®åç§°è·å–é€‚é…å™¨
        
        Args:
            name: é€‚é…å™¨åç§°
            
        Returns:
            æ‰¾åˆ°çš„é€‚é…å™¨ï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆ™è¿”å›None
        """
        for adapter in self.adapters:
            if adapter.name == name:
                return adapter
        return None

    def get_adapters_for_url(self, url: str) -> List[URLAdapter]:
        """
        è·å–èƒ½å¤„ç†æŒ‡å®šURLçš„æ‰€æœ‰é€‚é…å™¨
        
        Args:
            url: è¦æ£€æŸ¥çš„URL
            
        Returns:
            èƒ½å¤„ç†è¯¥URLçš„é€‚é…å™¨åˆ—è¡¨
        """
        return [adapter for adapter in self.adapters if adapter.can_handle(url)]

    def health_check(self) -> dict:
        """
        å¥åº·æ£€æŸ¥
        
        Returns:
            æœåŠ¡çŠ¶æ€ä¿¡æ¯
        """
        return {
            "service": "URLMappingService",
            "status": "healthy",
            "adapters_count": len(self.adapters),
            "adapters": [
                {
                    "name": adapter.name,
                    "supported_domains": adapter.supported_domains,
                    "strategies_count": len(adapter.strategies),
                }
                for adapter in self.adapters
            ]
        }


# å…¨å±€æœåŠ¡å®ä¾‹
_url_mapping_service = None


def get_url_mapping_service(enable_url_validation: bool = False) -> URLMappingService:
    """
    è·å–URLæ˜ å°„æœåŠ¡çš„å•ä¾‹å®ä¾‹

    Args:
        enable_url_validation: æ˜¯å¦å¯ç”¨URLéªŒè¯ï¼ˆé»˜è®¤å¯ç”¨ï¼‰

    Returns:
        URLMappingServiceå®ä¾‹
    """
    global _url_mapping_service
    if _url_mapping_service is None:
        _url_mapping_service = URLMappingService(enable_url_validation=enable_url_validation)
        logger.info(f"åˆ›å»ºURLæ˜ å°„æœåŠ¡å•ä¾‹å®ä¾‹ï¼ŒURLéªŒè¯: {'å¯ç”¨' if enable_url_validation else 'ç¦ç”¨'}")
    return _url_mapping_service


def reset_url_mapping_service():
    """é‡ç½®URLæ˜ å°„æœåŠ¡å•ä¾‹ï¼ˆä¸»è¦ç”¨äºæµ‹è¯•ï¼‰"""
    global _url_mapping_service
    _url_mapping_service = None
    logger.info("é‡ç½®URLæ˜ å°„æœåŠ¡å•ä¾‹")

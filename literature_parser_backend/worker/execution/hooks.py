"""
Hookç³»ç»Ÿ - è‡ªåŠ¨åŒ–æ•°æ®å¤„ç†é’©å­

å®ç°äº‹ä»¶é©±åŠ¨çš„è‡ªåŠ¨æŸ¥é‡ã€åˆ«ååˆ›å»ºã€è´¨é‡è¯„ä¼°ç­‰åå¤„ç†é€»è¾‘ã€‚
"""

import asyncio
import logging
from typing import Dict, List, Any, Optional, Set
from datetime import datetime
from abc import ABC, abstractmethod

from ...models.literature import MetadataModel
from ...db.dao import LiteratureDAO

logger = logging.getLogger(__name__)


class Hook(ABC):
    """HookåŸºç±» - æ‰€æœ‰Hookéƒ½ç»§æ‰¿æ­¤ç±»"""
    
    def __init__(self):
        self.hook_manager = None
    
    def set_hook_manager(self, hook_manager):
        """è®¾ç½®HookManagerå¼•ç”¨ï¼Œç”¨äºè§¦å‘çº§è”äº‹ä»¶"""
        self.hook_manager = hook_manager
    
    @property
    @abstractmethod
    def name(self) -> str:
        """Hookåç§°"""
        pass
    
    @property
    @abstractmethod
    def triggers(self) -> List[str]:
        """è§¦å‘äº‹ä»¶åˆ—è¡¨"""
        pass
    
    @abstractmethod
    async def execute(self, event: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡ŒHooké€»è¾‘"""
        pass


class DeduplicationHook(Hook):
    """è‡ªåŠ¨æŸ¥é‡Hook - å½“æ–°å…ƒæ•°æ®å¯ç”¨æ—¶è‡ªåŠ¨æ£€æŸ¥é‡å¤"""
    
    @property
    def name(self) -> str:
        return "auto_deduplication"
    
    @property
    def triggers(self) -> List[str]:
        return ["metadata_updated", "literature_created"]
    
    def __init__(self, dao: LiteratureDAO):
        super().__init__()
        self.dao = dao
    
    async def execute(self, event: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œè‡ªåŠ¨æŸ¥é‡"""
        try:
            literature_id = context.get('literature_id')
            metadata = context.get('metadata')
            
            if not literature_id or not metadata:
                return {'status': 'skipped', 'reason': 'insufficient_data'}
            
            logger.info(f"ğŸ” [Hook] è‡ªåŠ¨æŸ¥é‡å¼€å§‹: {literature_id}")
            
            # æ‰§è¡ŒæŸ¥é‡é€»è¾‘
            duplicates = await self._find_duplicates(metadata, literature_id)
            
            if duplicates:
                # å‘ç°é‡å¤ï¼Œåˆå¹¶å¤„ç†
                merged_result = await self._handle_duplicates(literature_id, duplicates, context)
                logger.info(f"âœ… [Hook] æŸ¥é‡å®Œæˆï¼Œå‘ç° {len(duplicates)} ä¸ªé‡å¤é¡¹")
                return {
                    'status': 'completed',
                    'action': 'merged',
                    'duplicates_found': len(duplicates),
                    'result': merged_result
                }
            else:
                logger.info(f"âœ… [Hook] æŸ¥é‡å®Œæˆï¼Œæœªå‘ç°é‡å¤é¡¹")
                return {'status': 'completed', 'action': 'none', 'duplicates_found': 0}
                
        except Exception as e:
            logger.error(f"âŒ [Hook] è‡ªåŠ¨æŸ¥é‡å¤±è´¥: {e}")
            return {'status': 'failed', 'error': str(e)}
    
    async def _find_duplicates(self, metadata: MetadataModel, current_id: str) -> List[str]:
        """æŸ¥æ‰¾é‡å¤é¡¹"""
        duplicates = []
        
        # åŸºäºDOIæŸ¥é‡
        if hasattr(metadata, 'identifiers') and metadata.identifiers and hasattr(metadata.identifiers, 'doi') and metadata.identifiers.doi:
            doi_matches = await self.dao.find_by_doi(metadata.identifiers.doi)
            duplicates.extend([lit.lid for lit in doi_matches if lit.lid != current_id])
        
        # åŸºäºæ ‡é¢˜+ä½œè€…æŸ¥é‡ (ç®€åŒ–ç‰ˆ)
        if metadata.title and metadata.authors:
            title_matches = await self.dao.find_by_title_fuzzy(metadata.title, threshold=0.9)
            for match in title_matches:
                if match.lid != current_id and match.lid not in duplicates:
                    # ç®€å•çš„ä½œè€…åŒ¹é…æ£€æŸ¥
                    if self._authors_match(metadata.authors, match.authors):
                        duplicates.append(match.lid)
        
        return duplicates
    
    def _authors_match(self, authors1: List[Dict], authors2: List[Dict], threshold: float = 0.7) -> bool:
        """ç®€å•çš„ä½œè€…åŒ¹é…ç®—æ³•"""
        if not authors1 or not authors2:
            return False
        
        # æå–ä½œè€…å§“å
        names1 = {author.get('name', '') for author in authors1}
        names2 = {author.get('name', '') for author in authors2}
        
        # è®¡ç®—äº¤é›†æ¯”ä¾‹
        intersection = len(names1 & names2)
        union = len(names1 | names2)
        
        if union == 0:
            return False
            
        similarity = intersection / union
        return similarity >= threshold
    
    async def _handle_duplicates(self, literature_id: str, duplicates: List[str], context: Dict[str, Any]) -> Dict:
        """å¤„ç†å‘ç°çš„é‡å¤é¡¹"""
        # ç®€åŒ–å¤„ç†ï¼šé€‰æ‹©ç¬¬ä¸€ä¸ªé‡å¤é¡¹ä½œä¸ºä¸»é¡¹ï¼Œåˆ é™¤å½“å‰é¡¹
        if duplicates:
            primary_id = duplicates[0]
            
            # å°†åˆ«åæ·»åŠ åˆ°ä¸»é¡¹
            # è¿™é‡Œåº”è¯¥è°ƒç”¨DAOçš„æ–¹æ³•æ¥å¤„ç†åˆ«ååˆå¹¶
            logger.info(f"ğŸ“‹ [Hook] å°† {literature_id} åˆå¹¶åˆ° {primary_id}")
            
            return {
                'primary_id': primary_id,
                'merged_ids': [literature_id],
                'action': 'merged_to_existing'
            }
        
        return {}


class AliasCreationHook(Hook):
    """åˆ«ååˆ›å»ºHook - è‡ªåŠ¨ä¸ºæ–°æ–‡çŒ®åˆ›å»ºå„ç§åˆ«å"""
    
    @property
    def name(self) -> str:
        return "auto_alias_creation"
    
    @property
    def triggers(self) -> List[str]:
        return ["literature_created", "metadata_updated"]
    
    def __init__(self, dao: LiteratureDAO):
        super().__init__()
        self.dao = dao
    
    async def execute(self, event: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œåˆ«ååˆ›å»º - å®ç°å®Œæ•´çš„åˆ«åæ˜ å°„é€»è¾‘"""
        try:
            literature_id = context.get('literature_id')
            
            if not literature_id:
                return {'status': 'skipped', 'reason': 'Missing literature_id'}
            
            logger.info(f"ğŸ·ï¸ [Hook] å¼€å§‹åˆ›å»ºåˆ«å: {literature_id}")
            
            # è·å–å½“å‰æ–‡çŒ®
            literature = await self.dao.find_by_lid(literature_id)
            if not literature:
                return {'status': 'skipped', 'reason': 'Literature not found'}
            
            # ğŸ¯ ä½¿ç”¨å®Œæ•´çš„åˆ«åæ˜ å°„é€»è¾‘
            try:
                from ...db.alias_dao import AliasDAO
                from ...models.alias import AliasType, extract_aliases_from_source
                
                # åˆ›å»ºåˆ«åDAO
                alias_dao = AliasDAO(database=self.dao.driver if hasattr(self.dao, 'driver') else None)
                
                # ä»ä¸Šä¸‹æ–‡è·å–æºæ•°æ®
                source_data = context.get('source_data', {})
                
                # æå–æºåˆ«å
                source_aliases = extract_aliases_from_source(source_data)
                logger.info(f"ğŸ·ï¸ [Hook] ä»æºæ•°æ®ä¸­æ‰¾åˆ° {len(source_aliases)} ä¸ªåˆ«å")
                
                # æ·»åŠ ä»æ–‡çŒ®æ ‡è¯†ç¬¦ä¸­æå–çš„åˆ«å
                literature_aliases = {}
                
                if literature.identifiers:
                    if hasattr(literature.identifiers, 'doi') and literature.identifiers.doi:
                        literature_aliases[AliasType.DOI] = literature.identifiers.doi
                    
                    if hasattr(literature.identifiers, 'arxiv_id') and literature.identifiers.arxiv_id:
                        literature_aliases[AliasType.ARXIV] = literature.identifiers.arxiv_id
                        
                    if hasattr(literature.identifiers, 'pmid') and literature.identifiers.pmid:
                        literature_aliases[AliasType.PMID] = literature.identifiers.pmid
                
                # æ·»åŠ å†…å®¹URLåˆ«å
                if literature.content:
                    if hasattr(literature.content, 'pdf_url') and literature.content.pdf_url:
                        literature_aliases[AliasType.PDF_URL] = literature.content.pdf_url
                        
                    if hasattr(literature.content, 'source_page_url') and literature.content.source_page_url:
                        literature_aliases[AliasType.SOURCE_PAGE] = literature.content.source_page_url
                
                # æ·»åŠ æ ‡é¢˜åˆ«åï¼ˆç”¨äºåŸºäºæ ‡é¢˜çš„æŸ¥æ‰¾ï¼‰
                if literature.metadata and hasattr(literature.metadata, 'title') and literature.metadata.title:
                    literature_aliases[AliasType.TITLE] = literature.metadata.title
                
                # åˆå¹¶æ‰€æœ‰åˆ«å
                all_aliases = {**source_aliases, **literature_aliases}
                logger.info(f"ğŸ·ï¸ [Hook] æ€»å…± {len(all_aliases)} ä¸ªåˆ«åå¾…åˆ›å»º: {literature_id}")
                
                # æ‰¹é‡åˆ›å»ºæ˜ å°„
                if all_aliases:
                    task_id = context.get('task_id', 'unknown')
                    created_ids = await alias_dao.batch_create_mappings(
                        lid=literature_id,
                        mappings=all_aliases,
                        confidence=1.0,
                        metadata={
                            "source": "literature_creation",
                            "task_id": task_id,
                            "created_from": "hook_automatic_mapping"
                        }
                    )
                    
                    logger.info(f"âœ… [Hook] æˆåŠŸåˆ›å»º {len(created_ids)} ä¸ªåˆ«åæ˜ å°„: {literature_id}")
                    
                    # æ ¼å¼åŒ–åˆ«ååˆ—è¡¨ç”¨äºæ—¥å¿—
                    alias_summary = []
                    for alias_type, value in all_aliases.items():
                        alias_summary.append(f"{alias_type.value}:{value[:50]}...")
                    
                    return {
                        'status': 'completed',
                        'aliases_created': alias_summary,
                        'count': len(created_ids),
                        'total_aliases': len(all_aliases)
                    }
                else:
                    logger.warning(f"ğŸ·ï¸ [Hook] æ²¡æœ‰æ‰¾åˆ°åˆ«åéœ€è¦åˆ›å»º: {literature_id}")
                    return {
                        'status': 'completed',
                        'aliases_created': [],
                        'count': 0,
                        'reason': 'No aliases found'
                    }
                    
            except ImportError:
                logger.error(f"âŒ [Hook] æ— æ³•å¯¼å…¥åˆ«åç›¸å…³æ¨¡å—")
                return {'status': 'failed', 'error': 'Alias modules not available'}
            
        except Exception as e:
            logger.error(f"âŒ [Hook] åˆ«ååˆ›å»ºå¤±è´¥: {e}")
            return {'status': 'failed', 'error': str(e)}
    
    async def _create_doi_alias(self, literature_id: str, doi: str):
        """åˆ›å»ºDOIåˆ«å"""
        # è¿™é‡Œåº”è¯¥è°ƒç”¨DAOçš„æ–¹æ³•åˆ›å»ºDOIåˆ«å
        logger.debug(f"ğŸ“‹ åˆ›å»ºDOIåˆ«å: {literature_id} -> {doi}")
    
    async def _create_url_alias(self, literature_id: str, url: str):
        """åˆ›å»ºURLåˆ«å"""
        # è¿™é‡Œåº”è¯¥è°ƒç”¨DAOçš„æ–¹æ³•åˆ›å»ºURLåˆ«å
        logger.debug(f"ğŸ“‹ åˆ›å»ºURLåˆ«å: {literature_id} -> {url}")
    
    async def _create_arxiv_alias(self, literature_id: str, arxiv_id: str):
        """åˆ›å»ºArXivåˆ«å"""
        # è¿™é‡Œåº”è¯¥è°ƒç”¨DAOçš„æ–¹æ³•åˆ›å»ºArXivåˆ«å
        logger.debug(f"ğŸ“‹ åˆ›å»ºArXivåˆ«å: {literature_id} -> {arxiv_id}")


class QualityAssessmentHook(Hook):
    """è´¨é‡è¯„ä¼°Hook - è‡ªåŠ¨è¯„ä¼°æ–‡çŒ®å…ƒæ•°æ®è´¨é‡"""
    
    @property
    def name(self) -> str:
        return "auto_quality_assessment"
    
    @property
    def triggers(self) -> List[str]:
        return ["metadata_updated"]
    
    def __init__(self, dao: LiteratureDAO):
        super().__init__()
        self.dao = dao
    
    async def execute(self, event: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œè´¨é‡è¯„ä¼°"""
        try:
            metadata = context.get('metadata')
            literature_id = context.get('literature_id')
            
            if not metadata:
                return {'status': 'skipped', 'reason': 'no_metadata'}
            
            logger.info(f"ğŸ“Š [Hook] è´¨é‡è¯„ä¼°å¼€å§‹: {literature_id}")
            
            # è®¡ç®—è´¨é‡åˆ†æ•°
            quality_score = self._calculate_quality_score(metadata)
            quality_level = self._get_quality_level(quality_score)
            
            # æ›´æ–°è´¨é‡ä¿¡æ¯åˆ°æ•°æ®åº“
            await self._update_quality_info(literature_id, quality_score, quality_level)
            
            logger.info(f"âœ… [Hook] è´¨é‡è¯„ä¼°å®Œæˆ: {quality_score}/100 ({quality_level})")
            
            return {
                'status': 'completed',
                'quality_score': quality_score,
                'quality_level': quality_level
            }
            
        except Exception as e:
            logger.error(f"âŒ [Hook] è´¨é‡è¯„ä¼°å¤±è´¥: {e}")
            return {'status': 'failed', 'error': str(e)}
    
    def _calculate_quality_score(self, metadata: MetadataModel) -> int:
        """è®¡ç®—è´¨é‡åˆ†æ•° (0-100)"""
        score = 0
        
        # åŸºç¡€ä¿¡æ¯ (40åˆ†)
        if metadata.title:
            score += 20
        if metadata.authors and len(metadata.authors) > 0:
            score += 20
        
        # æ ‡è¯†ç¬¦ (30åˆ†)
        if hasattr(metadata, 'identifiers') and metadata.identifiers:
            if hasattr(metadata.identifiers, 'doi') and metadata.identifiers.doi:
                score += 15
            if hasattr(metadata.identifiers, 'arxiv_id') and metadata.identifiers.arxiv_id:
                score += 10
        if metadata.year:
            score += 5
        
        # è¯¦ç»†ä¿¡æ¯ (30åˆ†)
        if metadata.abstract and len(metadata.abstract) > 100:
            score += 15
        if metadata.journal:
            score += 10
        if metadata.keywords and len(metadata.keywords) > 0:
            score += 5
        
        return min(score, 100)
    
    def _get_quality_level(self, score: int) -> str:
        """è·å–è´¨é‡ç­‰çº§"""
        if score >= 80:
            return "high"
        elif score >= 60:
            return "medium"
        elif score >= 40:
            return "low"
        else:
            return "poor"
    
    async def _update_quality_info(self, literature_id: str, score: int, level: str):
        """æ›´æ–°è´¨é‡ä¿¡æ¯åˆ°æ•°æ®åº“"""
        # è¿™é‡Œåº”è¯¥è°ƒç”¨DAOçš„æ–¹æ³•æ›´æ–°è´¨é‡ä¿¡æ¯
        logger.debug(f"ğŸ“‹ æ›´æ–°è´¨é‡ä¿¡æ¯: {literature_id} -> {score} ({level})")


class HookManager:
    """Hookç®¡ç†å™¨ - ç®¡ç†æ‰€æœ‰Hookçš„æ³¨å†Œå’Œæ‰§è¡Œ"""
    
    def __init__(self, dao: LiteratureDAO):
        super().__init__()
        self.dao = dao
        self.hooks: Dict[str, Hook] = {}
        self.event_hooks: Dict[str, List[Hook]] = {}
        
        # æ³¨å†Œé»˜è®¤Hook
        self._register_default_hooks()
    
    def _register_default_hooks(self):
        """æ³¨å†Œé»˜è®¤Hook"""
        hooks = [
            DeduplicationHook(self.dao),
            AliasCreationHook(self.dao),
            QualityAssessmentHook(self.dao),
            # ğŸ†• æ–°å¢å…³ç³»æ•°æ®å¤„ç†Hook
            # ReferencesFetchHook(self.dao),
            CitationResolverHook(self.dao),
            UnresolvedNodeUpgradeHook(self.dao)
        ]
        
        for hook in hooks:
            self.register_hook(hook)
    
    def register_hook(self, hook: Hook):
        """æ³¨å†ŒHook"""
        self.hooks[hook.name] = hook
        
        # ä¸ºHookè®¾ç½®HookManagerå¼•ç”¨ï¼Œä»¥ä¾¿è§¦å‘çº§è”äº‹ä»¶
        if hasattr(hook, 'set_hook_manager'):
            hook.set_hook_manager(self)
        
        # å»ºç«‹äº‹ä»¶åˆ°Hookçš„æ˜ å°„
        for event in hook.triggers:
            if event not in self.event_hooks:
                self.event_hooks[event] = []
            self.event_hooks[event].append(hook)
        
        logger.info(f"âœ… æ³¨å†ŒHook: {hook.name} (è§¦å‘äº‹ä»¶: {hook.triggers})")
    
    async def trigger_event(self, event: str, context: Dict[str, Any]) -> Dict[str, List[Dict]]:
        """è§¦å‘äº‹ä»¶ï¼Œæ‰§è¡Œç›¸å…³Hook"""
        if event not in self.event_hooks:
            logger.debug(f"ğŸ” äº‹ä»¶ {event} æ²¡æœ‰å¯¹åº”çš„Hook")
            return {'event': event, 'results': []}
        
        hooks = self.event_hooks[event]
        logger.info(f"ğŸš€ è§¦å‘äº‹ä»¶ {event}, æ‰§è¡Œ {len(hooks)} ä¸ªHook")
        
        # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰ç›¸å…³Hook
        tasks = []
        for hook in hooks:
            task = asyncio.create_task(self._execute_hook_safe(hook, event, context))
            tasks.append(task)
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†ç»“æœ
        hook_results = []
        next_events = []  # æ”¶é›†éœ€è¦è§¦å‘çš„ä¸‹ä¸€ä¸ªäº‹ä»¶
        
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                hook_results.append({
                    'hook': hooks[i].name,
                    'status': 'failed',
                    'error': str(result)
                })
            else:
                hook_results.append({
                    'hook': hooks[i].name,
                    **result
                })
                
                # æ£€æŸ¥æ˜¯å¦æœ‰ä¸‹ä¸€ä¸ªäº‹ä»¶éœ€è¦è§¦å‘
                if result.get('next_event'):
                    next_events.append(result['next_event'])
        
        # ç»Ÿè®¡æ‰§è¡Œç»“æœ
        successful = len([r for r in hook_results if r.get('status') == 'completed'])
        logger.info(f"âœ… äº‹ä»¶ {event} æ‰§è¡Œå®Œæˆ: {successful}/{len(hooks)} HookæˆåŠŸ")
        
        # ğŸ†• è§¦å‘çº§è”äº‹ä»¶
        cascade_results = []
        for next_event in set(next_events):  # å»é‡
            logger.info(f"ğŸ”— è§¦å‘çº§è”äº‹ä»¶: {next_event}")
            cascade_result = await self.trigger_event(next_event, context)
            cascade_results.append(cascade_result)
        
        result = {
            'event': event,
            'results': hook_results,
            'summary': {
                'total_hooks': len(hooks),
                'successful': successful,
                'failed': len(hooks) - successful
            }
        }
        
        # å¦‚æœæœ‰çº§è”äº‹ä»¶ï¼Œä¹ŸåŒ…å«åœ¨ç»“æœä¸­
        if cascade_results:
            result['cascade_events'] = cascade_results
        
        return result
    
    async def _execute_hook_safe(self, hook: Hook, event: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """å®‰å…¨æ‰§è¡ŒHook (æ•è·å¼‚å¸¸)"""
        try:
            return await hook.execute(event, context)
        except Exception as e:
            logger.error(f"âŒ Hook {hook.name} æ‰§è¡Œå¤±è´¥: {e}")
            return {'status': 'failed', 'error': str(e)}


# =================== ğŸ†• æ–°å¢å…³ç³»æ•°æ®å¤„ç†Hook ===================

# class ReferencesFetchHook(Hook):
#     """å¼•ç”¨æ–‡çŒ®è·å–Hook    æœªå¯ç”¨"""
    
#     @property
#     def name(self) -> str:
#         return "references_fetch"
    
#     @property
#     def triggers(self) -> List[str]:
#         return ["metadata_updated"]
    
#     def __init__(self, dao: LiteratureDAO):
#         super().__init__()
#         self.dao = dao
    
#     async def execute(self, event: str, context: Dict[str, Any]) -> Dict[str, Any]:
#         """è·å–å¼•ç”¨æ–‡çŒ®"""
#         try:
#             literature_id = context.get('literature_id')
#             metadata = context.get('metadata')
            
#             if not literature_id or not metadata:
#                 return {'status': 'skipped', 'reason': 'Missing literature_id or metadata'}
            
#             logger.info(f"ğŸ“š [Hook] å¼€å§‹è·å–å¼•ç”¨æ–‡çŒ®: {literature_id}")
            
#             # ğŸ¯ ä½¿ç”¨åŸæœ‰çš„ReferencesFetcheré€»è¾‘
#             try:
#                 from ..references_fetcher import ReferencesFetcher
#                 from ...settings import Settings
                
#                 settings = Settings()
#                 references_fetcher = ReferencesFetcher(settings)
                
#                 # æ„å»ºæ ‡è¯†ç¬¦å­—å…¸
#                 identifiers = {}
#                 if metadata:
#                     if hasattr(metadata, 'identifiers') and metadata.identifiers:
#                         if hasattr(metadata.identifiers, 'doi') and metadata.identifiers.doi:
#                             identifiers['doi'] = metadata.identifiers.doi
#                         if hasattr(metadata.identifiers, 'arxiv_id') and metadata.identifiers.arxiv_id:
#                             identifiers['arxiv_id'] = metadata.identifiers.arxiv_id
                
#                 logger.info(f"ğŸ“š [Hook] ä½¿ç”¨æ ‡è¯†ç¬¦è·å–å¼•ç”¨: {identifiers}")
                
#                 # ä½¿ç”¨ç€‘å¸ƒæµæ–¹æ³•è·å–å¼•ç”¨
#                 if identifiers:
#                     references, raw_data = references_fetcher.fetch_references_waterfall(
#                         identifiers=identifiers,
#                         pdf_content=None  # æš‚æ—¶ä¸ä¼ å…¥PDFå†…å®¹
#                     )
                    
#                     if references:
#                         # æ›´æ–°æ–‡çŒ®çš„å¼•ç”¨ä¿¡æ¯ï¼ˆå¦‚æœDAOæ”¯æŒæ­¤æ–¹æ³•ï¼‰
#                         try:
#                             if hasattr(self.dao, 'update_literature_references'):
#                                 await self.dao.update_literature_references(literature_id, references)
#                         except Exception as e:
#                             logger.warning(f"æ›´æ–°æ–‡çŒ®å¼•ç”¨å¤±è´¥: {e}")
                        
#                         # ğŸ¯ è§¦å‘å¼•ç”¨è·å–å®Œæˆäº‹ä»¶
#                         # å°†å¼•ç”¨æ•°æ®æ·»åŠ åˆ°ä¸Šä¸‹æ–‡ä¸­ï¼Œä¾›CitationResolverHookä½¿ç”¨
#                         context.update({
#                             'references': references,
#                             'raw_references_data': raw_data,
#                             'source_identifiers': identifiers
#                         })
                        
#                         logger.info(f"âœ… [Hook] å¼•ç”¨è·å–å®Œæˆ: {len(references)} ä¸ªå¼•ç”¨")
                        
#                         # ğŸ”„ æ‰‹åŠ¨è§¦å‘çº§è”äº‹ä»¶
#                         if hasattr(self, 'hook_manager') and self.hook_manager:
#                             try:
#                                 await self.hook_manager.trigger_event('references_fetched', context)
#                                 logger.info(f"ğŸ”„ [Hook] å·²è§¦å‘ references_fetched äº‹ä»¶")
#                             except Exception as e:
#                                 logger.warning(f"è§¦å‘çº§è”äº‹ä»¶å¤±è´¥: {e}")
                        
#                         return {
#                             'status': 'completed',
#                             'references_count': len(references),
#                             'identifiers_used': identifiers,
#                             'cascade_triggered': True
#                         }
#                     else:
#                         logger.warning(f"âš ï¸ [Hook] ä½¿ç”¨ç†æƒ³æ ‡è¯†ç¬¦æœªèƒ½è·å–åˆ°å¼•ç”¨æ–‡çŒ®")
#                         return {
#                             'status': 'completed',
#                             'references_count': 0,
#                             'reason': 'No references found from sources with ideal identifiers'
#                         }
#                 else:
#                     logger.warning(f"âš ï¸ [Hook] æ²¡æœ‰å¯ç”¨çš„æ ‡è¯†ç¬¦è·å–å¼•ç”¨")
#                     return {
#                         'status': 'skipped',
#                         'reason': 'No valid identifiers (DOI/ArXiv) available'
#                     }
                    
#             except ImportError:
#                 logger.error(f"âŒ [Hook] æ— æ³•å¯¼å…¥ReferencesFetcher")
#                 return {'status': 'failed', 'error': 'ReferencesFetcher not available'}
                
#         except Exception as e:
#             logger.error(f"âŒ [Hook] å¼•ç”¨è·å–å¤±è´¥: {e}")
#             return {'status': 'failed', 'error': str(e)}


class CitationResolverHook(Hook):
    """å¼•ç”¨å…³ç³»è§£æHook"""
    
    @property
    def name(self) -> str:
        return "citation_resolver"
    
    @property
    def triggers(self) -> List[str]:
        return ["references_fetched", "literature_created"]
    
    def __init__(self, dao: LiteratureDAO):
        super().__init__()
        self.dao = dao
    
    async def execute(self, event: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """è§£æå¼•ç”¨å…³ç³»"""
        try:
            literature_id = context.get('literature_id')
            
            if not literature_id:
                return {'status': 'skipped', 'reason': 'Missing literature_id'}
            
            logger.info(f"ğŸ”— [Hook] å¼€å§‹è§£æå¼•ç”¨å…³ç³»: {literature_id}")
            
            # è·å–æ–‡çŒ®çš„å¼•ç”¨åˆ—è¡¨
            literature = await self.dao.find_by_lid(literature_id)
            if not literature or not literature.references:
                return {'status': 'skipped', 'reason': 'No references to resolve'}
            
            references = literature.references
            
            try:
                from ..citation_resolver import CitationResolver
                
                # åˆå§‹åŒ–å¼•ç”¨è§£æå™¨
                citation_resolver = CitationResolver(task_id=context.get('task_id', 'unknown'))
                await citation_resolver.initialize_with_dao(self.dao)
                
                # è§£æå¼•ç”¨å…³ç³»
                resolution_result = await citation_resolver.resolve_citations_for_literature(
                    citing_literature_lid=literature_id,
                    references=references
                )
                
                stats = resolution_result.get("statistics", {})
                logger.info(f"ğŸ”— [Hook] å¼•ç”¨å…³ç³»è§£æå®Œæˆ: {stats.get('resolved_citations', 0)} å·²è§£æ, {stats.get('unresolved_references', 0)} æœªè§£æ")
                
                return {
                    'status': 'completed',
                    'statistics': stats,
                    'resolution_rate': stats.get('resolution_rate', 0.0)
                }
                
            except ImportError:
                logger.error(f"âŒ [Hook] æ— æ³•å¯¼å…¥CitationResolver")
                return {'status': 'failed', 'error': 'CitationResolver not available'}
                
        except Exception as e:
            logger.error(f"âŒ [Hook] å¼•ç”¨å…³ç³»è§£æå¤±è´¥: {e}")
            return {'status': 'failed', 'error': str(e)}


class UnresolvedNodeUpgradeHook(Hook):
    """æœªè§£æèŠ‚ç‚¹å‡çº§Hook"""
    
    @property
    def name(self) -> str:
        return "unresolved_node_upgrade"
    
    @property
    def triggers(self) -> List[str]:
        return ["literature_created"]
    
    def __init__(self, dao: LiteratureDAO):
        super().__init__()
        self.dao = dao
    
    async def execute(self, event: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """å‡çº§åŒ¹é…çš„æœªè§£æèŠ‚ç‚¹"""
        try:
            literature_id = context.get('literature_id')
            
            if not literature_id:
                return {'status': 'skipped', 'reason': 'Missing literature_id'}
            
            logger.info(f"â¬†ï¸ [Hook] å¼€å§‹å‡çº§æœªè§£æèŠ‚ç‚¹: {literature_id}")
            
            # è·å–æ–°åˆ›å»ºçš„æ–‡çŒ®
            literature = await self.dao.find_by_lid(literature_id)
            if not literature:
                return {'status': 'skipped', 'reason': 'Literature not found'}
            
            # ğŸ¯ å®ç°æœªè§£æèŠ‚ç‚¹å‡çº§é€»è¾‘
            # è¿™é‡Œéœ€è¦è°ƒç”¨åŸæœ‰çš„ _upgrade_matching_unresolved_nodes å‡½æ•°é€»è¾‘
            try:
                upgraded_count = await self._upgrade_matching_unresolved_nodes(literature)
                
                logger.info(f"â¬†ï¸ [Hook] æœªè§£æèŠ‚ç‚¹å‡çº§å®Œæˆ: {upgraded_count} ä¸ªèŠ‚ç‚¹å·²å‡çº§")
                
                return {
                    'status': 'completed',
                    'upgraded_nodes': upgraded_count
                }
                
            except Exception as e:
                logger.error(f"âŒ [Hook] èŠ‚ç‚¹å‡çº§é€»è¾‘å¤±è´¥: {e}")
                return {'status': 'failed', 'error': f'Upgrade logic failed: {str(e)}'}
                
        except Exception as e:
            logger.error(f"âŒ [Hook] æœªè§£æèŠ‚ç‚¹å‡çº§å¤±è´¥: {e}")
            return {'status': 'failed', 'error': str(e)}
    
    async def _upgrade_matching_unresolved_nodes(self, literature) -> int:
        """å‡çº§åŒ¹é…çš„æœªè§£æèŠ‚ç‚¹ (å®ç°åŸæœ‰é€»è¾‘)"""
        try:
            from ...db.relationship_dao import RelationshipDAO
            
            # åˆ›å»ºå…³ç³»DAO - ä½¿ç”¨ç›¸åŒçš„æ•°æ®åº“è¿æ¥
            relationship_dao = RelationshipDAO(database=self.dao.driver if hasattr(self.dao, 'driver') else None)
            
            # ç”ŸæˆåŒ¹é…å€™é€‰çš„LIDæ¨¡å¼
            matching_patterns = []
            
            # ğŸ¯ åŸºäºæ ‡é¢˜è§„èŒƒåŒ–è¿›è¡Œæ™ºèƒ½åŒ¹é…
            if literature.metadata and literature.metadata.title:
                # ä½¿ç”¨æ ‡é¢˜è§„èŒƒåŒ–è¿›è¡ŒåŒ¹é…æŸ¥æ‰¾
                try:
                    from ...utils.title_normalization import normalize_title_for_matching
                    
                    normalized_title = normalize_title_for_matching(literature.metadata.title)
                    if normalized_title:
                        logger.info(f"â¬†ï¸ [Hook] æœç´¢æ ‡é¢˜åŒ¹é…çš„æœªè§£æèŠ‚ç‚¹: '{normalized_title[:50]}...'")
                        
                        # ç›´æ¥æŸ¥æ‰¾æ•°æ®åº“ä¸­åŒ¹é…çš„æœªè§£æèŠ‚ç‚¹
                        async with relationship_dao._get_session() as session:
                            # æŸ¥æ‰¾æ ‡é¢˜åŒ¹é…çš„æœªè§£æèŠ‚ç‚¹
                            title_match_query = """
                            MATCH (u:Unresolved)
                            WHERE u.parsed_title IS NOT NULL
                            RETURN u.lid as lid, u.parsed_title as title, u.parsed_year as year
                            """
                            
                            result = await session.run(title_match_query)
                            candidate_nodes = []
                            async for record in result:
                                candidate_title = record["title"]
                                candidate_year = record["year"]
                                candidate_lid = record["lid"]
                                
                                if candidate_title:
                                    candidate_normalized = normalize_title_for_matching(candidate_title)
                                    
                                    # ğŸ¯ åŒ¹é…æ¡ä»¶ï¼šæ ‡é¢˜ç›¸åŒ + å¹´ä»½ç›¸åŒæˆ–ç›¸è¿‘(Â±1å¹´)
                                    title_matches = candidate_normalized == normalized_title
                                    year_matches = True  # é»˜è®¤åŒ¹é…
                                    
                                    if literature.metadata.year and candidate_year:
                                        try:
                                            lit_year = int(literature.metadata.year)
                                            cand_year = int(candidate_year)
                                            # å…è®¸Â±1å¹´çš„å·®å¼‚
                                            year_matches = abs(lit_year - cand_year) <= 1
                                        except (ValueError, TypeError):
                                            year_matches = True  # å¹´ä»½è§£æå¤±è´¥æ—¶ä¸ä½œä¸ºé˜»æ–­æ¡ä»¶
                                    
                                    if title_matches and year_matches:
                                        candidate_nodes.append({
                                            "lid": candidate_lid,
                                            "title": candidate_title,
                                            "year": candidate_year
                                        })
                                        logger.info(f"â¬†ï¸ [Hook] æ‰¾åˆ°æ ‡é¢˜åŒ¹é…å€™é€‰: {candidate_lid} (å¹´ä»½: {candidate_year} vs {literature.metadata.year})")
                            
                            # æ·»åŠ åŒ¹é…çš„å€™é€‰LID
                            for candidate in candidate_nodes:
                                matching_patterns.append(candidate["lid"])
                                
                except ImportError:
                    logger.warning("â¬†ï¸ [Hook] æ— æ³•å¯¼å…¥title_normalizationï¼Œè·³è¿‡æ ‡é¢˜åŒ¹é…")
                except Exception as e:
                    logger.warning(f"â¬†ï¸ [Hook] æ ‡é¢˜åŒ¹é…å‡ºé”™: {e}")
            
            logger.info(f"â¬†ï¸ [Hook] æœç´¢åŒ¹é…çš„æœªè§£æèŠ‚ç‚¹: {matching_patterns}")
            
            # æ£€æŸ¥æ¯ä¸ªå¯èƒ½çš„LIDå¹¶æ‰§è¡Œå‡çº§
            upgraded_count = 0
            for pattern_lid in matching_patterns:
                try:
                    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨è¿™ä¸ªæœªè§£æèŠ‚ç‚¹
                    async with relationship_dao._get_session() as session:
                        check_query = """
                        MATCH (unresolved:Unresolved {lid: $pattern_lid})
                        RETURN unresolved.lid as lid, unresolved.parsed_title as title
                        """
                        
                        result = await session.run(check_query, pattern_lid=pattern_lid)
                        record = await result.single()
                        
                        if record:
                            logger.info(f"â¬†ï¸ [Hook] æ‰¾åˆ°åŒ¹é…çš„æœªè§£æèŠ‚ç‚¹: {pattern_lid} -> {record['title']}")
                            
                            # æ‰§è¡Œå‡çº§
                            upgrade_stats = await relationship_dao.upgrade_unresolved_to_literature(
                                placeholder_lid=pattern_lid,
                                literature_lid=literature.lid
                            )
                            
                            if upgrade_stats.get("relationships_updated", 0) > 0:
                                upgraded_count += 1
                                logger.info(f"â¬†ï¸ [Hook] âœ… å‡çº§æˆåŠŸ {pattern_lid} -> {literature.lid}, æ›´æ–°äº† {upgrade_stats['relationships_updated']} ä¸ªå…³ç³»")
                            else:
                                logger.warning(f"â¬†ï¸ [Hook] âš ï¸ æ‰¾åˆ° {pattern_lid} ä½†æ²¡æœ‰å…³ç³»éœ€è¦å‡çº§")
                        
                except Exception as e:
                    logger.warning(f"â¬†ï¸ [Hook] æ£€æŸ¥æ¨¡å¼ {pattern_lid} æ—¶å‡ºé”™: {e}")
                    # ç»§ç»­æ£€æŸ¥å…¶ä»–æ¨¡å¼
            
            if upgraded_count > 0:
                logger.info(f"â¬†ï¸ [Hook] âœ… æˆåŠŸå‡çº§ {upgraded_count} ä¸ªæœªè§£æèŠ‚ç‚¹åˆ°æ–‡çŒ® {literature.lid}")
            else:
                logger.info(f"â¬†ï¸ [Hook] æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„æœªè§£æèŠ‚ç‚¹ {literature.lid}")
            
            return upgraded_count
            
        except ImportError:
            logger.error("â¬†ï¸ [Hook] æ— æ³•å¯¼å…¥RelationshipDAO")
            return 0
        except Exception as e:
            logger.error(f"â¬†ï¸ [Hook] æœªè§£æèŠ‚ç‚¹å‡çº§å‡ºé”™: {e}")
            return 0

"""
Hookç³»ç»Ÿ - è‡ªåŠ¨åŒ–æ•°æ®å¤„ç†é’©å­

å®ç°äº‹ä»¶é©±åŠ¨çš„è‡ªåŠ¨æŸ¥é‡ã€åˆ«ååˆ›å»ºã€è´¨é‡è¯„ä¼°ç­‰åå¤„ç†é€»è¾‘ã€‚
"""

import asyncio
import logging
from typing import Dict, List, Any, Optional, Set
from datetime import datetime
from abc import ABC, abstractmethod

from ...models.literature import MetadataModel
from ...db.dao import LiteratureDAO

logger = logging.getLogger(__name__)


class Hook(ABC):
    """HookåŸºç±» - æ‰€æœ‰Hookéƒ½ç»§æ‰¿æ­¤ç±»"""
    
    @property
    @abstractmethod
    def name(self) -> str:
        """Hookåç§°"""
        pass
    
    @property
    @abstractmethod
    def triggers(self) -> List[str]:
        """è§¦å‘äº‹ä»¶åˆ—è¡¨"""
        pass
    
    @abstractmethod
    async def execute(self, event: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡ŒHooké€»è¾‘"""
        pass


class DeduplicationHook(Hook):
    """è‡ªåŠ¨æŸ¥é‡Hook - å½“æ–°å…ƒæ•°æ®å¯ç”¨æ—¶è‡ªåŠ¨æ£€æŸ¥é‡å¤"""
    
    @property
    def name(self) -> str:
        return "auto_deduplication"
    
    @property
    def triggers(self) -> List[str]:
        return ["metadata_updated", "literature_created"]
    
    def __init__(self, dao: LiteratureDAO):
        self.dao = dao
    
    async def execute(self, event: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œè‡ªåŠ¨æŸ¥é‡"""
        try:
            literature_id = context.get('literature_id')
            metadata = context.get('metadata')
            
            if not literature_id or not metadata:
                return {'status': 'skipped', 'reason': 'insufficient_data'}
            
            logger.info(f"ğŸ” [Hook] è‡ªåŠ¨æŸ¥é‡å¼€å§‹: {literature_id}")
            
            # æ‰§è¡ŒæŸ¥é‡é€»è¾‘
            duplicates = await self._find_duplicates(metadata, literature_id)
            
            if duplicates:
                # å‘ç°é‡å¤ï¼Œåˆå¹¶å¤„ç†
                merged_result = await self._handle_duplicates(literature_id, duplicates, context)
                logger.info(f"âœ… [Hook] æŸ¥é‡å®Œæˆï¼Œå‘ç° {len(duplicates)} ä¸ªé‡å¤é¡¹")
                return {
                    'status': 'completed',
                    'action': 'merged',
                    'duplicates_found': len(duplicates),
                    'result': merged_result
                }
            else:
                logger.info(f"âœ… [Hook] æŸ¥é‡å®Œæˆï¼Œæœªå‘ç°é‡å¤é¡¹")
                return {'status': 'completed', 'action': 'none', 'duplicates_found': 0}
                
        except Exception as e:
            logger.error(f"âŒ [Hook] è‡ªåŠ¨æŸ¥é‡å¤±è´¥: {e}")
            return {'status': 'failed', 'error': str(e)}
    
    async def _find_duplicates(self, metadata: MetadataModel, current_id: str) -> List[str]:
        """æŸ¥æ‰¾é‡å¤é¡¹"""
        duplicates = []
        
        # åŸºäºDOIæŸ¥é‡
        if metadata.doi:
            doi_matches = await self.dao.find_by_doi(metadata.doi)
            duplicates.extend([lit.lid for lit in doi_matches if lit.lid != current_id])
        
        # åŸºäºæ ‡é¢˜+ä½œè€…æŸ¥é‡ (ç®€åŒ–ç‰ˆ)
        if metadata.title and metadata.authors:
            title_matches = await self.dao.find_by_fuzzy_title(metadata.title, threshold=0.9)
            for match in title_matches:
                if match.lid != current_id and match.lid not in duplicates:
                    # ç®€å•çš„ä½œè€…åŒ¹é…æ£€æŸ¥
                    if self._authors_match(metadata.authors, match.authors):
                        duplicates.append(match.lid)
        
        return duplicates
    
    def _authors_match(self, authors1: List[Dict], authors2: List[Dict], threshold: float = 0.7) -> bool:
        """ç®€å•çš„ä½œè€…åŒ¹é…ç®—æ³•"""
        if not authors1 or not authors2:
            return False
        
        # æå–ä½œè€…å§“å
        names1 = {author.get('name', '') for author in authors1}
        names2 = {author.get('name', '') for author in authors2}
        
        # è®¡ç®—äº¤é›†æ¯”ä¾‹
        intersection = len(names1 & names2)
        union = len(names1 | names2)
        
        if union == 0:
            return False
            
        similarity = intersection / union
        return similarity >= threshold
    
    async def _handle_duplicates(self, literature_id: str, duplicates: List[str], context: Dict[str, Any]) -> Dict:
        """å¤„ç†å‘ç°çš„é‡å¤é¡¹"""
        # ç®€åŒ–å¤„ç†ï¼šé€‰æ‹©ç¬¬ä¸€ä¸ªé‡å¤é¡¹ä½œä¸ºä¸»é¡¹ï¼Œåˆ é™¤å½“å‰é¡¹
        if duplicates:
            primary_id = duplicates[0]
            
            # å°†åˆ«åæ·»åŠ åˆ°ä¸»é¡¹
            # è¿™é‡Œåº”è¯¥è°ƒç”¨DAOçš„æ–¹æ³•æ¥å¤„ç†åˆ«ååˆå¹¶
            logger.info(f"ğŸ“‹ [Hook] å°† {literature_id} åˆå¹¶åˆ° {primary_id}")
            
            return {
                'primary_id': primary_id,
                'merged_ids': [literature_id],
                'action': 'merged_to_existing'
            }
        
        return {}


class AliasCreationHook(Hook):
    """åˆ«ååˆ›å»ºHook - è‡ªåŠ¨ä¸ºæ–°æ–‡çŒ®åˆ›å»ºå„ç§åˆ«å"""
    
    @property
    def name(self) -> str:
        return "auto_alias_creation"
    
    @property
    def triggers(self) -> List[str]:
        return ["literature_created", "metadata_updated"]
    
    def __init__(self, dao: LiteratureDAO):
        self.dao = dao
    
    async def execute(self, event: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œåˆ«ååˆ›å»º"""
        try:
            literature_id = context.get('literature_id')
            metadata = context.get('metadata')
            url_info = context.get('url_info', {})
            
            if not literature_id:
                return {'status': 'skipped', 'reason': 'no_literature_id'}
            
            logger.info(f"ğŸ·ï¸ [Hook] è‡ªåŠ¨åˆ«ååˆ›å»ºå¼€å§‹: {literature_id}")
            
            aliases_created = []
            
            # DOIåˆ«å
            if metadata and metadata.doi:
                await self._create_doi_alias(literature_id, metadata.doi)
                aliases_created.append(f"DOI:{metadata.doi}")
            
            # URLåˆ«å
            if url_info.get('url'):
                await self._create_url_alias(literature_id, url_info['url'])
                aliases_created.append(f"URL:{url_info['url']}")
            
            # ArXivåˆ«å
            if metadata and hasattr(metadata, 'arxiv_id') and metadata.arxiv_id:
                await self._create_arxiv_alias(literature_id, metadata.arxiv_id)
                aliases_created.append(f"ArXiv:{metadata.arxiv_id}")
            
            logger.info(f"âœ… [Hook] åˆ«ååˆ›å»ºå®Œæˆ: {len(aliases_created)} ä¸ªåˆ«å")
            
            return {
                'status': 'completed',
                'aliases_created': aliases_created,
                'count': len(aliases_created)
            }
            
        except Exception as e:
            logger.error(f"âŒ [Hook] åˆ«ååˆ›å»ºå¤±è´¥: {e}")
            return {'status': 'failed', 'error': str(e)}
    
    async def _create_doi_alias(self, literature_id: str, doi: str):
        """åˆ›å»ºDOIåˆ«å"""
        # è¿™é‡Œåº”è¯¥è°ƒç”¨DAOçš„æ–¹æ³•åˆ›å»ºDOIåˆ«å
        logger.debug(f"ğŸ“‹ åˆ›å»ºDOIåˆ«å: {literature_id} -> {doi}")
    
    async def _create_url_alias(self, literature_id: str, url: str):
        """åˆ›å»ºURLåˆ«å"""
        # è¿™é‡Œåº”è¯¥è°ƒç”¨DAOçš„æ–¹æ³•åˆ›å»ºURLåˆ«å
        logger.debug(f"ğŸ“‹ åˆ›å»ºURLåˆ«å: {literature_id} -> {url}")
    
    async def _create_arxiv_alias(self, literature_id: str, arxiv_id: str):
        """åˆ›å»ºArXivåˆ«å"""
        # è¿™é‡Œåº”è¯¥è°ƒç”¨DAOçš„æ–¹æ³•åˆ›å»ºArXivåˆ«å
        logger.debug(f"ğŸ“‹ åˆ›å»ºArXivåˆ«å: {literature_id} -> {arxiv_id}")


class QualityAssessmentHook(Hook):
    """è´¨é‡è¯„ä¼°Hook - è‡ªåŠ¨è¯„ä¼°æ–‡çŒ®å…ƒæ•°æ®è´¨é‡"""
    
    @property
    def name(self) -> str:
        return "auto_quality_assessment"
    
    @property
    def triggers(self) -> List[str]:
        return ["metadata_updated"]
    
    def __init__(self, dao: LiteratureDAO):
        self.dao = dao
    
    async def execute(self, event: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œè´¨é‡è¯„ä¼°"""
        try:
            metadata = context.get('metadata')
            literature_id = context.get('literature_id')
            
            if not metadata:
                return {'status': 'skipped', 'reason': 'no_metadata'}
            
            logger.info(f"ğŸ“Š [Hook] è´¨é‡è¯„ä¼°å¼€å§‹: {literature_id}")
            
            # è®¡ç®—è´¨é‡åˆ†æ•°
            quality_score = self._calculate_quality_score(metadata)
            quality_level = self._get_quality_level(quality_score)
            
            # æ›´æ–°è´¨é‡ä¿¡æ¯åˆ°æ•°æ®åº“
            await self._update_quality_info(literature_id, quality_score, quality_level)
            
            logger.info(f"âœ… [Hook] è´¨é‡è¯„ä¼°å®Œæˆ: {quality_score}/100 ({quality_level})")
            
            return {
                'status': 'completed',
                'quality_score': quality_score,
                'quality_level': quality_level
            }
            
        except Exception as e:
            logger.error(f"âŒ [Hook] è´¨é‡è¯„ä¼°å¤±è´¥: {e}")
            return {'status': 'failed', 'error': str(e)}
    
    def _calculate_quality_score(self, metadata: MetadataModel) -> int:
        """è®¡ç®—è´¨é‡åˆ†æ•° (0-100)"""
        score = 0
        
        # åŸºç¡€ä¿¡æ¯ (40åˆ†)
        if metadata.title:
            score += 20
        if metadata.authors and len(metadata.authors) > 0:
            score += 20
        
        # æ ‡è¯†ç¬¦ (30åˆ†)
        if metadata.doi:
            score += 15
        if hasattr(metadata, 'arxiv_id') and metadata.arxiv_id:
            score += 10
        if metadata.year:
            score += 5
        
        # è¯¦ç»†ä¿¡æ¯ (30åˆ†)
        if metadata.abstract and len(metadata.abstract) > 100:
            score += 15
        if metadata.journal:
            score += 10
        if metadata.keywords and len(metadata.keywords) > 0:
            score += 5
        
        return min(score, 100)
    
    def _get_quality_level(self, score: int) -> str:
        """è·å–è´¨é‡ç­‰çº§"""
        if score >= 80:
            return "high"
        elif score >= 60:
            return "medium"
        elif score >= 40:
            return "low"
        else:
            return "poor"
    
    async def _update_quality_info(self, literature_id: str, score: int, level: str):
        """æ›´æ–°è´¨é‡ä¿¡æ¯åˆ°æ•°æ®åº“"""
        # è¿™é‡Œåº”è¯¥è°ƒç”¨DAOçš„æ–¹æ³•æ›´æ–°è´¨é‡ä¿¡æ¯
        logger.debug(f"ğŸ“‹ æ›´æ–°è´¨é‡ä¿¡æ¯: {literature_id} -> {score} ({level})")


class HookManager:
    """Hookç®¡ç†å™¨ - ç®¡ç†æ‰€æœ‰Hookçš„æ³¨å†Œå’Œæ‰§è¡Œ"""
    
    def __init__(self, dao: LiteratureDAO):
        self.dao = dao
        self.hooks: Dict[str, Hook] = {}
        self.event_hooks: Dict[str, List[Hook]] = {}
        
        # æ³¨å†Œé»˜è®¤Hook
        self._register_default_hooks()
    
    def _register_default_hooks(self):
        """æ³¨å†Œé»˜è®¤Hook"""
        hooks = [
            DeduplicationHook(self.dao),
            AliasCreationHook(self.dao),
            QualityAssessmentHook(self.dao)
        ]
        
        for hook in hooks:
            self.register_hook(hook)
    
    def register_hook(self, hook: Hook):
        """æ³¨å†ŒHook"""
        self.hooks[hook.name] = hook
        
        # å»ºç«‹äº‹ä»¶åˆ°Hookçš„æ˜ å°„
        for event in hook.triggers:
            if event not in self.event_hooks:
                self.event_hooks[event] = []
            self.event_hooks[event].append(hook)
        
        logger.info(f"âœ… æ³¨å†ŒHook: {hook.name} (è§¦å‘äº‹ä»¶: {hook.triggers})")
    
    async def trigger_event(self, event: str, context: Dict[str, Any]) -> Dict[str, List[Dict]]:
        """è§¦å‘äº‹ä»¶ï¼Œæ‰§è¡Œç›¸å…³Hook"""
        if event not in self.event_hooks:
            logger.debug(f"ğŸ” äº‹ä»¶ {event} æ²¡æœ‰å¯¹åº”çš„Hook")
            return {'event': event, 'results': []}
        
        hooks = self.event_hooks[event]
        logger.info(f"ğŸš€ è§¦å‘äº‹ä»¶ {event}, æ‰§è¡Œ {len(hooks)} ä¸ªHook")
        
        # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰ç›¸å…³Hook
        tasks = []
        for hook in hooks:
            task = asyncio.create_task(self._execute_hook_safe(hook, event, context))
            tasks.append(task)
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†ç»“æœ
        hook_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                hook_results.append({
                    'hook': hooks[i].name,
                    'status': 'failed',
                    'error': str(result)
                })
            else:
                hook_results.append({
                    'hook': hooks[i].name,
                    **result
                })
        
        # ç»Ÿè®¡æ‰§è¡Œç»“æœ
        successful = len([r for r in hook_results if r.get('status') == 'completed'])
        logger.info(f"âœ… äº‹ä»¶ {event} æ‰§è¡Œå®Œæˆ: {successful}/{len(hooks)} HookæˆåŠŸ")
        
        return {
            'event': event,
            'results': hook_results,
            'summary': {
                'total_hooks': len(hooks),
                'successful': successful,
                'failed': len(hooks) - successful
            }
        }
    
    async def _execute_hook_safe(self, hook: Hook, event: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """å®‰å…¨æ‰§è¡ŒHook (æ•è·å¼‚å¸¸)"""
        try:
            return await hook.execute(event, context)
        except Exception as e:
            logger.error(f"âŒ Hook {hook.name} æ‰§è¡Œå¤±è´¥: {e}")
            return {'status': 'failed', 'error': str(e)}

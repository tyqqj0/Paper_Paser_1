#!/usr/bin/env python3
"""
ArXivå…ƒæ•°æ®å¤„ç†å™¨ - Paper Parser 0.2

ä¸“é—¨å¤„ç†ArXivè®ºæ–‡çš„å…ƒæ•°æ®è·å–å’Œå¢å¼ºã€‚
æ”¯æŒç›´æ¥è·å–å’Œç°æœ‰metadataçš„å¢å¼ºæ¨¡å¼ã€‚
"""

import logging
from typing import Any, Dict, List, Optional, Tuple

from ....models.literature import AuthorModel, MetadataModel
from ....services.arxiv_api import ArXivAPIClient
from ..base import IdentifierData, MetadataProcessor, ProcessorResult, ProcessorType

logger = logging.getLogger(__name__)


class ArXivProcessor(MetadataProcessor):
    """
    ArXivå…ƒæ•°æ®å¤„ç†å™¨ã€‚
    
    ä¸“é—¨å¤„ç†ArXivè®ºæ–‡ï¼Œæ”¯æŒç›´æ¥è·å–å’Œå¢å¼ºæ¨¡å¼ã€‚
    ä¼˜å…ˆçº§ï¼š10ï¼ˆä¸­ç­‰ä¼˜å…ˆçº§ï¼Œä¸»è¦ç”¨ä½œå¢å¼ºï¼‰
    """
    
    def __init__(self, settings=None):
        """åˆå§‹åŒ–ArXivå¤„ç†å™¨"""
        super().__init__(settings)
        self.arxiv_client = ArXivAPIClient(settings)
    
    @property
    def name(self) -> str:
        """å¤„ç†å™¨åç§°"""
        return "ArXiv Official API"
    
    @property
    def processor_type(self) -> ProcessorType:
        """å¤„ç†å™¨ç±»å‹"""
        return ProcessorType.API
    
    @property
    def priority(self) -> int:
        """å¤„ç†å™¨ä¼˜å…ˆçº§ï¼ˆä¸­ç­‰ä¼˜å…ˆçº§ï¼Œä¸»è¦ç”¨ä½œå¢å¼ºï¼‰"""
        return 10
    
    def can_handle(self, identifiers: IdentifierData) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦å¯ä»¥å¤„ç†ç»™å®šçš„æ ‡è¯†ç¬¦ã€‚
        
        åªæœ‰åœ¨æœ‰ArXiv IDçš„æƒ…å†µä¸‹æ‰èƒ½å¤„ç†ã€‚
        
        Args:
            identifiers: æ ‡å‡†åŒ–çš„æ ‡è¯†ç¬¦æ•°æ®
            
        Returns:
            True if æœ‰ArXiv IDå¯ä»¥å¤„ç†
        """
        return bool(identifiers.arxiv_id)
    
    async def process(self, identifiers: IdentifierData) -> ProcessorResult:
        """
        å¤„ç†æ ‡è¯†ç¬¦å¹¶è¿”å›å…ƒæ•°æ®ã€‚
        
        ArXivå¤„ç†å™¨çš„ç‰¹æ®Šé€»è¾‘ï¼š
        1. æ£€æŸ¥æ˜¯å¦éœ€è¦ArXivå¢å¼ºï¼ˆåŸºäºç°æœ‰metadataè´¨é‡ï¼‰
        2. å¦‚æœéœ€è¦ï¼Œè·å–ArXivæ•°æ®å¹¶å¢å¼º
        3. å¦‚æœæ²¡æœ‰ç°æœ‰metadataï¼Œç›´æ¥ä½¿ç”¨ArXivæ•°æ®
        
        Args:
            identifiers: æ ‡å‡†åŒ–çš„æ ‡è¯†ç¬¦æ•°æ®
            
        Returns:
            ProcessorResult with æˆåŠŸçŠ¶æ€å’Œå…ƒæ•°æ®
        """
        try:
            if not identifiers.arxiv_id:
                return ProcessorResult(
                    success=False,
                    error="ArXiv: No ArXiv ID provided",
                    source=self.name
                )
            
            logger.info(f"ğŸ” ArXiv APIæŸ¥è¯¢: {identifiers.arxiv_id}")
            
            # è·å–ArXivæ•°æ®
            arxiv_data = self.arxiv_client.get_metadata(identifiers.arxiv_id)
            
            if not arxiv_data:
                return ProcessorResult(
                    success=False,
                    error="ArXiv: No metadata found",
                    source=self.name
                )
            
            # è½¬æ¢ä¸ºæ ‡å‡†MetadataModel
            arxiv_metadata = self.arxiv_client.convert_to_metadata_model(arxiv_data)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ç°æœ‰metadataéœ€è¦å¢å¼º
            existing_metadata = self._extract_existing_metadata(identifiers)
            
            if existing_metadata:
                # å¢å¼ºæ¨¡å¼ï¼šåˆå¹¶ç°æœ‰metadataå’ŒArXivæ•°æ®
                enhanced_metadata = self._enhance_metadata(existing_metadata, arxiv_metadata)
                confidence = 0.75  # å¢å¼ºæ¨¡å¼ç½®ä¿¡åº¦ç¨ä½
                logger.info("âœ… ArXivæ•°æ®ç”¨äºå¢å¼ºç°æœ‰metadata")
            else:
                # ç›´æ¥æ¨¡å¼ï¼šä½¿ç”¨ArXivæ•°æ®ä½œä¸ºä¸»è¦æ¥æº
                enhanced_metadata = arxiv_metadata
                confidence = 0.85  # ç›´æ¥ä½¿ç”¨ArXivæ•°æ®ç½®ä¿¡åº¦è¾ƒé«˜
                logger.info("âœ… ArXivæ•°æ®ä½œä¸ºä¸»è¦metadataæ¥æº")
            
            return ProcessorResult(
                success=True,
                metadata=enhanced_metadata,
                raw_data=arxiv_data,
                confidence=confidence,
                source=self.name
            )
            
        except Exception as e:
            logger.error(f"ArXivå¤„ç†å™¨å¼‚å¸¸: {e}")
            return ProcessorResult(
                success=False,
                error=f"ArXivå¤„ç†å™¨å¼‚å¸¸: {str(e)}",
                source=self.name
            )
    
    def _extract_existing_metadata(self, identifiers: IdentifierData) -> Optional[MetadataModel]:
        """
        ä»æ ‡è¯†ç¬¦æ•°æ®ä¸­æå–ç°æœ‰çš„metadataï¼ˆå¦‚æœæœ‰ï¼‰ã€‚
        
        è¿™ä¸ªæ–¹æ³•æ£€æŸ¥source_dataä¸­æ˜¯å¦æœ‰ç°æœ‰çš„metadataéœ€è¦å¢å¼ºã€‚
        
        Args:
            identifiers: æ ‡è¯†ç¬¦æ•°æ®
            
        Returns:
            ç°æœ‰çš„MetadataModelæˆ–None
        """
        # æ£€æŸ¥source_dataä¸­æ˜¯å¦æœ‰ç°æœ‰çš„metadata
        if identifiers.source_data:
            # è¿™é‡Œå¯ä»¥æ ¹æ®å®é™…æƒ…å†µæ£€æŸ¥æ˜¯å¦æœ‰é¢„å¤„ç†çš„metadata
            # ç›®å‰ç®€åŒ–å¤„ç†ï¼Œä¸»è¦åŸºäºæ ‡é¢˜å’Œå¹´ä»½åˆ¤æ–­
            if identifiers.title:
                # æ„å»ºä¸€ä¸ªç®€å•çš„ç°æœ‰metadata
                return MetadataModel(
                    title=identifiers.title,
                    year=identifiers.year,
                    authors=[],  # ç©ºçš„ä½œè€…åˆ—è¡¨ï¼Œç­‰å¾…å¢å¼º
                    abstract=None,  # ç©ºçš„æ‘˜è¦ï¼Œç­‰å¾…å¢å¼º
                    journal=identifiers.venue
                )
        
        return None
    
    def _enhance_metadata(
        self, 
        existing_metadata: MetadataModel, 
        arxiv_metadata: MetadataModel
    ) -> MetadataModel:
        """
        ä½¿ç”¨ArXivæ•°æ®å¢å¼ºç°æœ‰metadataã€‚
        
        å¢å¼ºç­–ç•¥ï¼š
        1. å¦‚æœç°æœ‰å­—æ®µä¸ºç©ºï¼Œä½¿ç”¨ArXivæ•°æ®å¡«å……
        2. å¦‚æœç°æœ‰æ ‡é¢˜è´¨é‡å·®ï¼Œæ›¿æ¢ä¸ºArXivæ ‡é¢˜
        3. å§‹ç»ˆä½¿ç”¨ArXivçš„æ‘˜è¦ï¼ˆé€šå¸¸è´¨é‡å¾ˆé«˜ï¼‰
        4. åˆå¹¶å…³é”®è¯
        
        Args:
            existing_metadata: ç°æœ‰çš„metadata
            arxiv_metadata: ArXivçš„metadata
            
        Returns:
            å¢å¼ºåçš„MetadataModel
        """
        logger.info("ğŸ”§ å¼€å§‹å¢å¼ºç°æœ‰metadata...")
        
        # å¤åˆ¶ç°æœ‰metadataä½œä¸ºåŸºç¡€
        enhanced = MetadataModel(
            title=existing_metadata.title,
            authors=existing_metadata.authors.copy() if existing_metadata.authors else [],
            year=existing_metadata.year,
            journal=existing_metadata.journal,
            abstract=existing_metadata.abstract,
            keywords=existing_metadata.keywords.copy() if existing_metadata.keywords else [],
            source_priority=existing_metadata.source_priority.copy() if existing_metadata.source_priority else []
        )
        
        # 1. å¢å¼ºæ ‡é¢˜ï¼ˆå¦‚æœç°æœ‰æ ‡é¢˜è´¨é‡å·®ï¼‰
        if self._needs_title_enhancement(existing_metadata.title, arxiv_metadata.title):
            enhanced.title = arxiv_metadata.title
            logger.info(f"âœ… æ ‡é¢˜å¢å¼º: '{existing_metadata.title}' -> '{arxiv_metadata.title}'")
        
        # 2. å¢å¼ºæ‘˜è¦ï¼ˆArXivæ‘˜è¦é€šå¸¸è´¨é‡å¾ˆé«˜ï¼‰
        if not enhanced.abstract and arxiv_metadata.abstract:
            enhanced.abstract = arxiv_metadata.abstract
            logger.info("âœ… æ‘˜è¦å¢å¼º: æ·»åŠ ArXivæ‘˜è¦")
        elif arxiv_metadata.abstract and len(arxiv_metadata.abstract) > len(enhanced.abstract or ""):
            # å¦‚æœArXivæ‘˜è¦æ›´é•¿ï¼Œå¯èƒ½è´¨é‡æ›´å¥½
            enhanced.abstract = arxiv_metadata.abstract
            logger.info("âœ… æ‘˜è¦å¢å¼º: æ›¿æ¢ä¸ºæ›´è¯¦ç»†çš„ArXivæ‘˜è¦")
        
        # 3. å¢å¼ºä½œè€…ï¼ˆå¦‚æœç°æœ‰ä½œè€…ä¸ºç©ºï¼‰
        if not enhanced.authors and arxiv_metadata.authors:
            enhanced.authors = arxiv_metadata.authors
            logger.info(f"âœ… ä½œè€…å¢å¼º: æ·»åŠ {len(arxiv_metadata.authors)}ä¸ªä½œè€…")
        
        # 4. å¢å¼ºå¹´ä»½ï¼ˆå¦‚æœç°æœ‰å¹´ä»½ä¸ºç©ºï¼‰
        if not enhanced.year and arxiv_metadata.year:
            enhanced.year = arxiv_metadata.year
            logger.info(f"âœ… å¹´ä»½å¢å¼º: æ·»åŠ å¹´ä»½{arxiv_metadata.year}")
        
        # 5. å¢å¼ºæœŸåˆŠä¿¡æ¯ï¼ˆå¦‚æœç°æœ‰æœŸåˆŠä¸ºç©ºï¼Œå¹¶ä¸”ArXivæœ‰æœŸåˆŠå¼•ç”¨ï¼‰
        if not enhanced.journal and arxiv_metadata.journal:
            enhanced.journal = arxiv_metadata.journal
            logger.info(f"âœ… æœŸåˆŠå¢å¼º: æ·»åŠ æœŸåˆŠä¿¡æ¯")
        
        # 6. åˆå¹¶å…³é”®è¯
        if arxiv_metadata.keywords:
            existing_keywords = set(enhanced.keywords)
            new_keywords = [kw for kw in arxiv_metadata.keywords if kw not in existing_keywords]
            if new_keywords:
                enhanced.keywords.extend(new_keywords)
                logger.info(f"âœ… å…³é”®è¯å¢å¼º: æ·»åŠ {len(new_keywords)}ä¸ªæ–°å…³é”®è¯")
        
        # 7. æ›´æ–°source_priority
        enhanced.source_priority.append(f"{self.name} (enhancement)")
        
        return enhanced
    
    def _needs_title_enhancement(self, existing_title: str, arxiv_title: str) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦éœ€è¦æ ‡é¢˜å¢å¼ºã€‚
        
        å¢å¼ºæ¡ä»¶ï¼š
        1. ç°æœ‰æ ‡é¢˜ä¸ºç©ºæˆ–é»˜è®¤å€¼
        2. ç°æœ‰æ ‡é¢˜åŒ…å«"Processing:"ç­‰ä¸´æ—¶æ–‡æœ¬
        3. ç°æœ‰æ ‡é¢˜æ˜æ˜¾è´¨é‡å·®ï¼ˆå¤ªçŸ­ç­‰ï¼‰
        
        Args:
            existing_title: ç°æœ‰æ ‡é¢˜
            arxiv_title: ArXivæ ‡é¢˜
            
        Returns:
            æ˜¯å¦éœ€è¦å¢å¼º
        """
        if not existing_title or not arxiv_title:
            return bool(arxiv_title)
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯é»˜è®¤æˆ–ä¸´æ—¶æ ‡é¢˜
        poor_title_indicators = [
            "Unknown Title",
            "Processing:",
            "Extracting:",
            "Loading...",
            "Error:",
            "N/A"
        ]
        
        for indicator in poor_title_indicators:
            if indicator in existing_title:
                return True
        
        # æ£€æŸ¥æ ‡é¢˜é•¿åº¦ï¼ˆå¤ªçŸ­å¯èƒ½è´¨é‡å·®ï¼‰
        if len(existing_title.strip()) < 10:
            return True
        
        # æ£€æŸ¥æ˜¯å¦ä¸»è¦æ˜¯ç¬¦å·æˆ–æ•°å­—ï¼ˆå¯èƒ½æ˜¯è§£æé”™è¯¯ï¼‰
        import re
        if re.match(r'^[\d\s\-\.]+$', existing_title.strip()):
            return True
        
        return False


# è‡ªåŠ¨æ³¨å†Œå¤„ç†å™¨
from ..registry import register_processor
register_processor(ArXivProcessor)



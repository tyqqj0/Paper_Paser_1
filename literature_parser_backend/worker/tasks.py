"""
Celery tasks for literature processing.

This module contains the core literature processing task that implements
the intelligent hybrid workflow for gathering metadata and references.
"""

import asyncio
import hashlib
import logging
# from datetime import datetime
from typing import Any, Dict, Optional, Tuple

from celery import Task, current_task

from ..db.dao import LiteratureDAO
from ..db.neo4j import close_task_connection, create_task_connection
from ..models.literature import (
    IdentifiersModel,
    LiteratureModel,
    MetadataModel,
)
from ..models.task import (
    TaskExecutionStatus,
    TaskResultType,
)
from ..services import GrobidClient
from ..services.lid_generator import LIDGenerator
from ..db.alias_dao import AliasDAO
from ..models.alias import AliasType, extract_aliases_from_source
from .execution.smart_router import SmartRouter
from ..utils.title_matching import MatchingMode, TitleMatchingUtils
from .celery_app import celery_app
from .content_fetcher import ContentFetcher
from .deduplication import WaterfallDeduplicator
from .metadata.fetcher import MetadataFetcher
from .references_fetcher import ReferencesFetcher
from .utils import (
    convert_grobid_to_metadata,
    extract_authoritative_identifiers,
    update_task_status,
)
# ğŸ†• å¯¼å…¥æ™ºèƒ½è·¯ç”±å™¨ (æ›¿ä»£åŸæœ‰çš„SmartExecutor)
from .execution.smart_router import SmartRouter

logger = logging.getLogger(__name__)


# ===============================================
# Metadata Quality Assessment
# ===============================================

def _evaluate_metadata_quality(metadata: Optional[MetadataModel], source: str) -> Dict[str, Any]:
    """
    Evaluate metadata quality with strict criteria.
    
    Returns quality assessment including:
    - is_high_quality: bool - True if metadata is complete and reliable
    - is_partial: bool - True if metadata has basic info but missing key fields  
    - quality_score: int - Score from 0-100
    - missing_fields: List[str] - List of missing critical fields
    """
    if not metadata:
        return {
            "is_high_quality": False,
            "is_partial": False, 
            "quality_score": 0,
            "missing_fields": ["title", "authors", "year", "journal", "abstract"],
            "assessment": "No metadata available"
        }
    
    # Check if this is just fallback data (not from external APIs)
    is_fallback_only = (
        hasattr(metadata, 'source_priority') and 
        metadata.source_priority and 
        len(metadata.source_priority) == 1 and 
        "fallback" in metadata.source_priority[0].lower()
    )
    
    missing_fields = []
    quality_score = 0
    
    # ğŸ¯ Core Requirements Assessment
    
    # Title (Essential - 25 points)
    # ğŸ›¡ï¸ æ£€æŸ¥æ˜¯å¦æ˜¯è§£æå¤±è´¥çš„æ ‡è¯†
    failed_title_indicators = [
        "Unknown Title",
        "Processing...",
        "Extracting...",
        "Loading...",
        "Error:",
        "N/A"
    ]
    
    is_parsing_failed = any(indicator in (metadata.title or "") for indicator in failed_title_indicators)
    
    if not metadata.title or is_parsing_failed:
        missing_fields.append("title")
        if is_parsing_failed:
            # å¦‚æœæ£€æµ‹åˆ°è§£æå¤±è´¥æ ‡è¯†ï¼Œç›´æ¥è¿”å›ç‰¹æ®Šè¯„ä¼°ç»“æœ
            return {
                "is_high_quality": False,
                "is_partial": False,
                "quality_score": 0,
                "missing_fields": ["title", "authors", "year", "journal", "abstract"],
                "assessment": "parsing_failed",
                "is_fallback_only": False,
                "is_parsing_failed": True,
                "failed_indicators": [indicator for indicator in failed_title_indicators if indicator in (metadata.title or "")]
            }
    else:
        quality_score += 25
        
    # Authors (Critical - 25 points)  
    if not metadata.authors or len(metadata.authors) == 0:
        missing_fields.append("authors")
    else:
        quality_score += 25
        
    # Publication Year (Important - 20 points)
    if not metadata.year:
        missing_fields.append("year") 
    else:
        quality_score += 20
        
    # Journal/Venue (Important - 15 points)
    if not metadata.journal:
        missing_fields.append("journal")
    else:
        quality_score += 15
        
    # Abstract (Valuable - 10 points)
    if not metadata.abstract:
        missing_fields.append("abstract")
    else:
        quality_score += 10
        
    # Keywords (Nice-to-have - 5 points)
    if not metadata.keywords or len(metadata.keywords) == 0:
        missing_fields.append("keywords")
    else:
        quality_score += 5
        
    # ğŸ¯ Quality Thresholds
    
    # Penalize fallback-only data severely
    if is_fallback_only:
        quality_score = min(quality_score, 30)  # Cap at 30% for fallback data
        
    # High Quality: Complete metadata with all essential fields (80%+)
    is_high_quality = (
        quality_score >= 80 and 
        not is_fallback_only and
        "title" not in missing_fields and 
        "authors" not in missing_fields
    )
    
    # Partial Quality: Has title and at least one other important field (40-79%)
    is_partial = (
        quality_score >= 40 and 
        not is_high_quality and
        "title" not in missing_fields
    )
    
    assessment = "high_quality" if is_high_quality else ("partial" if is_partial else "failed")
    
    logger.info(
        f"Metadata quality assessment: {assessment} (score: {quality_score}/100, "
        f"source: {source}, fallback_only: {is_fallback_only}, "
        f"missing: {missing_fields})"
    )
    
    return {
        "is_high_quality": is_high_quality,
        "is_partial": is_partial,
        "quality_score": quality_score, 
        "missing_fields": missing_fields,
        "assessment": assessment,
        "is_fallback_only": is_fallback_only
    }


# ===============================================
# Task Status Management
# ===============================================


class TaskStatusManager:
    """ä»»åŠ¡çŠ¶æ€ç®¡ç†å™¨ - åˆ†ç¦»ä»»åŠ¡æ‰§è¡ŒçŠ¶æ€å’Œæ–‡çŒ®å¤„ç†çŠ¶æ€"""

    def __init__(self, task_id: str):
        self.task_id = task_id
        self.url_validation_info = None

    def update_task_progress(self, stage: str, progress: int, literature_id: str = None):
        """æ›´æ–°Celeryä»»åŠ¡è¿›åº¦ï¼ˆè½»é‡çº§ä¿¡æ¯ï¼‰"""
        meta = {
            "literature_id": literature_id,
            "current_stage": stage,
            "progress": progress
        }

        # å¦‚æœæœ‰URLéªŒè¯ä¿¡æ¯ï¼Œæ·»åŠ åˆ°metaä¸­
        if self.url_validation_info:
            meta.update({
                "url_validation_status": self.url_validation_info.get("status"),
                "url_validation_error": self.url_validation_info.get("error"),
                "original_url": self.url_validation_info.get("original_url"),
            })

        current_task.update_state(
            state="PROGRESS",
            meta=meta
        )

    def set_url_validation_info(self, url_validation_info: Dict[str, Any]):
        """è®¾ç½®URLéªŒè¯ä¿¡æ¯"""
        self.url_validation_info = url_validation_info

    def fail_task_with_url_validation_error(self, error_info, original_url: str = None):
        """å› URLéªŒè¯å¤±è´¥è€Œç»ˆæ­¢ä»»åŠ¡"""
        # ä¸ä½¿ç”¨FAILUREçŠ¶æ€ï¼Œè€Œæ˜¯ä½¿ç”¨PROGRESSçŠ¶æ€æ¥é¿å…Celeryåºåˆ—åŒ–é—®é¢˜
        meta = {
            "error": error_info.error_message,
            "error_type": error_info.error_type,
            "error_category": error_info.error_category,
            "url_validation_status": "failed",
            "url_validation_error": error_info.error_message,
            "original_url": original_url,
            "url_validation_details": error_info.url_validation_details,
            "task_failed": True,  # æ ‡è®°ä»»åŠ¡å¤±è´¥
        }

        current_task.update_state(
            state="PROGRESS",  # ä½¿ç”¨PROGRESSè€Œä¸æ˜¯FAILURE
            meta=meta
        )

    def complete_task(self, result_type: TaskResultType, literature_id: str) -> Dict[str, Any]:
        """å®Œæˆä»»åŠ¡å¹¶è¿”å›ç»“æœ"""
        result = {
            "status": TaskExecutionStatus.COMPLETED,
            "result_type": result_type,
            "literature_id": literature_id
        }

        # å¦‚æœæœ‰URLéªŒè¯ä¿¡æ¯ï¼Œæ·»åŠ åˆ°ç»“æœä¸­
        if self.url_validation_info:
            result.update({
                "url_validation_status": self.url_validation_info.get("status"),
                "original_url": self.url_validation_info.get("original_url"),
            })

        return result

    def fail_task(self, error_message: str, literature_id: str = None) -> Dict[str, Any]:
        """ä»»åŠ¡å¤±è´¥"""
        return {
            "status": TaskExecutionStatus.FAILED,
            "error_message": error_message,
            "literature_id": literature_id
        }


# ===============================================
# Helper Functions for Deduplication and Fetching
# ===============================================


async def _deduplicate_literature(
    identifiers: IdentifiersModel,
    source_data: Dict[str, Any],
    dao: LiteratureDAO,
    task_id: str,
) -> Tuple[Optional[str], Optional[MetadataModel], Optional[bytes]]:
    """
    Execute the deduplication waterfall logic.

    Returns a tuple of:
    - Existing literature model if found
    - Prefetched metadata from GROBID if any
    - PDF content if downloaded
    """
    # 1. Direct identifier check (DOI, ArXiv ID) with failure cleanup
    if identifiers.doi:
        if literature := await dao.find_by_doi(identifiers.doi):
            # Check if this is a failed literature
            if literature.task_info and literature.task_info.status == "failed":
                logger.info(
                    f"Found failed literature with DOI {identifiers.doi}, cleaning up...",
                )
                await dao.delete_literature(str(literature.id))
                return None, None, None
            return str(literature.id), None, None
    if identifiers.arxiv_id:
        if literature := await dao.find_by_arxiv_id(identifiers.arxiv_id):
            # Check if this is a failed literature
            if literature.task_info and literature.task_info.status == "failed":
                logger.info(
                    f"Found failed literature with ArXiv ID {identifiers.arxiv_id}, cleaning up...",
                )
                await dao.delete_literature(str(literature.id))
                return None, None, None
            return str(literature.id), None, None

    # 2. PDF-based check (Fingerprint, Title)
    pdf_content: Optional[bytes] = None
    prefetched_metadata: Optional[MetadataModel] = None

    if source_data.get("pdf_url"):
        update_task_status("æ­£åœ¨ä¸‹è½½PDFç”¨äºå»é‡", progress=10)
        try:
            from .content_fetcher import ContentFetcher

            content_fetcher = ContentFetcher()
            pdf_content = content_fetcher._download_pdf(source_data["pdf_url"])

            if pdf_content:
                # Generate fingerprint
                fingerprint = hashlib.md5(pdf_content).hexdigest()

                # Check by fingerprint with failure cleanup
                if literature := await dao.find_by_fingerprint(fingerprint):
                    # Check if this is a failed literature
                    if literature.task_info and literature.task_info.status == "failed":
                        logger.info(
                            f"Found failed literature with fingerprint {fingerprint}, cleaning up...",
                        )
                        await dao.delete_literature(str(literature.id))
                    else:
                        return str(literature.id), None, pdf_content

                # Try to extract title with GROBID for title-based deduplication
                try:
                    grobid_client = GrobidClient()
                    parsed_data = grobid_client.process_header_only(pdf_content)
                    prefetched_metadata = convert_grobid_to_metadata(parsed_data)

                    if (
                        prefetched_metadata
                        and prefetched_metadata.title != "Unknown Title"
                    ):
                        if literature := await dao.find_by_title(
                            prefetched_metadata.title,
                        ):
                            # Check if this is a failed literature
                            if (
                                literature.task_info
                                and literature.task_info.status == "failed"
                            ):
                                logger.info(
                                    f"Found failed literature with title {prefetched_metadata.title}, cleaning up...",
                                )
                                await dao.delete_literature(str(literature.id))
                            else:
                                return (
                                    str(literature.id),
                                    prefetched_metadata,
                                    pdf_content,
                                )
                except Exception as e:
                    logger.warning(f"GROBID prefetch failed: {e}")
        except Exception as e:
            logger.warning(f"PDF download/processing failed: {e}")

    return None, prefetched_metadata, pdf_content


async def _record_alias_mappings(
    literature: LiteratureModel,
    source_data: Dict[str, Any],
    dao: LiteratureDAO,
    task_id: str
) -> None:
    """
    Record alias mappings for a successfully created literature.
    
    This function creates mappings between external identifiers and the LID,
    enabling fast future lookups without requiring full processing.
    
    Args:
        literature: The created literature model
        source_data: Original source data from the request
        dao: Database access object
        task_id: Current task ID
    """
    try:
        if not literature.lid:
            logger.warning(f"Task {task_id}: No LID found in literature, skipping alias mapping")
            return
        
        # Create alias DAO from same database connection
        alias_dao = AliasDAO(database=dao.driver)
        
        # Extract aliases from source data
        source_aliases = extract_aliases_from_source(source_data)
        logger.info(f"Task {task_id}: Found {len(source_aliases)} source aliases to map")
        
        # Add aliases from parsed identifiers
        literature_aliases = {}
        
        if literature.identifiers.doi:
            literature_aliases[AliasType.DOI] = literature.identifiers.doi
        
        if literature.identifiers.arxiv_id:
            literature_aliases[AliasType.ARXIV] = literature.identifiers.arxiv_id
            
        if literature.identifiers.pmid:
            literature_aliases[AliasType.PMID] = literature.identifiers.pmid
        
        # Add content URLs if available
        if literature.content.pdf_url:
            literature_aliases[AliasType.PDF_URL] = literature.content.pdf_url
            
        if literature.content.source_page_url:
            literature_aliases[AliasType.SOURCE_PAGE] = literature.content.source_page_url
        
        # Add title if available (for title-based lookups)
        if literature.metadata.title:
            literature_aliases[AliasType.TITLE] = literature.metadata.title
        
        # Combine all aliases
        all_aliases = {**source_aliases, **literature_aliases}
        logger.info(f"Task {task_id}: Total {len(all_aliases)} aliases to create for LID {literature.lid}")
        
        # Batch create all mappings
        if all_aliases:
            created_ids = await alias_dao.batch_create_mappings(
                lid=literature.lid,
                mappings=all_aliases,
                confidence=1.0,
                metadata={
                    "source": "literature_creation",
                    "task_id": task_id,
                    "created_from": "automatic_mapping"
                }
            )
            
            logger.info(
                f"Task {task_id}: Successfully created {len(created_ids)} alias mappings for LID {literature.lid}"
            )
        else:
            logger.warning(f"Task {task_id}: No aliases found to create for LID {literature.lid}")
            
    except Exception as e:
        # Don't fail the entire task if alias creation fails
        logger.error(
            f"Task {task_id}: Failed to create alias mappings for LID {literature.lid if literature else 'unknown'}: {e}",
            exc_info=True
        )


async def _upgrade_matching_unresolved_nodes(
    literature: "LiteratureModel",
    dao: "LiteratureDAO", 
    task_id: str
):
    """
    æ£€æŸ¥å¹¶å‡çº§åŒ¹é…çš„æœªè§£æèŠ‚ç‚¹ã€‚
    
    å½“æ–°æ–‡çŒ®æ·»åŠ æ—¶ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰åŒ¹é…çš„æœªè§£æå ä½ç¬¦èŠ‚ç‚¹ï¼Œ
    å¦‚æœæœ‰ï¼Œå°†è¿™äº›èŠ‚ç‚¹å‡çº§ä¸ºæŒ‡å‘çœŸå®æ–‡çŒ®çš„å…³ç³»ã€‚
    
    Args:
        literature: æ–°åˆ›å»ºçš„æ–‡çŒ®æ¨¡å‹
        dao: æ•°æ®åº“è®¿é—®å¯¹è±¡
        task_id: å½“å‰ä»»åŠ¡ID
    """
    try:
        from ..db.relationship_dao import RelationshipDAO
        from ..worker.citation_resolver import CitationResolver
        
        # åˆ›å»ºå…³ç³»DAO - ä½¿ç”¨ç›¸åŒçš„æ•°æ®åº“è¿æ¥
        relationship_dao = RelationshipDAO(database=dao.driver if hasattr(dao, 'driver') else None)
        
        # ç”ŸæˆåŒ¹é…å€™é€‰çš„LIDæ¨¡å¼
        matching_patterns = []
        
        # ğŸ¯ æ–°ç­–ç•¥ï¼šåŸºäºæ ‡é¢˜è§„èŒƒåŒ–è¿›è¡Œæ™ºèƒ½åŒ¹é…ï¼Œä¸ä¾èµ–ä½œè€…æ ¼å¼å·®å¼‚
        if literature.metadata and literature.metadata.title:
            # ä½¿ç”¨æ ‡é¢˜è§„èŒƒåŒ–è¿›è¡ŒåŒ¹é…æŸ¥æ‰¾
            from ..utils.title_normalization import normalize_title_for_matching
            
            normalized_title = normalize_title_for_matching(literature.metadata.title)
            if normalized_title:
                logger.info(
                    f"Task {task_id}: Searching for unresolved nodes with normalized title: "
                    f"'{normalized_title[:50]}...'"
                )
                
                # ç›´æ¥æŸ¥æ‰¾æ•°æ®åº“ä¸­åŒ¹é…çš„æœªè§£æèŠ‚ç‚¹
                try:
                    async with relationship_dao._get_session() as session:
                        # æŸ¥æ‰¾æ ‡é¢˜åŒ¹é…çš„æœªè§£æèŠ‚ç‚¹
                        title_match_query = """
                        MATCH (u:Unresolved)
                        WHERE u.parsed_title IS NOT NULL
                        RETURN u.lid as lid, u.parsed_title as title, u.parsed_year as year
                        """
                        
                        result = await session.run(title_match_query)
                        candidate_nodes = []
                        async for record in result:
                            candidate_title = record["title"]
                            candidate_year = record["year"]
                            candidate_lid = record["lid"]
                            
                            if candidate_title:
                                candidate_normalized = normalize_title_for_matching(candidate_title)
                                
                                # ğŸ¯ åŒ¹é…æ¡ä»¶ï¼šæ ‡é¢˜ç›¸åŒ + å¹´ä»½ç›¸åŒæˆ–ç›¸è¿‘(Â±1å¹´ï¼Œè€ƒè™‘ä¸åŒæ•°æ®æºçš„å¹´ä»½å·®å¼‚)
                                title_matches = candidate_normalized == normalized_title
                                year_matches = True  # é»˜è®¤åŒ¹é…
                                
                                if literature.metadata.year and candidate_year:
                                    try:
                                        lit_year = int(literature.metadata.year)
                                        cand_year = int(candidate_year)
                                        # å…è®¸Â±1å¹´çš„å·®å¼‚ï¼ˆè€ƒè™‘ä¼šè®®/æœŸåˆŠå‘è¡¨æ—¶é—´å·®å¼‚ï¼‰
                                        year_matches = abs(lit_year - cand_year) <= 1
                                    except (ValueError, TypeError):
                                        year_matches = True  # å¹´ä»½è§£æå¤±è´¥æ—¶ä¸ä½œä¸ºé˜»æ–­æ¡ä»¶
                                
                                if title_matches and year_matches:
                                    candidate_nodes.append({
                                        "lid": candidate_lid,
                                        "title": candidate_title,
                                        "year": candidate_year
                                    })
                                    logger.info(
                                        f"Task {task_id}: Found title match candidate: {candidate_lid} "
                                        f"(year: {candidate_year} vs {literature.metadata.year})"
                                    )
                        
                        # æ·»åŠ åŒ¹é…çš„å€™é€‰LID
                        for candidate in candidate_nodes:
                            matching_patterns.append(candidate["lid"])
                
                except Exception as e:
                    logger.warning(f"Task {task_id}: Error in title-based matching: {e}")
                    # ç»§ç»­æ‰§è¡Œï¼Œä¸å› åŒ¹é…é”™è¯¯ä¸­æ–­ä»»åŠ¡
        
        logger.info(f"Task {task_id}: Searching for unresolved nodes to upgrade: {matching_patterns}")
        
        # æ£€æŸ¥æ¯ä¸ªå¯èƒ½çš„LID
        upgraded_count = 0
        for pattern_lid in matching_patterns:
            try:
                # æ£€æŸ¥æ˜¯å¦å­˜åœ¨è¿™ä¸ªæœªè§£æèŠ‚ç‚¹
                async with relationship_dao._get_session() as session:
                    check_query = """
                    MATCH (unresolved:Unresolved {lid: $pattern_lid})
                    RETURN unresolved.lid as lid, unresolved.parsed_title as title
                    """
                    
                    result = await session.run(check_query, pattern_lid=pattern_lid)
                    record = await result.single()
                    
                    if record:
                        logger.info(f"Task {task_id}: Found matching unresolved node: {pattern_lid} -> {record['title']}")
                        
                        # æ‰§è¡Œå‡çº§
                        upgrade_stats = await relationship_dao.upgrade_unresolved_to_literature(
                            placeholder_lid=pattern_lid,
                            literature_lid=literature.lid
                        )
                        
                        if upgrade_stats.get("relationships_updated", 0) > 0:
                            upgraded_count += 1
                            logger.info(
                                f"Task {task_id}: âœ… Upgraded {pattern_lid} -> {literature.lid}, "
                                f"updated {upgrade_stats['relationships_updated']} relationships"
                            )
                        else:
                            logger.warning(
                                f"Task {task_id}: âš ï¸ Found {pattern_lid} but no relationships to upgrade"
                            )
                    
            except Exception as e:
                logger.warning(f"Task {task_id}: Error checking pattern {pattern_lid}: {e}")
                # ç»§ç»­æ£€æŸ¥å…¶ä»–æ¨¡å¼
        
        if upgraded_count > 0:
            logger.info(f"Task {task_id}: âœ… Successfully upgraded {upgraded_count} unresolved nodes to literature {literature.lid}")
        else:
            logger.info(f"Task {task_id}: No matching unresolved nodes found for literature {literature.lid}")
        
    except Exception as e:
        logger.error(f"Task {task_id}: Error in unresolved node upgrade: {e}", exc_info=True)
        # ä¸è¦å› ä¸ºå‡çº§å¤±è´¥è€Œä½¿æ•´ä¸ªä»»åŠ¡å¤±è´¥
        pass


async def _check_and_handle_post_metadata_duplicate(
    dao: "LiteratureDAO",
    identifiers: "IdentifiersModel",
    metadata: "MetadataModel",
    source_data: Dict[str, Any],
    placeholder_lid: str,
    task_id: str,
) -> Optional[str]:
    """
    Checks for duplicates after metadata is fetched and handles them.
    If a duplicate is found, it merges aliases, deletes the placeholder,
    and returns the LID of the existing literature.
    """
    logger.info(f"ğŸ•µï¸â€â™‚ï¸ [Secondary Dedup] Starting for placeholder {placeholder_lid} with title='{metadata.title}' and DOI='{identifiers.doi}'")
    
    # ğŸ” Debug: è¯¦ç»†æœç´¢ç°æœ‰æ–‡çŒ®
    try:
        # 1. æŒ‰æ ‡é¢˜æœç´¢
        candidates_debug = await dao.find_by_title_fuzzy(metadata.title, limit=10)
        logger.info(f"ğŸ” [Secondary Dedup] DEBUG - æŒ‰æ ‡é¢˜æœç´¢åˆ° {len(candidates_debug)} ä¸ªå€™é€‰æ–‡çŒ®")
        for i, cand in enumerate(candidates_debug):
            if cand and cand.metadata:
                logger.info(f"ğŸ” [Secondary Dedup] DEBUG - å€™é€‰ {i+1}: {cand.lid} - '{cand.metadata.title}' (å¹´ä»½: {getattr(cand.metadata, 'year', 'N/A')})")
        
        # 2. æŸ¥çœ‹æ•°æ®åº“ä¸­çš„æ‰€æœ‰æ–‡çŒ®ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        all_literature_debug = await dao.get_all_literature(limit=20)
        logger.info(f"ğŸ” [Secondary Dedup] DEBUG - æ•°æ®åº“ä¸­æ€»å…±æœ‰ {len(all_literature_debug)} ç¯‡æ–‡çŒ®:")
        for i, lit in enumerate(all_literature_debug):
            if lit and lit.metadata:
                logger.info(f"ğŸ” [Secondary Dedup] DEBUG - æ•°æ®åº“æ–‡çŒ® {i+1}: {lit.lid} - '{lit.metadata.title}' (å¹´ä»½: {getattr(lit.metadata, 'year', 'N/A')})")
        
        # 3. æ£€æŸ¥å½“å‰æ ‡é¢˜å’Œç¬¬ä¸€ä¸ªæ–‡çŒ®çš„åŒ¹é…æƒ…å†µï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if all_literature_debug and len(all_literature_debug) > 0:
            first_lit = all_literature_debug[0]
            if first_lit and first_lit.metadata:
                logger.info(f"ğŸ” [Secondary Dedup] DEBUG - æ¯”è¾ƒå½“å‰æ ‡é¢˜: '{metadata.title}' ä¸ç¬¬ä¸€ä¸ªæ–‡çŒ®: '{first_lit.metadata.title}'")
                # ä½¿ç”¨æ ‡é¢˜åŒ¹é…å·¥å…·è¿›è¡Œè¯¦ç»†æ¯”è¾ƒ
                from ..utils.title_matching import TitleMatchingUtils, MatchingMode
                is_match = TitleMatchingUtils.is_acceptable_match(
                    first_lit.metadata.title, metadata.title, mode=MatchingMode.STRICT
                )
                logger.info(f"ğŸ” [Secondary Dedup] DEBUG - ä¸¥æ ¼æ¨¡å¼åŒ¹é…ç»“æœ: {is_match}")
                is_match_standard = TitleMatchingUtils.is_acceptable_match(
                    first_lit.metadata.title, metadata.title, mode=MatchingMode.STANDARD
                )
                logger.info(f"ğŸ” [Secondary Dedup] DEBUG - æ ‡å‡†æ¨¡å¼åŒ¹é…ç»“æœ: {is_match_standard}")
                
    except Exception as e:
        logger.warning(f"ğŸ” [Secondary Dedup] DEBUG - æ£€æŸ¥æ—¶å‡ºé”™: {e}")
        import traceback
        logger.warning(f"ğŸ” [Secondary Dedup] DEBUG - é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
    existing_lit = None
    # 1. Check by DOI first (most reliable)
    if identifiers and identifiers.doi:
        existing_lit = await dao.find_by_doi(identifiers.doi)

    # 2. If no DOI match, check by title similarity
    if not existing_lit and metadata and metadata.title:
        # Use fuzzy search to get candidates, then a more precise similarity check
        candidates = await dao.find_by_title_fuzzy(metadata.title, limit=5)
        logger.info(f"ğŸ•µï¸â€â™‚ï¸ [Secondary Dedup] Found {len(candidates)} candidates by fuzzy title search for '{metadata.title}'")
        
        # Filter out the current placeholder to avoid self-matching
        candidates = [cand for cand in candidates if cand.lid != placeholder_lid]
        logger.info(f"ğŸ•µï¸â€â™‚ï¸ [Secondary Dedup] After filtering out placeholder {placeholder_lid}: {len(candidates)} candidates remain")
        
        # ğŸ” Debug: åˆ—å‡ºæ‰€æœ‰å€™é€‰æ–‡çŒ®è¯¦æƒ…
        for i, cand in enumerate(candidates):
            logger.info(f"ğŸ•µï¸â€â™‚ï¸ [Secondary Dedup]   Candidate {i+1}: LID={cand.lid}, Title='{cand.metadata.title if cand.metadata else 'N/A'}'")
        for cand_lit in candidates:
            if not cand_lit or not cand_lit.metadata or not cand_lit.metadata.title:
                logger.warning(f"ğŸ•µï¸â€â™‚ï¸ [Secondary Dedup] Skipping invalid candidate: {cand_lit}")
                continue
            
            logger.info(f"ğŸ•µï¸â€â™‚ï¸ [Secondary Dedup]  - Comparing with candidate {cand_lit.lid} ('{cand_lit.metadata.title}')")
            # Use a standard, balanced matching mode
            is_match = TitleMatchingUtils.is_acceptable_match(
                cand_lit.metadata.title, metadata.title, mode=MatchingMode.STANDARD
            )
            logger.info(f"ğŸ•µï¸â€â™‚ï¸ [Secondary Dedup]  - Title match result: {is_match}")
            
            if is_match:
                # As an extra precaution, check year difference for non-DOI matches
                if metadata.year and cand_lit.metadata.year:
                    try:
                        year_diff = abs(int(metadata.year) - int(cand_lit.metadata.year))
                        logger.info(f"ğŸ•µï¸â€â™‚ï¸ [Secondary Dedup]  - Year difference: {year_diff}")
                        if year_diff > 2:  # Allow up to 2 years difference
                            logger.info(f"ğŸ•µï¸â€â™‚ï¸ [Secondary Dedup]  - Year difference too large, skipping.")
                            continue  # Likely a different version, not a duplicate
                    except (ValueError, TypeError):
                        pass  # Ignore if year is not a valid integer
                
                logger.info(f"âœ… [Secondary Dedup] Match found: {cand_lit.lid}")
                existing_lit = cand_lit
                break  # Found a match
    
    if not existing_lit:
        logger.info("ğŸ•µï¸â€â™‚ï¸ [Secondary Dedup] No duplicate found after all checks.")

    # 3. If a duplicate is found, handle it
    if existing_lit and existing_lit.lid:
        logger.info(
            f"Task {task_id}: Post-metadata duplicate found! "
            f"Placeholder {placeholder_lid} matches existing {existing_lit.lid}."
        )
        
        # Add new source info as alias to the existing literature
        try:
            alias_dao = AliasDAO(database=dao.driver)
            source_aliases = extract_aliases_from_source(source_data)
            if source_aliases:
                await alias_dao.batch_create_mappings(
                    lid=existing_lit.lid,
                    mappings=source_aliases,
                    confidence=1.0,
                    metadata={"source": "post_metadata_deduplication", "task_id": task_id}
                )
                logger.info(f"Task {task_id}: Added new aliases {list(source_aliases.keys())} to existing literature {existing_lit.lid}")
        except Exception as e:
            logger.error(f"Task {task_id}: Failed to add alias to existing literature {existing_lit.lid}: {e}")

        # Delete the placeholder node that is no longer needed
        try:
            await dao.delete_literature(placeholder_lid)
            logger.info(f"Task {task_id}: Deleted placeholder literature {placeholder_lid}.")
        except Exception as e:
            logger.error(f"Task {task_id}: Failed to delete placeholder {placeholder_lid}: {e}")
            
        return existing_lit.lid

    return None


async def _process_literature_async(
    task_id: str,
    source: Dict[str, Any],
) -> Dict[str, Any]:
    """Asynchronous core logic for processing literature."""
    # Create dedicated database connection for this task
    client = None
    try:
        client, database = await create_task_connection()

        # åˆå§‹åŒ–ä»»åŠ¡çŠ¶æ€ç®¡ç†å™¨
        task_manager = TaskStatusManager(task_id)
        task_manager.update_task_progress("ä»»åŠ¡å¼€å§‹", 0)

        dao = LiteratureDAO.create_from_task_connection(database)
        
        # ğŸ†• æ™ºèƒ½è·¯ç”±ç³»ç»Ÿ - ä¸“æ³¨è·¯ç”±é€‰æ‹©å’Œæ•°æ®ç®¡é“
        url = source.get('url', '')
        
        # ğŸš€ ä¼˜åŒ–ï¼šå…ˆç”¨è½»é‡çº§æ–¹æ³•åˆ¤æ–­æ˜¯å¦èƒ½å¤„ç†ï¼Œé¿å…ä¸å¿…è¦çš„SmartRouterå®ä¾‹åŒ–
        # ä½¿ç”¨å•ä¾‹è·¯ç”±ç®¡ç†å™¨è¿›è¡Œå¿«é€Ÿåˆ¤æ–­
        from .execution.routing import RouteManager
        route_manager = RouteManager.get_instance()
        route = route_manager.determine_route(url)
        
        # ğŸ”§ ä¿®å¤ï¼šæ‰€æœ‰è·¯ç”±éƒ½åº”è¯¥èµ°æ™ºèƒ½è·¯ç”±ï¼ŒåŒ…æ‹¬standard_waterfall
        logger.info(f"ğŸš€ Task {task_id}: æ™ºèƒ½è·¯ç”±å¯åŠ¨: {url} -> {route.name}")
        smart_router = SmartRouter(dao)
        
        try:
            router_result = await smart_router.route_and_process(url, source, task_id)
            
            # æ£€æŸ¥æ™ºèƒ½è·¯ç”±ç»“æœ
            if router_result.get('status') == 'completed':
                logger.info(f"âœ… Task {task_id}: æ™ºèƒ½è·¯ç”±å®Œæˆï¼Œè€—æ—¶: {router_result.get('execution_time', 0):.2f}s")
                
                # è½¬æ¢ä¸ºæ ‡å‡†ä»»åŠ¡ç»“æœæ ¼å¼
                result_type = 'duplicate' if router_result.get('result_type') == 'duplicate' else 'created'
                final_result = task_manager.complete_task(
                    TaskResultType.DUPLICATE if result_type == 'duplicate' else TaskResultType.CREATED,
                    router_result.get('literature_id')
                )
                
                # æ·»åŠ æ™ºèƒ½è·¯ç”±çš„é¢å¤–ä¿¡æ¯
                final_result.update({
                    'route_used': router_result.get('route_used'),
                    'processor_used': router_result.get('processor_used'),
                    'execution_time': router_result.get('execution_time')
                })
                
                # ğŸ”§ æ··åˆæ¨¡å¼ï¼šæ™ºèƒ½è·¯ç”±å®Œæˆï¼Œä¸ºä¼ ç»Ÿå¼•ç”¨è§£æå‡†å¤‡å˜é‡
                if router_result.get('result_type') == 'duplicate':
                    # é‡å¤æ–‡çŒ®ç›´æ¥è¿”å›ï¼Œæ— éœ€å¼•ç”¨è§£æ
                    return final_result
                else:
                    # æ–°åˆ›å»ºçš„æ–‡çŒ®ï¼šå‡†å¤‡å˜é‡ï¼Œç»§ç»­æ‰§è¡Œä¼ ç»Ÿå¼•ç”¨è§£æ
                    logger.info(f"ğŸ”„ Task {task_id}: æ™ºèƒ½è·¯ç”±å®Œæˆï¼Œå‡†å¤‡ä¼ ç»Ÿå¼•ç”¨è§£æ")
                    
                    # ğŸ¯ ä»æ™ºèƒ½è·¯ç”±ç»“æœä¸­æå–å¿…è¦å˜é‡ç»™ä¼ ç»Ÿæµç¨‹ä½¿ç”¨
                    literature_id = router_result.get('literature_id')  # è¿™æ˜¯LID
                    
                    # ğŸ”§ å…³é”®ä¿®å¤ï¼šæå–æ™ºèƒ½è·¯ç”±ä¸­çš„åŸå§‹æ ‡è¯†ç¬¦ä¿¡æ¯
                    router_identifiers = router_result.get('identifiers')
                    
                    # ä»DAOè·å–å®Œæ•´çš„æ–‡çŒ®å¯¹è±¡
                    try:
                        literature_obj = await dao.find_by_lid(literature_id)
                        if literature_obj:
                            metadata = literature_obj.metadata
                            
                            # ğŸ”§ å…³é”®ä¿®å¤ï¼šä¿ç•™åŸå§‹æ ‡è¯†ç¬¦ä¿¡æ¯ç”¨äºå¼•ç”¨è§£æ
                            if router_identifiers:
                                # ğŸ”§ å¤„ç†æ™ºèƒ½è·¯ç”±è¿”å›çš„æ ‡è¯†ç¬¦æ ¼å¼ï¼ˆå¯èƒ½æ˜¯å­—å…¸ï¼‰
                                from literature_parser_backend.models.literature import IdentifiersModel
                                if isinstance(router_identifiers, dict):
                                    identifiers = IdentifiersModel(
                                        doi=router_identifiers.get('doi'),
                                        arxiv_id=router_identifiers.get('arxiv_id'),
                                        pmid=router_identifiers.get('pmid')
                                    )
                                    logger.info(f"ğŸ”— Task {task_id}: æ™ºèƒ½è·¯ç”±å­—å…¸æ ‡è¯†ç¬¦å·²è½¬æ¢: DOI={identifiers.doi}, ArXiv={identifiers.arxiv_id}")
                                else:
                                    identifiers = router_identifiers
                                    logger.info(f"ğŸ”— Task {task_id}: ä½¿ç”¨æ™ºèƒ½è·¯ç”±åŸå§‹æ ‡è¯†ç¬¦: DOI={identifiers.doi}, ArXiv={identifiers.arxiv_id}")
                            else:
                                # å¤‡é€‰æ–¹æ¡ˆï¼šä»å…ƒæ•°æ®ä¸­æå–
                                from literature_parser_backend.models.literature import IdentifiersModel
                                identifiers = IdentifiersModel()
                                if metadata and hasattr(metadata, 'doi') and metadata.doi:
                                    identifiers.doi = metadata.doi
                                logger.info(f"ğŸ”— Task {task_id}: å¤‡é€‰ - ä»å…ƒæ•°æ®æå–æ ‡è¯†ç¬¦: DOI={identifiers.doi}")
                            
                            # è®¾ç½®æ ‡å¿—è¡¨ç¤ºå·²å®Œæˆæ™ºèƒ½è·¯ç”±
                            smart_router_completed = True
                            smart_router_result = router_result
                            logger.info(f"ğŸ”— Task {task_id}: å‡†å¤‡å¼•ç”¨è§£æï¼Œæ–‡çŒ®: {literature_id}")
                        else:
                            logger.error(f"âŒ Task {task_id}: æ— æ³•æ‰¾åˆ°åˆšåˆ›å»ºçš„æ–‡çŒ®: {literature_id}")
                            return final_result
                    except Exception as e:
                        logger.error(f"âŒ Task {task_id}: è·å–æ–‡çŒ®å¯¹è±¡å¤±è´¥: {e}")
                        return final_result
                
            elif router_result.get('fallback_to_legacy'):
                logger.warning(f"âš ï¸ Task {task_id}: æ™ºèƒ½è·¯ç”±å»ºè®®å›é€€: {router_result.get('error')}")
                smart_router_result = router_result  # ä¿å­˜é”™è¯¯ä¿¡æ¯
                # ç»§ç»­æ‰§è¡Œä¼ ç»Ÿæµç¨‹
            else:
                logger.error(f"âŒ Task {task_id}: æ™ºèƒ½è·¯ç”±å¤±è´¥: {router_result.get('error')}")
                smart_router_result = router_result  # ä¿å­˜é”™è¯¯ä¿¡æ¯
                # ç»§ç»­æ‰§è¡Œä¼ ç»Ÿæµç¨‹
                    
        except Exception as e:
            logger.error(f"âŒ Task {task_id}: æ™ºèƒ½è·¯ç”±å¼‚å¸¸: {e}")
            smart_router_result = {'error': str(e), 'error_type': 'system_error'}  # ä¿å­˜å¼‚å¸¸ä¿¡æ¯
            # ç»§ç»­æ‰§è¡Œä¼ ç»Ÿæµç¨‹
        
        # ğŸ“‹ ä¼ ç»Ÿç€‘å¸ƒæµå¤„ç†é€»è¾‘ (ä¿æŒåŸæœ‰é€»è¾‘ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ)
        
        # ğŸ”§ åˆå§‹åŒ–æ™ºèƒ½è·¯ç”±æ ‡å¿—
        smart_router_completed = locals().get('smart_router_completed', False)
        smart_router_result = locals().get('smart_router_result', {})
        
        # ğŸ”§ æ£€æŸ¥æ™ºèƒ½è·¯ç”±æ˜¯å¦å·²å®Œæˆ
        if smart_router_completed:
            logger.info(f"ğŸš€ Task {task_id}: æ™ºèƒ½è·¯ç”±å·²å®Œæˆï¼Œè·³è½¬åˆ°å¼•ç”¨è§£æ")
            # æ™ºèƒ½è·¯ç”±å·²å®Œæˆï¼Œè·³è¿‡å»é‡å’Œå…ƒæ•°æ®è·å–ï¼Œç›´æ¥è¿›å…¥å¼•ç”¨è§£æ
            # literature_id å’Œ metadata å·²ç»åœ¨ä¸Šé¢å‡†å¤‡å¥½äº†
        else:
            logger.info(f"ğŸ”„ Task {task_id}: å¼€å§‹ä¼ ç»Ÿç€‘å¸ƒæµå¤„ç†")





        # ğŸ”§ æ™ºèƒ½è·¯ç”±å’Œä¼ ç»Ÿæµç¨‹çš„ç»Ÿä¸€å¤„ç†ç‚¹
        if 'smart_router_completed' in locals() and smart_router_completed:
            # æ™ºèƒ½è·¯ç”±å·²å®Œæˆï¼Œç›´æ¥ä½¿ç”¨å‡†å¤‡å¥½çš„å˜é‡
            logger.info(f"ğŸ¯ Task {task_id}: ä½¿ç”¨æ™ºèƒ½è·¯ç”±ç»“æœè¿›è¡Œå¼•ç”¨è§£æï¼ŒLID: {literature_id}")
            
            # ğŸ“ ä¸ºå¼•ç”¨è§£æå‡†å¤‡æ ‡è¯†ç¬¦ä¿¡æ¯
            if not 'identifiers' in locals():
                # ğŸ”§ å…³é”®ä¿®å¤ï¼šä¼˜å…ˆä½¿ç”¨åŸå§‹çš„å»é‡é˜¶æ®µæå–çš„æ ‡è¯†ç¬¦ï¼Œè€Œä¸æ˜¯åˆ›å»ºç©ºçš„
                try:
                    # å°è¯•ä»å·²å®Œæˆçš„æ™ºèƒ½è·¯ç”±ç»“æœä¸­è·å–æ ‡è¯†ç¬¦
                    if smart_router_result and 'identifiers' in smart_router_result:
                        router_identifiers_dict = smart_router_result['identifiers']
                        
                        # ğŸ”§ å…³é”®ä¿®å¤ï¼šå°†å­—å…¸æ ¼å¼è½¬æ¢ä¸ºIdentifiersModelå¯¹è±¡
                        from literature_parser_backend.models.literature import IdentifiersModel
                        if isinstance(router_identifiers_dict, dict):
                            identifiers = IdentifiersModel(
                                doi=router_identifiers_dict.get('doi'),
                                arxiv_id=router_identifiers_dict.get('arxiv_id'),
                                pmid=router_identifiers_dict.get('pmid')
                            )
                            logger.info(f"ğŸ”— Task {task_id}: æ™ºèƒ½è·¯ç”±å­—å…¸æ ¼å¼æ ‡è¯†ç¬¦å·²è½¬æ¢: DOI={identifiers.doi}, ArXiv={identifiers.arxiv_id}")
                        else:
                            # å¦‚æœå·²ç»æ˜¯IdentifiersModelå¯¹è±¡ï¼Œç›´æ¥ä½¿ç”¨
                            identifiers = router_identifiers_dict
                            logger.info(f"ğŸ”— Task {task_id}: ä½¿ç”¨æ™ºèƒ½è·¯ç”±ç»“æœä¸­çš„æ ‡è¯†ç¬¦å¯¹è±¡")
                    else:
                        # å¤‡é€‰æ–¹æ¡ˆï¼šä»å…ƒæ•°æ®ä¸­æå–æ ‡è¯†ç¬¦ä¿¡æ¯
                        from literature_parser_backend.models.literature import IdentifiersModel
                        identifiers = IdentifiersModel()
                        if metadata:
                            if hasattr(metadata, 'doi') and metadata.doi:
                                identifiers.doi = metadata.doi
                                logger.info(f"ğŸ”§ Task {task_id}: ä»metadataä¸­æå–DOI: {metadata.doi}")
                            if hasattr(metadata, 'external_ids') and metadata.external_ids:
                                if 'ArXiv' in metadata.external_ids:
                                    identifiers.arxiv_id = metadata.external_ids['ArXiv']
                                    logger.info(f"ğŸ”§ Task {task_id}: ä»metadataä¸­æå–ArXiv ID: {metadata.external_ids['ArXiv']}")
                                if 'DOI' in metadata.external_ids and not identifiers.doi:
                                    identifiers.doi = metadata.external_ids['DOI']
                                    logger.info(f"ğŸ”§ Task {task_id}: ä»external_idsä¸­æå–DOI: {metadata.external_ids['DOI']}")
                        logger.info(f"ğŸ”— Task {task_id}: å¤‡é€‰æ–¹æ¡ˆ - ä»å…ƒæ•°æ®å‡†å¤‡æ ‡è¯†ç¬¦")
                except Exception as e:
                    logger.error(f"âš ï¸ Task {task_id}: æ ‡è¯†ç¬¦æå–å¤±è´¥: {e}")
                    # æœ€åçš„å¤‡é€‰æ–¹æ¡ˆï¼šåˆ›å»ºç©ºçš„æ ‡è¯†ç¬¦
                    from literature_parser_backend.models.literature import IdentifiersModel
                    identifiers = IdentifiersModel()
                
                logger.info(f"ğŸ”— Task {task_id}: æœ€ç»ˆæ ‡è¯†ç¬¦å‡†å¤‡å®Œæˆ: DOI={identifiers.doi}, ArXiv={identifiers.arxiv_id}")
            
            # ğŸš¨ å…³é”®ä¿®å¤ï¼šè®¾ç½®å…ƒæ•°æ®ç»„ä»¶çŠ¶æ€ä¸º successï¼Œç¡®ä¿å¼•ç”¨è§£æä¾èµ–æ£€æŸ¥é€šè¿‡
            logger.info(f"ğŸ”§ Task {task_id}: ä¸ºæ™ºèƒ½è·¯ç”±è®¾ç½®å…ƒæ•°æ®ç»„ä»¶çŠ¶æ€ä¸º success")
            await dao.update_enhanced_component_status(
                literature_id=literature_id,
                component="metadata",
                status="success",
                stage="æ™ºèƒ½è·¯ç”±å…ƒæ•°æ®è·å–æˆåŠŸ",
                progress=100,
                source="SmartRouter",
                next_action=None,
            )
            
            # ğŸ” å…ƒæ•°æ®è§£æå®Œæˆåçš„é‡å¤æ£€æŸ¥
            logger.info(f"ğŸ” Task {task_id}: å¼€å§‹å…ƒæ•°æ®è§£æåçš„é‡å¤æ£€æŸ¥")
            existing_lit_lid = await _check_and_handle_post_metadata_duplicate(
                dao=dao,
                identifiers=identifiers,
                metadata=metadata,
                source_data=source,
                placeholder_lid=literature_id,
                task_id=task_id
            )
            
            if existing_lit_lid:
                logger.info(f"âœ… Task {task_id}: å‘ç°é‡å¤æ–‡çŒ® {existing_lit_lid}ï¼Œåœæ­¢å¤„ç†å¹¶è¿”å›å·²æœ‰æ–‡çŒ®")
                return task_manager.complete_task(TaskResultType.DUPLICATE, existing_lit_lid)
            
            logger.info(f"âœ… Task {task_id}: æ— é‡å¤æ–‡çŒ®ï¼Œç»§ç»­å¤„ç†æµç¨‹")
        else:
            # ä¼ ç»Ÿæµç¨‹éœ€è¦åˆå§‹åŒ–å˜é‡ï¼ˆå¦‚æœä¼ ç»Ÿæµç¨‹è¢«å¯ç”¨çš„è¯ï¼‰
            logger.warning(f"âš ï¸ Task {task_id}: æ™ºèƒ½è·¯ç”±æœªå®Œæˆï¼Œä½†ä¼ ç»Ÿæµç¨‹è¢«æ³¨é‡Š")
            logger.warning(f"âš ï¸ Task {task_id}: è·³è¿‡å¼•ç”¨è§£æï¼Œå› ä¸ºç¼ºå°‘å¿…è¦çš„ literature_id")
            
            # ğŸ”„ æ ¹æ®æ™ºèƒ½è·¯ç”±çš„é”™è¯¯ç±»å‹è¿”å›ç›¸åº”çš„TaskResultType
            router_error_type = smart_router_result.get('error_type') if 'smart_router_result' in locals() else None
            
            if router_error_type == "url_not_found":
                result_type = TaskResultType.URL_NOT_FOUND
            elif router_error_type == "url_access_failed":
                result_type = TaskResultType.URL_ACCESS_FAILED
            else:
                result_type = TaskResultType.PARSING_FAILED
            
            logger.info(f"ğŸ”„ Task {task_id}: è¿”å›é”™è¯¯ç±»å‹ {result_type} (åŸºäº {router_error_type})")
            return task_manager.complete_task(result_type, None)
        
        # 4. Fetch References (Critical Component) - ä¼˜å…ˆå¤„ç†å…³é”®ç»„ä»¶
        update_task_status("è·å–å‚è€ƒæ–‡çŒ®", progress=40)

        # Initialize references variable to avoid UnboundLocalError
        references = []
        references_source = "æœªçŸ¥æ¥æº"

        # Check dependencies before proceeding
        deps_met = await dao.check_component_dependencies(literature_id, "references")
        if not deps_met:
            await dao.update_enhanced_component_status(
                literature_id=literature_id,
                component="references",
                status="waiting",
                stage="ç­‰å¾…ä¾èµ–å®Œæˆ",
                progress=0,
                dependencies_met=False,
                next_action="ç­‰å¾…å…ƒæ•°æ®è·å–å®Œæˆ",
            )
            logger.info("References fetch waiting for dependencies")
        else:
            await dao.update_enhanced_component_status(
                literature_id=literature_id,
                component="references",
                status="processing",
                stage="æ­£åœ¨è·å–å‚è€ƒæ–‡çŒ®",
                progress=0,
                dependencies_met=True,
                next_action="å°è¯•ä»å¤–éƒ¨APIè·å–å‚è€ƒæ–‡çŒ®",
            )

            references_fetcher = ReferencesFetcher()
            references_result = references_fetcher.fetch_references_waterfall(
                identifiers=identifiers.model_dump(),
                pdf_content=None, # PDF content is handled later
            )

            # Handle result tuple safely
            if isinstance(references_result, tuple) and len(references_result) == 2:
                references, references_raw = references_result
                references_source = references_raw.get("source", "æœªçŸ¥æ¥æº")
            else:
                references = references_result
                references_source = "æœªçŸ¥æ¥æº"

            # Check if references fetch was actually successful with improved logic
            if references and len(references) > 0:
                overall_status = await dao.update_enhanced_component_status(
                    literature_id=literature_id,
                    component="references",
                    status="success",
                    stage="å‚è€ƒæ–‡çŒ®è·å–æˆåŠŸ",
                    progress=100,
                    source=references_source or "æœªçŸ¥æ¥æº",
                    next_action=None,
                )
                logger.info(
                    f"References fetch successful ({len(references)} refs) from {references_source}. Overall status: {overall_status}",
                )
                
                # ğŸ¯ NEW: Citation Relationship Resolution
                logger.info(f"Task {task_id}: Starting citation relationship resolution")
                try:
                    from literature_parser_backend.worker.citation_resolver import CitationResolver
                    
                    # Initialize citation resolver
                    citation_resolver = CitationResolver(task_id=task_id)
                    await citation_resolver.initialize_with_dao(dao)
                    
                    # Resolve citations and create relationships
                    resolution_result = await citation_resolver.resolve_citations_for_literature(
                        citing_literature_lid=literature_id,
                        references=references
                    )
                    
                    stats = resolution_result["statistics"]
                    logger.info(f"Task {task_id}: Citation resolution completed - {stats['resolved_citations']} resolved, {stats['unresolved_references']} unresolved (rate: {stats['resolution_rate']:.2f})")
                    
                except Exception as e:
                    logger.error(f"Task {task_id}: Citation resolution failed: {e}")
                    # Don't fail the entire task for citation resolution errors
                    # This is a enhancement feature, not critical
            else:
                # Note: References failure is now critical
                error_info = {
                    "error_type": "ReferencesFetchError",
                    "error_message": "No references found or extraction failed",
                    "error_details": {
                        "attempted_sources": ["Semantic Scholar", "GROBID"],
                    },
                }
                overall_status = await dao.update_enhanced_component_status(
                    literature_id=literature_id,
                    component="references",
                    status="failed",
                    stage="å‚è€ƒæ–‡çŒ®è·å–å¤±è´¥",
                    progress=0,
                    error_info=error_info,
                    next_action="è€ƒè™‘æ‰‹åŠ¨è¾“å…¥å‚è€ƒæ–‡çŒ®",
                )
                logger.warning(f"References fetch failed. Overall status: {overall_status}")

        # ğŸš€ æ¶æ„é‡æ„ï¼šå®Œå…¨è·³è¿‡å†…å®¹è·å–ï¼Œä¸“æ³¨æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•
        # 6. ç«‹å³å®Œæˆæ ¸å¿ƒä»»åŠ¡ - ä¿å­˜å…ƒæ•°æ®ã€å¼•ç”¨ã€å…³ç³»æ•°æ®
        update_task_status("å®Œæˆæ ¸å¿ƒä»»åŠ¡", progress=70)
        logger.info(f"Task {task_id}: âš¡ è·³è¿‡å†…å®¹è·å–ï¼Œç›´æ¥å®Œæˆæ ¸å¿ƒæ•°æ®å¤„ç†")

        from datetime import datetime
        from ..models.literature import TaskInfoModel

        # Sync and get final overall status using smart status management (without content component)
        final_overall_status = await dao.sync_task_status(literature_id)
        logger.info(f"Core task synchronized status: {final_overall_status}")

        # Get current task_info from placeholder to preserve component statuses
        current_literature = await dao.find_by_lid(literature_id)
        if current_literature and current_literature.task_info:
            # Preserve the existing task_info with all component statuses
            task_info = current_literature.task_info
            # Update final status and completion time
            task_info.status = final_overall_status
            task_info.completed_at = datetime.now()
        else:
            # Fallback: create new task info (should not happen in normal flow)
            task_info = TaskInfoModel(
                task_id=task_id,
                status=final_overall_status,
                created_at=datetime.now(),
                completed_at=datetime.now(),
                error_message=None,
            )
            logger.warning(f"Could not find existing task_info for {literature_id}, created new one")

        # Ensure metadata is not None
        if metadata is None:
            from ..models.literature import MetadataModel

            metadata = MetadataModel(
                title="Unknown Title",
                authors=[],
                year=None,
                journal=None,
                abstract=None,
            )

        # Generate Literature ID (LID) from metadata
        lid_generator = LIDGenerator()
        generated_lid = lid_generator.generate_lid(metadata)
        
        # ğŸš€ åˆ›å»ºæ–‡çŒ®å¯¹è±¡ - ä½¿ç”¨ç©ºçš„ContentModelï¼ŒPDFå†…å®¹å°†åœ¨åå°å¤„ç†
        from ..models.literature import ContentModel
        literature = LiteratureModel(
            user_id=None,  # Optional field for user association
            lid=generated_lid,  # Add the generated LID
            task_info=task_info,
            identifiers=identifiers,
            metadata=metadata,
            content=ContentModel(),  # ç©ºçš„ContentModelï¼ŒPDFå°†åœ¨åå°å¼‚æ­¥å¡«å……
            references=references,
        )

        await dao.finalize_literature(literature_id, literature)
        logger.info(f"Task {task_id}: âœ… æ ¸å¿ƒæ–‡çŒ®æ•°æ®å·²ä¿å­˜ (LID: {literature.lid})")
        
        # Record alias mappings for the newly created literature
        task_manager.update_task_progress("è®°å½•åˆ«åæ˜ å°„", 85, literature_id)
        await _record_alias_mappings(literature, source, dao, task_id)
        
        # ğŸ†• æ£€æŸ¥å¹¶å‡çº§åŒ¹é…çš„æœªè§£æèŠ‚ç‚¹
        task_manager.update_task_progress("å‡çº§æœªè§£æèŠ‚ç‚¹", 90, literature_id)
        await _upgrade_matching_unresolved_nodes(literature, dao, task_id)
        
        # ğŸ¯ å…ˆè¿”å›æ ¸å¿ƒä»»åŠ¡å®ŒæˆçŠ¶æ€ï¼Œè®©ç”¨æˆ·ç«‹å³çœ‹åˆ°ç»“æœ
        task_manager.update_task_progress("æ ¸å¿ƒä»»åŠ¡å®Œæˆ", 95, literature_id)
        logger.info(f"Task {task_id}: âœ… æ ¸å¿ƒä»»åŠ¡å·²å®Œæˆï¼Œç”¨æˆ·å¯æŸ¥çœ‹å…ƒæ•°æ®å’Œå¼•ç”¨å…³ç³»")
        
        # ğŸš« å®Œå…¨è·³è¿‡å†…å®¹è·å– - ä¸“æ³¨æµ‹è¯•æ ¸å¿ƒåŠŸèƒ½
        logger.info(f"Task {task_id}: ğŸš« å†…å®¹è·å–å·²ç¦ç”¨ï¼Œä¸“æ³¨æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•")
        
        task_manager.update_task_progress("å¤„ç†å®Œæˆ", 100, literature_id)
        
        # ğŸ›¡ï¸ æ£€æŸ¥æ˜¯å¦æ˜¯è§£æå¤±è´¥çš„æ–‡çŒ®ï¼Œå¦‚æœæ˜¯åˆ™è¿”å›ç‰¹æ®ŠçŠ¶æ€
        is_parsing_failed = False
        if metadata and metadata.title:
            failed_title_indicators = [
                "Unknown Title",
                "Processing...",
                "Extracting...",
                "Loading...",
                "Error:",
                "N/A",
                "Parsing Failed"
            ]
            is_parsing_failed = any(indicator in metadata.title for indicator in failed_title_indicators)
        
        # ğŸ”§ æ™ºèƒ½è·¯ç”±å’Œä¼ ç»Ÿæµç¨‹çš„ç»Ÿä¸€è¿”å›
        if 'smart_router_completed' in locals() and smart_router_completed:
            # æ™ºèƒ½è·¯ç”±å®Œæˆï¼Œåˆå¹¶ç»“æœ
            # ğŸ¯ åŸºäºå®é™…ç»„ä»¶çŠ¶æ€åˆ¤æ–­ç»“æœç±»å‹ï¼Œè€Œä¸æ˜¯æ ‡é¢˜æ£€æŸ¥
            if final_overall_status == "completed":
                result_type = TaskResultType.CREATED
            elif final_overall_status in ["partial_completed", "processing"]:
                result_type = TaskResultType.CREATED  # éƒ¨åˆ†æˆåŠŸä¹Ÿç®—åˆ›å»ºæˆåŠŸ
            else:  # failed
                result_type = TaskResultType.PARSING_FAILED
            
            logger.info(f"âœ… Task {task_id}: æ™ºèƒ½è·¯ç”±+å¼•ç”¨è§£æå®Œæˆ (çŠ¶æ€: {final_overall_status} -> {result_type})")
            final_result = task_manager.complete_task(result_type, literature_id)
            
            # æ·»åŠ æ™ºèƒ½è·¯ç”±çš„é¢å¤–ä¿¡æ¯
            final_result.update({
                'route_used': smart_router_result.get('route_used'),
                'processor_used': smart_router_result.get('processor_used'),
                'smart_router_time': smart_router_result.get('execution_time'),
                'references_count': len(references) if 'references' in locals() else 0,
                'mode': 'smart_router_with_references',
                'is_parsing_failed': is_parsing_failed
            })
            return final_result
        else:
            # çº¯ä¼ ç»Ÿæµç¨‹
            # ğŸ¯ åŸºäºå®é™…ç»„ä»¶çŠ¶æ€åˆ¤æ–­ç»“æœç±»å‹ï¼Œè€Œä¸æ˜¯æ ‡é¢˜æ£€æŸ¥
            if final_overall_status == "completed":
                result_type = TaskResultType.CREATED
            elif final_overall_status in ["partial_completed", "processing"]:
                result_type = TaskResultType.CREATED  # éƒ¨åˆ†æˆåŠŸä¹Ÿç®—åˆ›å»ºæˆåŠŸ
            else:  # failed
                result_type = TaskResultType.PARSING_FAILED
            
            logger.info(f"âœ… Task {task_id}: ä¼ ç»Ÿæµç¨‹å®Œæˆ (çŠ¶æ€: {final_overall_status} -> {result_type})")
            # Return LID instead of MongoDB ObjectId for API consistency
            final_result = task_manager.complete_task(result_type, literature.lid or literature_id)
            final_result['is_parsing_failed'] = (result_type == TaskResultType.PARSING_FAILED)
            return final_result


    except Exception as e:
        logger.error(f"Task {task_id} failed: {e}", exc_info=True)
        if 'task_manager' in locals():
            task_manager.update_task_progress("å¤„ç†å¤±è´¥", 100, locals().get('literature_id'))
            return task_manager.fail_task(str(e), locals().get('literature_id'))
        else:
            # å¦‚æœtask_managerè¿˜æ²¡åˆ›å»ºï¼Œç›´æ¥æŠ›å‡ºå¼‚å¸¸
            raise
    finally:
        # Always close the task connection
        if client:
            await close_task_connection(client)


@celery_app.task(bind=True, name="process_literature_task")
def process_literature_task(self: Task, source: Dict[str, Any]) -> Dict[str, Any]:
    """Celery task entry point for literature processing."""
    try:
        # ğŸ” DEBUG: Check what data Worker receives from API
        logger.info("ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢")
        logger.info(f"ğŸ“‹ [WORKER] ğŸš€ã€ä»»åŠ¡æ—¥å¿—å¼€å§‹ã€‘Task {self.request.id} received source data:")
        logger.info(f"ğŸ“‹ [WORKER] Source keys: {list(source.keys()) if source else 'None'}")
        logger.info(f"ğŸ“‹ [WORKER] Source data: {source}")
        logger.info("ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢ğŸŸ¢")
        
        # Check specific identifiers field
        if 'identifiers' in source:
            logger.info(f"ğŸ“‹ [WORKER] Identifiers field: {source['identifiers']}")
        else:
            logger.info(f"ğŸ“‹ [WORKER] âŒ No 'identifiers' field in source data!")
            
        # Important: run the async function and get the dictionary result
        result_dict = asyncio.run(_process_literature_async(self.request.id, source))
        return result_dict
    except Exception as e:
        # å¯¼å…¥è‡ªå®šä¹‰å¼‚å¸¸ç±»å‹å’Œç»“æœç±»å‹
        from .execution.exceptions import URLNotFoundException, URLAccessFailedException, ParsingFailedException
        from ..models.task import TaskResultType
        
        logger.error(f"Task {self.request.id} failed: {e}", exc_info=True)
        
        # æ ¹æ®å¼‚å¸¸ç±»å‹è¿”å›ä¸åŒçš„ç»“æœç±»å‹
        if isinstance(e, URLNotFoundException):
            return {
                "result_type": TaskResultType.URL_NOT_FOUND.value,
                "error_message": str(e),
                "literature_id": None
            }
        elif isinstance(e, URLAccessFailedException):
            return {
                "result_type": TaskResultType.URL_ACCESS_FAILED.value,
                "error_message": str(e),
                "literature_id": None
            }
        elif isinstance(e, ParsingFailedException):
            return {
                "result_type": TaskResultType.PARSING_FAILED.value,
                "error_message": str(e),
                "literature_id": None
            }
        else:
            # å…¶ä»–æœªçŸ¥å¼‚å¸¸ï¼Œæ ‡è®°ä¸ºä»»åŠ¡å¤±è´¥
            update_task_status("å¤„ç†å¤±è´¥", progress=100)
            self.update_state(
                state="FAILURE",
                meta={"error": str(e), "exc_type": type(e).__name__},
            )
            return {
                "status": "FAILURE",
                "error": str(e),
                "exc_type": type(e).__name__,
            }

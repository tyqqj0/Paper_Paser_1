#!/usr/bin/env python3
"""
æµ‹è¯•é›†æˆçš„å»é‡é€»è¾‘ï¼Œæ£€æŸ¥ä¿®å¤åçš„æ ‡é¢˜å’Œä½œè€…åŒ¹é…æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import asyncio
import sys
import os
import json

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from literature_parser_backend.worker.execution.data_pipeline import DataPipeline
from literature_parser_backend.db.dao import LiteratureDAO
from literature_parser_backend.models.literature import MetadataModel

async def test_deduplication():
    """æµ‹è¯•å»é‡é€»è¾‘"""
    print("=" * 60)
    print("æµ‹è¯•é›†æˆå»é‡é€»è¾‘")
    print("=" * 60)
    
    # åˆ›å»ºæ•°æ®ç®¡é“å®ä¾‹
    dao = LiteratureDAO()
    pipeline = DataPipeline(dao)
    
    # æ¨¡æ‹Ÿç¬¬ä¸€ç¯‡è®ºæ–‡çš„å…ƒæ•°æ®ï¼ˆå·²å­˜åœ¨äºæ•°æ®åº“ä¸­ï¼‰
    metadata1 = MetadataModel(
        title="Attention Is All You Need",
        authors=[
            {"name": "Ashish Vaswani"},
            {"name": "Noam Shazeer"},
            {"name": "Niki Parmar"},
            {"name": "Jakob Uszkoreit"},
            {"name": "Llion Jones"}
        ],
        year=2017,
        journal="NIPS"
    )
    
    # æ¨¡æ‹Ÿç¬¬äºŒç¯‡è®ºæ–‡çš„å…ƒæ•°æ®ï¼ˆä¸åŒæ ¼å¼çš„ç›¸åŒè®ºæ–‡ï¼‰
    metadata2 = MetadataModel(
        title="Attention is All you Need",  # å¾®å°çš„å¤§å°å†™å·®å¼‚
        authors=[
            {"name": "Vaswani, Ashish"},  # "å§“, å" æ ¼å¼
            {"name": "Shazeer, Noam"},
            {"name": "Parmar, Niki"},
            {"name": "Uszkoreit, Jakob"},
            {"name": "Jones, Llion"}
        ],
        year=2017,
        journal="NIPS"
    )
    
    print("\nğŸ“‹ æµ‹è¯•æ•°æ®:")
    print("-" * 40)
    print(f"æ–‡çŒ®1 æ ‡é¢˜: {metadata1.title}")
    print(f"æ–‡çŒ®1 ä½œè€…: {[author['name'] for author in metadata1.authors]}")
    print(f"æ–‡çŒ®2 æ ‡é¢˜: {metadata2.title}")
    print(f"æ–‡çŒ®2 ä½œè€…: {[author['name'] for author in metadata2.authors]}")
    
    try:
        # æµ‹è¯•å»é‡æ£€æŸ¥
        print("\nğŸ” æ‰§è¡Œå»é‡æ£€æŸ¥:")
        print("-" * 40)
        
        result = await pipeline._check_duplicate_literature(metadata2)
        
        print(f"\nğŸ¯ å»é‡æ£€æŸ¥ç»“æœ:")
        print("-" * 40)
        print(f"æ˜¯å¦é‡å¤: {result.get('is_duplicate', False)}")
        
        if result.get('is_duplicate'):
            print(f"å·²å­˜åœ¨ LID: {result.get('existing_lid')}")
            print(f"é‡å¤åŸå› : {result.get('reason')}")
            print("âœ… æˆåŠŸæ£€æµ‹åˆ°é‡å¤æ–‡çŒ®!")
        else:
            print("âŒ æœªæ£€æµ‹åˆ°é‡å¤ï¼Œå¯èƒ½å­˜åœ¨é—®é¢˜")
            
        # é¢å¤–æµ‹è¯•ï¼šç›´æ¥æµ‹è¯•æ ‡é¢˜å’Œä½œè€…åŒ¹é…
        print(f"\nğŸ”§ è¯¦ç»†åŒ¹é…æµ‹è¯•:")
        print("-" * 40)
        
        title_match = pipeline._is_title_match(metadata1.title, metadata2.title)
        print(f"æ ‡é¢˜åŒ¹é…: {'âœ…' if title_match else 'âŒ'}")
        
        author_match = pipeline._is_author_match(metadata1.authors, metadata2.authors)
        print(f"ä½œè€…åŒ¹é…: {'âœ…' if author_match else 'âŒ'}")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()

async def test_fuzzy_search():
    """æµ‹è¯•æ¨¡ç³Šæœç´¢åŠŸèƒ½"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•æ¨¡ç³Šæœç´¢åŠŸèƒ½")
    print("=" * 60)
    
    dao = LiteratureDAO()
    
    try:
        # æµ‹è¯•ä¸åŒçš„æ ‡é¢˜å˜ä½“
        test_titles = [
            "Attention Is All You Need",
            "Attention is All you Need", 
            "attention is all you need",
            "ATTENTION IS ALL YOU NEED"
        ]
        
        for title in test_titles:
            print(f"\nğŸ” æœç´¢æ ‡é¢˜: {title}")
            results = await dao.find_by_title_fuzzy(title, limit=3)
            print(f"æ‰¾åˆ° {len(results)} ä¸ªç»“æœ:")
            
            for result in results:
                if result and result.metadata:
                    print(f"  - LID: {result.lid}")
                    print(f"    æ ‡é¢˜: {result.metadata.title}")
                    if hasattr(result.metadata, 'authors') and result.metadata.authors:
                        authors = [author.get('name', '') if isinstance(author, dict) else str(author) 
                                 for author in result.metadata.authors[:3]]
                        print(f"    ä½œè€…: {', '.join(authors)}...")
                    print()
            
    except Exception as e:
        print(f"âŒ æœç´¢æµ‹è¯•å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    await test_deduplication()
    await test_fuzzy_search()
    
    print("\n" + "=" * 60)
    print("æµ‹è¯•å®Œæˆ")
    print("=" * 60)

if __name__ == "__main__":
    asyncio.run(main())

#!/usr/bin/env python3
"""
æµ‹è¯•å…ƒæ•°æ®è§£æåçš„è‡ªåŠ¨æŸ¥é‡åŠŸèƒ½

éªŒè¯åœºæ™¯ï¼š
1. æäº¤ä¸€ä¸ªæ–‡çŒ®è¿›è¡Œå¤„ç†
2. åœ¨å…ƒæ•°æ®è§£æå®Œæˆåï¼Œå†æ¬¡æäº¤ç›¸åŒçš„æ–‡çŒ®
3. éªŒè¯ç¬¬äºŒæ¬¡æäº¤èƒ½å¤Ÿæ­£ç¡®æ£€æµ‹é‡å¤å¹¶è¿”å›å·²æœ‰æ–‡çŒ®ï¼Œè€Œä¸æ˜¯åˆ›å»ºæ–°èŠ‚ç‚¹
"""

import asyncio
import json
import time
from literature_parser_backend.worker.tasks import process_literature_task

async def test_post_metadata_deduplication():
    print("=" * 80)
    print("æµ‹è¯•å…ƒæ•°æ®è§£æåçš„è‡ªåŠ¨æŸ¥é‡åŠŸèƒ½")
    print("=" * 80)
    
    # æµ‹è¯•ç”¨çš„DOI
    test_doi = "10.1145/3485447.3512256"
    
    print(f"ğŸ§ª æµ‹è¯•DOI: {test_doi}")
    
    # ç¬¬ä¸€æ¬¡æäº¤
    print("\nğŸ“‹ ç¬¬ä¸€æ¬¡æäº¤æ–‡çŒ®...")
    task_data_1 = {
        "identifiers": {"doi": test_doi},
        "title": "First submission"
    }
    
    task_1 = process_literature_task.delay(task_data_1)
    print(f"âœ… ç¬¬ä¸€ä¸ªä»»åŠ¡å·²æäº¤: {task_1.id}")
    
    # ç­‰å¾…ä¸€æ®µæ—¶é—´è®©å…ƒæ•°æ®å¤„ç†å®Œæˆï¼ˆä½†ä¸è¦ç­‰åˆ°å®Œå…¨å®Œæˆï¼‰
    print("â³ ç­‰å¾…å…ƒæ•°æ®å¤„ç†å®Œæˆ...")
    await asyncio.sleep(15)  # ç­‰å¾…15ç§’ï¼Œè¶³å¤Ÿå…ƒæ•°æ®å¤„ç†å®Œæˆ
    
    # ç¬¬äºŒæ¬¡æäº¤ç›¸åŒçš„æ–‡çŒ®
    print(f"\nğŸ“‹ ç¬¬äºŒæ¬¡æäº¤ç›¸åŒæ–‡çŒ®ï¼ˆDOI: {test_doi}ï¼‰...")
    task_data_2 = {
        "identifiers": {"doi": test_doi},
        "title": "Second submission (should be detected as duplicate)"
    }
    
    task_2 = process_literature_task.delay(task_data_2)
    print(f"âœ… ç¬¬äºŒä¸ªä»»åŠ¡å·²æäº¤: {task_2.id}")
    
    # ç­‰å¾…ç¬¬äºŒä¸ªä»»åŠ¡å®Œæˆ
    print("â³ ç­‰å¾…ç¬¬äºŒä¸ªä»»åŠ¡å®Œæˆ...")
    result_2 = task_2.get(timeout=60)
    
    print(f"\nğŸ“Š ç¬¬äºŒä¸ªä»»åŠ¡ç»“æœ:")
    print(json.dumps(result_2, indent=2, ensure_ascii=False))
    
    # éªŒè¯ç»“æœ
    if result_2.get("result_type") == "duplicate":
        print("âœ… æˆåŠŸï¼ç¬¬äºŒæ¬¡æäº¤è¢«æ­£ç¡®è¯†åˆ«ä¸ºé‡å¤")
        print(f"ğŸ”— è¿”å›çš„å·²æœ‰æ–‡çŒ®ID: {result_2.get('literature_id')}")
    elif result_2.get("result_type") == "created":
        print("âŒ å¤±è´¥ï¼ç¬¬äºŒæ¬¡æäº¤è¢«é”™è¯¯åœ°åˆ›å»ºä¸ºæ–°æ–‡çŒ®")
        print(f"âš ï¸  åˆ›å»ºçš„æ–°æ–‡çŒ®ID: {result_2.get('literature_id')}")
    else:
        print(f"â“ æœªçŸ¥ç»“æœç±»å‹: {result_2.get('result_type')}")
    
    # ç­‰å¾…ç¬¬ä¸€ä¸ªä»»åŠ¡ä¹Ÿå®Œæˆ
    print("\nâ³ ç­‰å¾…ç¬¬ä¸€ä¸ªä»»åŠ¡å®Œæˆ...")
    try:
        result_1 = task_1.get(timeout=120)
        print(f"\nğŸ“Š ç¬¬ä¸€ä¸ªä»»åŠ¡ç»“æœ:")
        print(json.dumps(result_1, indent=2, ensure_ascii=False))
    except Exception as e:
        print(f"âš ï¸  ç¬¬ä¸€ä¸ªä»»åŠ¡å¯èƒ½ä»åœ¨è¿è¡Œæˆ–å¤±è´¥: {e}")
    
    print("\n" + "=" * 80)
    print("æµ‹è¯•å®Œæˆ")
    print("=" * 80)

if __name__ == "__main__":
    asyncio.run(test_post_metadata_deduplication())

#!/usr/bin/env python3
"""
åˆ†ææ•°æ®åº“ä¸­çš„é‡å¤è®ºæ–‡é—®é¢˜
"""

import asyncio
import json
from literature_parser_backend.db.relationship_dao import RelationshipDAO
from literature_parser_backend.db.neo4j import connect_to_neo4j
from literature_parser_backend.settings import Settings

# å·²çŸ¥çš„é‡å¤è®ºæ–‡LID
KNOWN_DUPLICATES = [
    "2017-ashish-aayn-fa59",   # Attention is All you Need
    "2017-vaswani-aayn-9572",  # Attention Is All You Need
]

async def analyze_duplicate_papers():
    """è¯¦ç»†åˆ†æé‡å¤è®ºæ–‡çš„å…ƒæ•°æ®"""
    
    # åˆå§‹åŒ–è¿æ¥
    settings = Settings()
    await connect_to_neo4j(settings)
    
    # åˆå§‹åŒ–DAO
    relationship_dao = RelationshipDAO.create_from_global_connection()
    
    try:
        print("ğŸ“Š åˆ†æé‡å¤è®ºæ–‡è¯¦ç»†ä¿¡æ¯")
        print("=" * 80)
        
        for i, lid in enumerate(KNOWN_DUPLICATES, 1):
            print(f"\n{i}. åˆ†æ LID: {lid}")
            print("-" * 50)
            
            # æŸ¥è¯¢å®Œæ•´çš„èŠ‚ç‚¹ä¿¡æ¯
            query = """
            MATCH (n:Literature {lid: $lid})
            RETURN n.lid as lid, 
                   n.title as title,
                   n.metadata as metadata,
                   n.doi as doi,
                   n.type as type,
                   n.created_at as created_at,
                   n.updated_at as updated_at
            """
            
            result = await relationship_dao._execute_cypher(query, {"lid": lid})
            
            if result:
                record = result[0]
                print(f"ğŸ“„ æ ‡é¢˜: {record['title']}")
                print(f"ğŸ†” LID: {record['lid']}")
                print(f"ğŸ“– DOI: {record['doi']}")
                print(f"ğŸ“‚ ç±»å‹: {record['type']}")
                print(f"ğŸ“… åˆ›å»ºæ—¶é—´: {record['created_at']}")
                print(f"ğŸ”„ æ›´æ–°æ—¶é—´: {record['updated_at']}")
                
                # è§£æå…ƒæ•°æ®
                metadata = relationship_dao._parse_json_field(record['metadata'])
                if metadata:
                    print(f"ğŸ‘¥ ä½œè€…: {metadata.get('authors', 'N/A')}")
                    print(f"ğŸ“† å¹´ä»½: {metadata.get('year', 'N/A')}")
                    print(f"ğŸ“° æœŸåˆŠ: {metadata.get('journal', 'N/A')}")
                    print(f"ğŸ›ï¸ å‡ºç‰ˆå•†: {metadata.get('publisher', 'N/A')}")
                    print(f"ğŸ“ æ‘˜è¦é•¿åº¦: {len(str(metadata.get('abstract', '')))}")
                    
                    # æ˜¾ç¤ºå®Œæ•´çš„å…ƒæ•°æ®ç»“æ„
                    print(f"ğŸ” å®Œæ•´å…ƒæ•°æ®:")
                    print(json.dumps(metadata, indent=2, ensure_ascii=False))
                else:
                    print("âš ï¸ æ— æ³•è§£æå…ƒæ•°æ®")
            else:
                print(f"âŒ æœªæ‰¾åˆ° LID: {lid}")
        
        # æŸ¥æ‰¾æ›´å¤šæ½œåœ¨çš„é‡å¤é¡¹
        print(f"\n\nğŸ” å¯»æ‰¾å…¶ä»–æ½œåœ¨é‡å¤é¡¹...")
        print("=" * 80)
        
        # æŒ‰æ ‡é¢˜ç›¸ä¼¼æ€§æŸ¥æ‰¾æ½œåœ¨é‡å¤
        similar_titles_query = """
        MATCH (n:Literature)
        WITH n.title as title, collect(n) as nodes
        WHERE size(nodes) > 1
        RETURN title, [node in nodes | node.lid] as lids, size(nodes) as count
        ORDER BY count DESC
        """
        
        similar_results = await relationship_dao._execute_cypher(similar_titles_query)
        
        if similar_results:
            print(f"ğŸ“Š æ‰¾åˆ° {len(similar_results)} ç»„ç›¸åŒæ ‡é¢˜çš„è®ºæ–‡:")
            for i, record in enumerate(similar_results, 1):
                print(f"{i}. æ ‡é¢˜: {record['title']}")
                print(f"   LIDs: {record['lids']}")
                print(f"   æ•°é‡: {record['count']}")
                print()
        else:
            print("âœ… æœªå‘ç°å®Œå…¨ç›¸åŒæ ‡é¢˜çš„é‡å¤è®ºæ–‡")
            
        # æŒ‰DOIæŸ¥æ‰¾é‡å¤
        print(f"\nğŸ” æŒ‰DOIæŸ¥æ‰¾é‡å¤...")
        print("-" * 50)
        
        duplicate_doi_query = """
        MATCH (n:Literature)
        WHERE n.doi IS NOT NULL AND n.doi <> ""
        WITH n.doi as doi, collect(n) as nodes
        WHERE size(nodes) > 1
        RETURN doi, [node in nodes | node.lid] as lids, size(nodes) as count
        ORDER BY count DESC
        """
        
        doi_results = await relationship_dao._execute_cypher(duplicate_doi_query)
        
        if doi_results:
            print(f"ğŸ“Š æ‰¾åˆ° {len(doi_results)} ç»„ç›¸åŒDOIçš„è®ºæ–‡:")
            for i, record in enumerate(doi_results, 1):
                print(f"{i}. DOI: {record['doi']}")
                print(f"   LIDs: {record['lids']}")
                print(f"   æ•°é‡: {record['count']}")
                print()
        else:
            print("âœ… æœªå‘ç°ç›¸åŒDOIçš„é‡å¤è®ºæ–‡")
            
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    # ä½¿ç”¨æ­£ç¡®çš„Neo4j URI
    import os
    os.environ['LITERATURE_PARSER_BACKEND_NEO4J_URI'] = 'bolt://localhost:7687'
    
    asyncio.run(analyze_duplicate_papers())





#!/usr/bin/env python3
"""
å¹¶å‘æ€§èƒ½æµ‹è¯•è„šæœ¬

æµ‹è¯•ç³»ç»Ÿåœ¨é«˜å¹¶å‘æƒ…å†µä¸‹çš„è¡¨ç°ï¼ŒåŒ…æ‹¬ï¼š
1. å¹¶å‘æäº¤ç›¸åŒæ–‡çŒ®æµ‹è¯•å»é‡åŠŸèƒ½
2. å¹¶å‘æäº¤ä¸åŒæ–‡çŒ®æµ‹è¯•å¤„ç†èƒ½åŠ›
3. ç³»ç»Ÿè´Ÿè½½æµ‹è¯•

ä½¿ç”¨æ–¹æ³•:
    python test_concurrency.py --test dedup --count 10     # æµ‹è¯•å»é‡ï¼Œ10ä¸ªå¹¶å‘
    python test_concurrency.py --test load --count 20      # è´Ÿè½½æµ‹è¯•ï¼Œ20ä¸ªå¹¶å‘
    python test_concurrency.py --test mixed --count 15     # æ··åˆæµ‹è¯•ï¼Œ15ä¸ªå¹¶å‘
"""

import argparse
import asyncio
import json
import random
import sys
import time
from datetime import datetime
from typing import List, Dict, Any

import aiohttp
from loguru import logger


class ConcurrencyTester:
    """å¹¶å‘æµ‹è¯•å™¨"""
    
    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url
        self.session = None
        self.results = []
    
    async def initialize(self):
        """åˆå§‹åŒ–HTTPä¼šè¯"""
        self.session = aiohttp.ClientSession(
            timeout=aiohttp.ClientTimeout(total=300)  # 5åˆ†é’Ÿè¶…æ—¶
        )
        logger.info("âœ… HTTPä¼šè¯åˆå§‹åŒ–æˆåŠŸ")
    
    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.session:
            await self.session.close()
    
    async def submit_literature(self, literature_data: Dict[str, Any]) -> Dict[str, Any]:
        """æäº¤æ–‡çŒ®å¤„ç†è¯·æ±‚"""
        url = f"{self.base_url}/api/literature/"
        
        start_time = time.time()
        
        try:
            async with self.session.post(url, json=literature_data) as response:
                end_time = time.time()
                
                result = {
                    "status_code": response.status,
                    "response_time": round(end_time - start_time, 3),
                    "success": response.status in [200, 201, 202],  # 202æ˜¯å¼‚æ­¥ä»»åŠ¡åˆ›å»ºæˆåŠŸ
                    "literature_data": literature_data,
                    "timestamp": datetime.now().isoformat(),
                }

                if response.status in [200, 201, 202]:
                    response_data = await response.json()
                    result["task_id"] = response_data.get("task_id")
                    result["literature_id"] = response_data.get("literature_id")
                    result["message"] = response_data.get("message")
                else:
                    result["error"] = await response.text()
                
                return result
                
        except Exception as e:
            end_time = time.time()
            return {
                "status_code": 0,
                "response_time": round(end_time - start_time, 3),
                "success": False,
                "error": str(e),
                "literature_data": literature_data,
                "timestamp": datetime.now().isoformat(),
            }
    
    async def test_deduplication(self, concurrent_count: int = 10) -> List[Dict[str, Any]]:
        """æµ‹è¯•å»é‡åŠŸèƒ½ - å¹¶å‘æäº¤ç›¸åŒæ–‡çŒ®"""
        logger.info(f"ğŸ”„ å¼€å§‹å»é‡æµ‹è¯•ï¼Œå¹¶å‘æ•°: {concurrent_count}")
        
        # ä½¿ç”¨ç›¸åŒçš„æ–‡çŒ®æ•°æ®
        literature_data = {
            "url": "https://doi.org/10.1038/nature12373",
            "title": "Deep learning test paper",
            "authors": ["Test Author"]
        }
        
        # åˆ›å»ºå¹¶å‘ä»»åŠ¡
        tasks = []
        for i in range(concurrent_count):
            task = asyncio.create_task(
                self.submit_literature(literature_data),
                name=f"dedup_test_{i}"
            )
            tasks.append(task)
        
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†ç»“æœ
        processed_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                processed_results.append({
                    "task_name": f"dedup_test_{i}",
                    "success": False,
                    "error": str(result),
                    "timestamp": datetime.now().isoformat(),
                })
            else:
                result["task_name"] = f"dedup_test_{i}"
                processed_results.append(result)
        
        return processed_results
    
    async def test_load(self, concurrent_count: int = 20) -> List[Dict[str, Any]]:
        """è´Ÿè½½æµ‹è¯• - å¹¶å‘æäº¤ä¸åŒæ–‡çŒ®"""
        logger.info(f"ğŸ“Š å¼€å§‹è´Ÿè½½æµ‹è¯•ï¼Œå¹¶å‘æ•°: {concurrent_count}")
        
        # ç”Ÿæˆä¸åŒçš„æ–‡çŒ®æ•°æ®
        literature_list = []
        for i in range(concurrent_count):
            literature_data = {
                "url": f"https://example.com/paper_{i}",
                "title": f"Test Paper {i}: Concurrent Processing Analysis",
                "authors": [f"Test Author {i}"]
            }
            literature_list.append(literature_data)
        
        # åˆ›å»ºå¹¶å‘ä»»åŠ¡
        tasks = []
        for i, literature_data in enumerate(literature_list):
            task = asyncio.create_task(
                self.submit_literature(literature_data),
                name=f"load_test_{i}"
            )
            tasks.append(task)
        
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†ç»“æœ
        processed_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                processed_results.append({
                    "task_name": f"load_test_{i}",
                    "success": False,
                    "error": str(result),
                    "timestamp": datetime.now().isoformat(),
                })
            else:
                result["task_name"] = f"load_test_{i}"
                processed_results.append(result)
        
        return processed_results
    
    async def test_mixed(self, concurrent_count: int = 15) -> List[Dict[str, Any]]:
        """æ··åˆæµ‹è¯• - éƒ¨åˆ†ç›¸åŒï¼Œéƒ¨åˆ†ä¸åŒçš„æ–‡çŒ®"""
        logger.info(f"ğŸ”€ å¼€å§‹æ··åˆæµ‹è¯•ï¼Œå¹¶å‘æ•°: {concurrent_count}")
        
        literature_list = []
        
        # 30%ç›¸åŒæ–‡çŒ®ï¼ˆæµ‹è¯•å»é‡ï¼‰
        duplicate_count = int(concurrent_count * 0.3)
        duplicate_data = {
            "url": "https://doi.org/10.1038/nature12373",
            "title": "Duplicate Test Paper",
            "authors": ["Duplicate Author"]
        }
        for i in range(duplicate_count):
            literature_list.append(duplicate_data)

        # 70%ä¸åŒæ–‡çŒ®ï¼ˆæµ‹è¯•è´Ÿè½½ï¼‰
        unique_count = concurrent_count - duplicate_count
        for i in range(unique_count):
            literature_data = {
                "url": f"https://example.com/unique_paper_{i}",
                "title": f"Unique Paper {i}: Mixed Test Analysis",
                "authors": [f"Unique Author {i}"]
            }
            literature_list.append(literature_data)
        
        # éšæœºæ‰“ä¹±é¡ºåº
        random.shuffle(literature_list)
        
        # åˆ›å»ºå¹¶å‘ä»»åŠ¡
        tasks = []
        for i, literature_data in enumerate(literature_list):
            task = asyncio.create_task(
                self.submit_literature(literature_data),
                name=f"mixed_test_{i}"
            )
            tasks.append(task)
        
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†ç»“æœ
        processed_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                processed_results.append({
                    "task_name": f"mixed_test_{i}",
                    "success": False,
                    "error": str(result),
                    "timestamp": datetime.now().isoformat(),
                })
            else:
                result["task_name"] = f"mixed_test_{i}"
                processed_results.append(result)
        
        return processed_results
    
    def analyze_results(self, results: List[Dict[str, Any]], test_type: str):
        """åˆ†ææµ‹è¯•ç»“æœ"""
        total_requests = len(results)
        successful_requests = sum(1 for r in results if r.get("success", False))
        failed_requests = total_requests - successful_requests
        
        response_times = [r.get("response_time", 0) for r in results if r.get("response_time")]
        avg_response_time = sum(response_times) / len(response_times) if response_times else 0
        max_response_time = max(response_times) if response_times else 0
        min_response_time = min(response_times) if response_times else 0
        
        # ç»Ÿè®¡ä¸åŒçš„literature_idï¼ˆç”¨äºå»é‡æµ‹è¯•ï¼‰
        literature_ids = set()
        task_ids = set()
        for r in results:
            if r.get("literature_id"):
                literature_ids.add(r["literature_id"])
            if r.get("task_id"):
                task_ids.add(r["task_id"])
        
        print(f"\nğŸ“Š {test_type.upper()} æµ‹è¯•ç»“æœåˆ†æ")
        print("="*60)
        print(f"æ€»è¯·æ±‚æ•°: {total_requests}")
        print(f"æˆåŠŸè¯·æ±‚: {successful_requests}")
        print(f"å¤±è´¥è¯·æ±‚: {failed_requests}")
        print(f"æˆåŠŸç‡: {successful_requests/total_requests*100:.2f}%")
        print(f"å¹³å‡å“åº”æ—¶é—´: {avg_response_time:.3f}s")
        print(f"æœ€å¤§å“åº”æ—¶é—´: {max_response_time:.3f}s")
        print(f"æœ€å°å“åº”æ—¶é—´: {min_response_time:.3f}s")
        print(f"å”¯ä¸€æ–‡çŒ®IDæ•°: {len(literature_ids)}")
        print(f"å”¯ä¸€ä»»åŠ¡IDæ•°: {len(task_ids)}")
        
        if test_type == "dedup":
            print(f"å»é‡æ•ˆæœ: {len(literature_ids)} ä¸ªå”¯ä¸€æ–‡çŒ® (æœŸæœ›: 1)")
            if len(literature_ids) == 1:
                print("âœ… å»é‡åŠŸèƒ½æ­£å¸¸")
            else:
                print("âŒ å»é‡åŠŸèƒ½å¼‚å¸¸")
        
        # æ˜¾ç¤ºå¤±è´¥çš„è¯·æ±‚
        failed_results = [r for r in results if not r.get("success", False)]
        if failed_results:
            print(f"\nâŒ å¤±è´¥è¯·æ±‚è¯¦æƒ…:")
            for i, result in enumerate(failed_results[:5]):  # åªæ˜¾ç¤ºå‰5ä¸ª
                print(f"  {i+1}. {result.get('error', 'Unknown error')}")
        
        print("="*60)
    
    def export_results(self, results: List[Dict[str, Any]], test_type: str):
        """å¯¼å‡ºæµ‹è¯•ç»“æœ"""
        filename = f"concurrency_test_{test_type}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump({
                    "test_type": test_type,
                    "timestamp": datetime.now().isoformat(),
                    "total_requests": len(results),
                    "results": results
                }, f, indent=2, ensure_ascii=False)
            
            logger.info(f"ğŸ“ æµ‹è¯•ç»“æœå·²å¯¼å‡ºåˆ°: {filename}")
            
        except Exception as e:
            logger.error(f"å¯¼å‡ºç»“æœå¤±è´¥: {e}")


async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="å¹¶å‘æ€§èƒ½æµ‹è¯•è„šæœ¬",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
æµ‹è¯•ç±»å‹:
    dedup  - å»é‡æµ‹è¯•ï¼šå¹¶å‘æäº¤ç›¸åŒæ–‡çŒ®
    load   - è´Ÿè½½æµ‹è¯•ï¼šå¹¶å‘æäº¤ä¸åŒæ–‡çŒ®  
    mixed  - æ··åˆæµ‹è¯•ï¼šéƒ¨åˆ†ç›¸åŒéƒ¨åˆ†ä¸åŒçš„æ–‡çŒ®

ä½¿ç”¨ç¤ºä¾‹:
    python test_concurrency.py --test dedup --count 10
    python test_concurrency.py --test load --count 20
    python test_concurrency.py --test mixed --count 15
        """
    )
    
    parser.add_argument(
        "--test", 
        choices=["dedup", "load", "mixed"],
        required=True,
        help="æµ‹è¯•ç±»å‹"
    )
    
    parser.add_argument(
        "--count", 
        type=int, 
        default=10,
        help="å¹¶å‘è¯·æ±‚æ•°é‡ (é»˜è®¤: 10)"
    )
    
    parser.add_argument(
        "--url", 
        default="http://localhost:8000",
        help="APIåŸºç¡€URL (é»˜è®¤: http://localhost:8000)"
    )
    
    parser.add_argument(
        "--export", 
        action="store_true", 
        help="å¯¼å‡ºæµ‹è¯•ç»“æœåˆ°JSONæ–‡ä»¶"
    )
    
    args = parser.parse_args()
    
    tester = ConcurrencyTester(args.url)
    
    try:
        await tester.initialize()
        
        logger.info(f"ğŸš€ å¼€å§‹ {args.test.upper()} æµ‹è¯•ï¼Œå¹¶å‘æ•°: {args.count}")
        start_time = time.time()
        
        if args.test == "dedup":
            results = await tester.test_deduplication(args.count)
        elif args.test == "load":
            results = await tester.test_load(args.count)
        elif args.test == "mixed":
            results = await tester.test_mixed(args.count)
        
        end_time = time.time()
        total_time = end_time - start_time
        
        logger.info(f"âœ… æµ‹è¯•å®Œæˆï¼Œæ€»è€—æ—¶: {total_time:.2f}s")
        
        # åˆ†æç»“æœ
        tester.analyze_results(results, args.test)
        
        # å¯¼å‡ºç»“æœ
        if args.export:
            tester.export_results(results, args.test)
        
    except Exception as e:
        logger.error(f"æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        sys.exit(1)
    
    finally:
        await tester.cleanup()


if __name__ == "__main__":
    asyncio.run(main())

#!/usr/bin/env python3
"""
ç»¼åˆURLæµ‹è¯•è„šæœ¬
åŒ…å«URLæ˜ å°„æµ‹è¯•å’Œå®Œæ•´å¤„ç†æµ‹è¯•ï¼Œä½¿ç”¨çœŸå®DOI
"""

import subprocess
import json
import requests
import time
from typing import List, Dict

def get_real_test_urls():
    """è·å–çœŸå®çš„æµ‹è¯•URLåˆ—è¡¨"""
    return [
        'https://arxiv.org/abs/2301.00001',
        'https://www.nature.com/articles/s41586-023-00001-0', 
        'https://science.sciencemag.org/content/379/6628/123',
        'https://ieeexplore.ieee.org/document/10000001',
        'https://dl.acm.org/doi/10.1145/3000001.3000002',
        'https://link.springer.com/article/10.1007/s00000-023-00001-0',
        'https://www.cell.com/cell/fulltext/S0092-8674(23)00001-0',
        'https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0000001'
    ]

def test_url_mapping(url: str) -> Dict:
    """æµ‹è¯•å•ä¸ªURLçš„æ˜ å°„èƒ½åŠ›"""
    try:
        test_script = f'''
import sys
sys.path.insert(0, '/app')
from literature_parser_backend.services.url_mapping import URLMappingService
import json

# ä½¿ç”¨å¸¦URLéªŒè¯çš„æ–°ç‰ˆæœ¬æœåŠ¡
service = URLMappingService(enable_url_validation=True)
result = service.map_url_sync("{url}")

output = {{
    "adapter": result.source_adapter or "æ— ",
    "strategy": result.strategy_used or "æ— ",
    "doi": result.doi or "æ— ",
    "arxiv_id": result.arxiv_id or "æ— ",
    "venue": result.venue or "æ— ",
    "confidence": result.confidence,
    "success": bool(result.doi or result.arxiv_id or result.venue),
    "url_validation_failed": result.metadata.get("url_validation_failed", False),
    "error": result.metadata.get("error", "")
}}

print(json.dumps(output))
'''
        
        cmd = ['sudo', 'docker', 'exec', '-i', 'paper_paser_1-worker-1', 'python3', '-c', test_script]
        proc = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
        
        if proc.returncode == 0:
            return json.loads(proc.stdout.strip())
        else:
            return {"success": False, "error": proc.stderr}
            
    except Exception as e:
        return {"success": False, "error": str(e)}

def test_crossref_doi(doi: str) -> bool:
    """æµ‹è¯•DOIåœ¨CrossRefä¸­çš„æœ‰æ•ˆæ€§"""
    if doi == "æ— " or not doi:
        return False
    try:
        url = f"https://api.crossref.org/works/{doi}"
        response = requests.get(url, timeout=10)
        return response.status_code == 200
    except:
        return False

def test_full_processing(url: str) -> Dict:
    """æµ‹è¯•å®Œæ•´çš„æ–‡çŒ®å¤„ç†æµç¨‹"""
    try:
        start_time = time.time()
        
        # æäº¤å¤„ç†ä»»åŠ¡
        response = requests.post(
            "http://localhost:8000/api/literature",
            json={"url": url},
            timeout=30
        )
        
        if response.status_code != 202:
            return {
                "success": False,
                "error": f"æäº¤å¤±è´¥: HTTP {response.status_code}",
                "processing_time": time.time() - start_time
            }
        
        task_data = response.json()
        task_id = task_data.get("task_id")
        
        # ç­‰å¾…å¤„ç†å®Œæˆ
        max_wait = 60
        wait_time = 0
        
        while wait_time < max_wait:
            time.sleep(5)
            wait_time += 5
            
            status_response = requests.get(
                f"http://localhost:8000/api/task/{task_id}",
                timeout=10
            )
            
            if status_response.status_code != 200:
                continue
            
            status_data = status_response.json()
            execution_status = status_data.get("execution_status")
            
            if execution_status == "completed":
                literature_id = status_data.get("literature_id")
                
                if literature_id:
                    # è·å–æ–‡çŒ®è¯¦ç»†ä¿¡æ¯
                    lit_response = requests.get(
                        f"http://localhost:8000/api/literature/{literature_id}",
                        timeout=10
                    )
                    
                    if lit_response.status_code == 200:
                        lit_data = lit_response.json()
                        return {
                            "success": True,
                            "processing_time": time.time() - start_time,
                            "title": lit_data.get("title", "æ— "),
                            "year": lit_data.get("year", "æ— "),
                            "doi": lit_data.get("doi", "æ— "),
                            "authors_count": len(lit_data.get("authors", [])),
                            "references_count": len(lit_data.get("references", []))
                        }
                
                return {
                    "success": False,
                    "error": "å¤„ç†å®Œæˆä½†æœªè·å–åˆ°æ–‡çŒ®ID",
                    "processing_time": time.time() - start_time
                }
            
            elif execution_status == "failed":
                return {
                    "success": False,
                    "error": f"å¤„ç†å¤±è´¥: {status_data.get('error_info', 'æœªçŸ¥é”™è¯¯')}",
                    "processing_time": time.time() - start_time
                }
        
        return {
            "success": False,
            "error": "å¤„ç†è¶…æ—¶",
            "processing_time": time.time() - start_time
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": f"å¤„ç†å¼‚å¸¸: {str(e)}",
            "processing_time": time.time() - start_time
        }

def run_comprehensive_test():
    """è¿è¡Œç»¼åˆæµ‹è¯•"""
    test_urls = get_real_test_urls()
    
    print("ğŸ” ç»¼åˆURLæµ‹è¯• (ä½¿ç”¨çœŸå®DOI)")
    print("=" * 80)
    print(f"ğŸ“‹ æµ‹è¯•URLæ•°é‡: {len(test_urls)}")
    print("ğŸ”§ åŒ…å«å®Œæ•´å¤„ç†æµ‹è¯•")
    print("=" * 80)
    
    results = []
    
    for i, url in enumerate(test_urls, 1):
        print(f"\næµ‹è¯• {i}/{len(test_urls)}: {url}")
        
        # 1. URLæ˜ å°„æµ‹è¯•
        mapping_result = test_url_mapping(url)
        
        # æ£€æŸ¥URLéªŒè¯çŠ¶æ€
        if mapping_result.get("url_validation_failed"):
            print(f"  âŒ URLéªŒè¯å¤±è´¥: {mapping_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            print(f"  ï¿½ è·³è¿‡åç»­å¤„ç†")
            results.append({
                "url": url,
                "mapping_success": False,
                "url_validation_failed": True,
                "error": mapping_result.get('error', 'æœªçŸ¥é”™è¯¯')
            })
            continue

        if mapping_result.get("success"):
            print(f"  ï¿½ é€‚é…å™¨: {mapping_result['adapter']}")
            print(f"  ğŸ”§ ç­–ç•¥: {mapping_result['strategy']}")
            print(f"  ï¿½ DOI: {mapping_result['doi']}")
            print(f"  ï¿½ ArXiv ID: {mapping_result['arxiv_id']}")
            print(f"  ğŸ›ï¸ æœŸåˆŠ: {mapping_result['venue']}")
            print(f"  ğŸ“Š ç½®ä¿¡åº¦: {mapping_result['confidence']}")
            print(f"  ï¿½ URLéªŒè¯: âœ… é€šè¿‡")
            
            # 2. CrossRefæœ‰æ•ˆæ€§æµ‹è¯•
            crossref_valid = False
            # if mapping_result['doi'] != "æ— ":
            #     crossref_valid = test_crossref_doi(mapping_result['doi'])
            #     print(f"  âœ… CrossRefæœ‰æ•ˆ: {'æ˜¯' if crossref_valid else 'å¦'}")
            crossref_valid = True
            
            # 3. å®Œæ•´å¤„ç†æµ‹è¯•
            if crossref_valid:  # åªå¯¹æœ‰æ•ˆDOIè¿›è¡Œå®Œæ•´å¤„ç†æµ‹è¯•
                print(f"  ğŸ”„ å¼€å§‹å®Œæ•´å¤„ç†æµ‹è¯•...")
                processing_result = test_full_processing(url)
                
                if processing_result.get("success"):
                    print(f"  ğŸ“š æ ‡é¢˜: {processing_result['title'][:50]}...")
                    print(f"  ğŸ“… å¹´ä»½: {processing_result['year']}")
                    print(f"  ğŸ‘¥ ä½œè€…æ•°: {processing_result['authors_count']}")
                    print(f"  ğŸ“– å‚è€ƒæ–‡çŒ®æ•°: {processing_result['references_count']}")
                    print(f"  â±ï¸ å¤„ç†æ—¶é—´: {processing_result['processing_time']:.1f}ç§’")
                    
                    results.append({
                        "url": url,
                        "mapping_success": True,
                        "crossref_valid": crossref_valid,
                        "processing_success": True,
                        **mapping_result,
                        **processing_result
                    })
                else:
                    print(f"  âŒ å¤„ç†å¤±è´¥: {processing_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                    results.append({
                        "url": url,
                        "mapping_success": True,
                        "crossref_valid": crossref_valid,
                        "processing_success": False,
                        "error": processing_result.get('error'),
                        **mapping_result
                    })
            else:
                print(f"  âš ï¸ è·³è¿‡å®Œæ•´å¤„ç†æµ‹è¯• (DOIæ— æ•ˆæˆ–ä¸å­˜åœ¨)")
                results.append({
                    "url": url,
                    "mapping_success": True,
                    "crossref_valid": crossref_valid,
                    "processing_success": False,
                    **mapping_result
                })
        else:
            print(f"  âŒ æ˜ å°„å¤±è´¥: {mapping_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            results.append({
                "url": url,
                "mapping_success": False,
                "crossref_valid": False,
                "processing_success": False,
                "error": mapping_result.get('error')
            })
    
    # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
    generate_comprehensive_report(results)
    
    return results

def generate_comprehensive_report(results: List[Dict]):
    """ç”Ÿæˆç»¼åˆæµ‹è¯•æŠ¥å‘Š"""
    total = len(results)
    mapping_success = sum(1 for r in results if r.get('mapping_success', False))
    crossref_valid = sum(1 for r in results if r.get('crossref_valid', False))
    processing_success = sum(1 for r in results if r.get('processing_success', False))
    
    print("\n" + "=" * 80)
    print("ğŸ“Š ç»¼åˆæµ‹è¯•æ€»ç»“æŠ¥å‘Š")
    print("=" * 80)
    
    print(f"\nğŸ“ˆ æ€»ä½“ç»Ÿè®¡:")
    print(f"  â€¢ æµ‹è¯•URLæ€»æ•°: {total}")
    print(f"  â€¢ URLæ˜ å°„æˆåŠŸ: {mapping_success}/{total} ({mapping_success/total*100:.1f}%)")
    print(f"  â€¢ CrossRefæœ‰æ•ˆ: {crossref_valid}/{total} ({crossref_valid/total*100:.1f}%)")
    print(f"  â€¢ å®Œæ•´å¤„ç†æˆåŠŸ: {processing_success}/{total} ({processing_success/total*100:.1f}%)")
    
    print(f"\nğŸ† æˆåŠŸå¤„ç†çš„æœŸåˆŠ:")
    successful_venues = {}
    for result in results:
        if result.get('processing_success'):
            venue = result.get('venue', 'æœªçŸ¥')
            successful_venues[venue] = successful_venues.get(venue, 0) + 1
    
    for venue, count in sorted(successful_venues.items()):
        print(f"  â€¢ {venue}: {count}ä¸ªURL")
    
    print(f"\nâš ï¸ éœ€è¦å…³æ³¨çš„é—®é¢˜:")
    failed_mapping = [r for r in results if not r.get('mapping_success', False)]
    invalid_dois = [r for r in results if r.get('mapping_success', False) and not r.get('crossref_valid', False)]
    failed_processing = [r for r in results if r.get('crossref_valid', False) and not r.get('processing_success', False)]
    
    if failed_mapping:
        print(f"  â€¢ URLæ˜ å°„å¤±è´¥: {len(failed_mapping)}ä¸ª")
    if invalid_dois:
        print(f"  â€¢ DOIæ— æ•ˆ: {len(invalid_dois)}ä¸ª (å¯èƒ½æ˜¯æµ‹è¯•DOI)")
    if failed_processing:
        print(f"  â€¢ å®Œæ•´å¤„ç†å¤±è´¥: {len(failed_processing)}ä¸ª")
    
    if not (failed_mapping or invalid_dois or failed_processing):
        print("  ğŸ‰ æ‰€æœ‰æµ‹è¯•éƒ½è¡¨ç°è‰¯å¥½ï¼")

if __name__ == "__main__":
    run_comprehensive_test()

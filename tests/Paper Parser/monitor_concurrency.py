#!/usr/bin/env python3
"""
å¹¶å‘ç›‘æ§è„šæœ¬

ç›‘æ§Celery workerçŠ¶æ€ã€Redisé˜Ÿåˆ—é•¿åº¦ã€MongoDBè¿æ¥çŠ¶æ€ç­‰å…³é”®æŒ‡æ ‡
ç”¨äºå®æ—¶äº†è§£ç³»ç»Ÿå¹¶å‘å¤„ç†èƒ½åŠ›å’Œç“¶é¢ˆã€‚

ä½¿ç”¨æ–¹æ³•:
    python monitor_concurrency.py --interval 10    # æ¯10ç§’ç›‘æ§ä¸€æ¬¡
    python monitor_concurrency.py --once           # åªç›‘æ§ä¸€æ¬¡
    python monitor_concurrency.py --export         # å¯¼å‡ºç›‘æ§æ•°æ®åˆ°æ–‡ä»¶
"""

import argparse
import asyncio
import json
import sys
import time
from datetime import datetime
from typing import Dict, Any, Optional

import redis
from celery import Celery
from motor.motor_asyncio import AsyncIOMotorClient

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, '/app')

from literature_parser_backend.settings import Settings
from loguru import logger


class ConcurrencyMonitor:
    """å¹¶å‘ç›‘æ§å™¨"""
    
    def __init__(self):
        self.settings = Settings()
        self.redis_client = None
        self.mongo_client = None
        self.celery_app = None
        self.monitoring_data = []
    
    async def initialize(self):
        """åˆå§‹åŒ–è¿æ¥"""
        try:
            # Redisè¿æ¥
            self.redis_client = redis.Redis(
                host=self.settings.redis_host,
                port=self.settings.redis_port,
                db=self.settings.redis_db,
                password=self.settings.redis_password if self.settings.redis_password else None,
                decode_responses=True
            )
            
            # MongoDBè¿æ¥
            self.mongo_client = AsyncIOMotorClient(str(self.settings.db_url))
            
            # Celeryè¿æ¥
            self.celery_app = Celery(
                "literature_parser_worker",
                broker=self.settings.celery_broker_url_computed,
                backend=self.settings.celery_result_backend_computed,
            )
            
            logger.info("âœ… ç›‘æ§å™¨åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            logger.error(f"âŒ ç›‘æ§å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    async def get_redis_stats(self) -> Dict[str, Any]:
        """è·å–Redisç»Ÿè®¡ä¿¡æ¯"""
        try:
            info = self.redis_client.info()
            
            # è·å–é˜Ÿåˆ—é•¿åº¦
            queue_length = self.redis_client.llen("celery")  # é»˜è®¤é˜Ÿåˆ—
            literature_queue_length = self.redis_client.llen("literature")  # æ–‡çŒ®é˜Ÿåˆ—
            
            return {
                "connected_clients": info.get("connected_clients", 0),
                "used_memory_human": info.get("used_memory_human", "0B"),
                "used_memory_peak_human": info.get("used_memory_peak_human", "0B"),
                "total_commands_processed": info.get("total_commands_processed", 0),
                "instantaneous_ops_per_sec": info.get("instantaneous_ops_per_sec", 0),
                "queue_length": queue_length,
                "literature_queue_length": literature_queue_length,
                "keyspace_hits": info.get("keyspace_hits", 0),
                "keyspace_misses": info.get("keyspace_misses", 0),
            }
        except Exception as e:
            logger.error(f"è·å–Redisç»Ÿè®¡å¤±è´¥: {e}")
            return {"error": str(e)}
    
    async def get_celery_stats(self) -> Dict[str, Any]:
        """è·å–Celeryç»Ÿè®¡ä¿¡æ¯"""
        try:
            inspect = self.celery_app.control.inspect()
            
            # è·å–æ´»è·ƒä»»åŠ¡
            active_tasks = inspect.active()
            
            # è·å–workerç»Ÿè®¡
            stats = inspect.stats()
            
            # è·å–æ³¨å†Œä»»åŠ¡
            registered_tasks = inspect.registered()
            
            # è®¡ç®—æ€»ä½“ç»Ÿè®¡
            total_active_tasks = 0
            total_workers = 0
            worker_details = {}
            
            if active_tasks:
                for worker, tasks in active_tasks.items():
                    total_active_tasks += len(tasks)
                    total_workers += 1
                    worker_details[worker] = {
                        "active_tasks": len(tasks),
                        "task_details": [
                            {
                                "id": task.get("id", "unknown"),
                                "name": task.get("name", "unknown"),
                                "time_start": task.get("time_start", 0),
                            }
                            for task in tasks
                        ]
                    }
            
            # è·å–workerè´Ÿè½½
            worker_load = {}
            if stats:
                for worker, stat in stats.items():
                    pool = stat.get("pool", {})
                    worker_load[worker] = {
                        "processes": pool.get("processes", []),
                        "max_concurrency": pool.get("max-concurrency", 0),
                        "max_memory_per_child": pool.get("max-memory-per-child", 0),
                    }
            
            return {
                "total_workers": total_workers,
                "total_active_tasks": total_active_tasks,
                "worker_details": worker_details,
                "worker_load": worker_load,
                "registered_tasks_count": len(registered_tasks) if registered_tasks else 0,
            }
            
        except Exception as e:
            logger.error(f"è·å–Celeryç»Ÿè®¡å¤±è´¥: {e}")
            return {"error": str(e)}
    
    async def get_mongodb_stats(self) -> Dict[str, Any]:
        """è·å–MongoDBç»Ÿè®¡ä¿¡æ¯"""
        try:
            db = self.mongo_client.get_database()
            
            # æ•°æ®åº“ç»Ÿè®¡
            db_stats = await db.command("dbStats")
            
            # é›†åˆç»Ÿè®¡
            collection = db.literatures
            collection_stats = await db.command("collStats", "literatures")
            
            # è¿æ¥ç»Ÿè®¡
            server_status = await db.command("serverStatus")
            connections = server_status.get("connections", {})
            
            # æ–‡çŒ®ç»Ÿè®¡
            total_literature = await collection.count_documents({})
            processing_literature = await collection.count_documents({
                "task_info.status": {"$in": ["pending", "processing", "in_progress"]}
            })
            failed_literature = await collection.count_documents({
                "task_info.status": "failed"
            })
            completed_literature = await collection.count_documents({
                "task_info.status": "completed"
            })
            
            return {
                "database_size_mb": round(db_stats.get("dataSize", 0) / 1024 / 1024, 2),
                "storage_size_mb": round(db_stats.get("storageSize", 0) / 1024 / 1024, 2),
                "index_size_mb": round(db_stats.get("indexSize", 0) / 1024 / 1024, 2),
                "collections": db_stats.get("collections", 0),
                "objects": db_stats.get("objects", 0),
                "current_connections": connections.get("current", 0),
                "available_connections": connections.get("available", 0),
                "total_created_connections": connections.get("totalCreated", 0),
                "literature_stats": {
                    "total": total_literature,
                    "processing": processing_literature,
                    "failed": failed_literature,
                    "completed": completed_literature,
                    "success_rate": round(completed_literature / max(total_literature, 1) * 100, 2)
                }
            }
            
        except Exception as e:
            logger.error(f"è·å–MongoDBç»Ÿè®¡å¤±è´¥: {e}")
            return {"error": str(e)}
    
    async def collect_metrics(self) -> Dict[str, Any]:
        """æ”¶é›†æ‰€æœ‰ç›‘æ§æŒ‡æ ‡"""
        timestamp = datetime.now()
        
        logger.info("ğŸ“Š æ­£åœ¨æ”¶é›†ç›‘æ§æŒ‡æ ‡...")
        
        # å¹¶è¡Œæ”¶é›†æ‰€æœ‰æŒ‡æ ‡
        redis_stats, celery_stats, mongodb_stats = await asyncio.gather(
            self.get_redis_stats(),
            self.get_celery_stats(),
            self.get_mongodb_stats(),
            return_exceptions=True
        )
        
        metrics = {
            "timestamp": timestamp.isoformat(),
            "redis": redis_stats if not isinstance(redis_stats, Exception) else {"error": str(redis_stats)},
            "celery": celery_stats if not isinstance(celery_stats, Exception) else {"error": str(celery_stats)},
            "mongodb": mongodb_stats if not isinstance(mongodb_stats, Exception) else {"error": str(mongodb_stats)},
        }
        
        return metrics
    
    def display_metrics(self, metrics: Dict[str, Any]):
        """æ˜¾ç¤ºç›‘æ§æŒ‡æ ‡"""
        print("\n" + "="*80)
        print(f"ğŸ• ç›‘æ§æ—¶é—´: {metrics['timestamp']}")
        print("="*80)
        
        # RedisæŒ‡æ ‡
        redis_data = metrics.get("redis", {})
        if "error" not in redis_data:
            print(f"ğŸ“Š RedisçŠ¶æ€:")
            print(f"   è¿æ¥å®¢æˆ·ç«¯: {redis_data.get('connected_clients', 0)}")
            print(f"   å†…å­˜ä½¿ç”¨: {redis_data.get('used_memory_human', '0B')}")
            print(f"   é˜Ÿåˆ—é•¿åº¦: {redis_data.get('literature_queue_length', 0)}")
            print(f"   æ¯ç§’æ“ä½œ: {redis_data.get('instantaneous_ops_per_sec', 0)}")
        else:
            print(f"âŒ Redisé”™è¯¯: {redis_data['error']}")
        
        # CeleryæŒ‡æ ‡
        celery_data = metrics.get("celery", {})
        if "error" not in celery_data:
            print(f"\nğŸ”„ CeleryçŠ¶æ€:")
            print(f"   æ´»è·ƒWorker: {celery_data.get('total_workers', 0)}")
            print(f"   æ´»è·ƒä»»åŠ¡: {celery_data.get('total_active_tasks', 0)}")
            
            worker_details = celery_data.get("worker_details", {})
            for worker, details in worker_details.items():
                print(f"   Worker {worker}: {details['active_tasks']} ä¸ªä»»åŠ¡")
        else:
            print(f"âŒ Celeryé”™è¯¯: {celery_data['error']}")
        
        # MongoDBæŒ‡æ ‡
        mongodb_data = metrics.get("mongodb", {})
        if "error" not in mongodb_data:
            print(f"\nğŸ’¾ MongoDBçŠ¶æ€:")
            print(f"   æ•°æ®åº“å¤§å°: {mongodb_data.get('database_size_mb', 0)} MB")
            print(f"   å½“å‰è¿æ¥: {mongodb_data.get('current_connections', 0)}")
            
            lit_stats = mongodb_data.get("literature_stats", {})
            print(f"   æ–‡çŒ®æ€»æ•°: {lit_stats.get('total', 0)}")
            print(f"   å¤„ç†ä¸­: {lit_stats.get('processing', 0)}")
            print(f"   å·²å®Œæˆ: {lit_stats.get('completed', 0)}")
            print(f"   å¤±è´¥: {lit_stats.get('failed', 0)}")
            print(f"   æˆåŠŸç‡: {lit_stats.get('success_rate', 0)}%")
        else:
            print(f"âŒ MongoDBé”™è¯¯: {mongodb_data['error']}")
        
        print("="*80)
    
    async def monitor_once(self):
        """æ‰§è¡Œä¸€æ¬¡ç›‘æ§"""
        await self.initialize()
        metrics = await self.collect_metrics()
        self.display_metrics(metrics)
        return metrics
    
    async def monitor_continuous(self, interval: int = 10):
        """æŒç»­ç›‘æ§"""
        await self.initialize()
        
        logger.info(f"ğŸš€ å¼€å§‹æŒç»­ç›‘æ§ï¼Œé—´éš” {interval} ç§’")
        logger.info("æŒ‰ Ctrl+C åœæ­¢ç›‘æ§")
        
        try:
            while True:
                metrics = await self.collect_metrics()
                self.display_metrics(metrics)
                self.monitoring_data.append(metrics)
                
                await asyncio.sleep(interval)
                
        except KeyboardInterrupt:
            logger.info("ğŸ›‘ ç›‘æ§å·²åœæ­¢")
    
    def export_data(self, filename: Optional[str] = None):
        """å¯¼å‡ºç›‘æ§æ•°æ®"""
        if not self.monitoring_data:
            logger.warning("æ²¡æœ‰ç›‘æ§æ•°æ®å¯å¯¼å‡º")
            return
        
        if filename is None:
            filename = f"concurrency_monitor_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(self.monitoring_data, f, indent=2, ensure_ascii=False)
            
            logger.info(f"ğŸ“ ç›‘æ§æ•°æ®å·²å¯¼å‡ºåˆ°: {filename}")
            
        except Exception as e:
            logger.error(f"å¯¼å‡ºæ•°æ®å¤±è´¥: {e}")


async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="å¹¶å‘ç›‘æ§è„šæœ¬",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
    python monitor_concurrency.py --once           # ç›‘æ§ä¸€æ¬¡
    python monitor_concurrency.py --interval 10    # æ¯10ç§’ç›‘æ§ä¸€æ¬¡
    python monitor_concurrency.py --export         # å¯¼å‡ºæ•°æ®
        """
    )
    
    parser.add_argument(
        "--once", 
        action="store_true", 
        help="åªç›‘æ§ä¸€æ¬¡"
    )
    
    parser.add_argument(
        "--interval", 
        type=int, 
        default=10,
        help="æŒç»­ç›‘æ§çš„é—´éš”ç§’æ•° (é»˜è®¤: 10)"
    )
    
    parser.add_argument(
        "--export", 
        action="store_true", 
        help="å¯¼å‡ºç›‘æ§æ•°æ®åˆ°JSONæ–‡ä»¶"
    )
    
    args = parser.parse_args()
    
    monitor = ConcurrencyMonitor()
    
    try:
        if args.once:
            await monitor.monitor_once()
        elif args.export:
            # å…ˆç›‘æ§ä¸€æ¬¡æ”¶é›†æ•°æ®
            await monitor.monitor_once()
            monitor.export_data()
        else:
            await monitor.monitor_continuous(args.interval)
            
    except Exception as e:
        logger.error(f"ç›‘æ§æ‰§è¡Œå¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())

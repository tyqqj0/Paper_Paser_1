#!/usr/bin/env python3
"""
è¯Šæ–­arXivè®ºæ–‡å…ƒæ•°æ®è·å–é—®é¢˜

åˆ†æä¸ºä»€ä¹ˆ https://arxiv.org/abs/2301.00001 æ— æ³•æ­£ç¡®è·å–å…ƒæ•°æ®
"""

import requests
import json
import time
import threading
from typing import Dict, Any


class ArXivMetadataDiagnoser:
    """arXivå…ƒæ•°æ®è¯Šæ–­å™¨"""
    
    def __init__(self):
        self.events = []
        self.metadata_details = {}
        self.is_connected = False
        self.error = None
        
    def diagnose_arxiv_paper(self, arxiv_url: str):
        """è¯Šæ–­arXivè®ºæ–‡çš„å…ƒæ•°æ®è·å–"""
        print(f"ğŸ” è¯Šæ–­arXivè®ºæ–‡: {arxiv_url}")
        print("=" * 70)
        
        # 1. é¦–å…ˆæµ‹è¯•ç›´æ¥çš„arXiv API
        arxiv_id = self._extract_arxiv_id(arxiv_url)
        if arxiv_id:
            print(f"ğŸ“‹ æå–çš„arXiv ID: {arxiv_id}")
            self._test_arxiv_api(arxiv_id)
        
        # 2. æµ‹è¯•æˆ‘ä»¬çš„SSEç«¯ç‚¹
        print(f"\nğŸ§ª æµ‹è¯•æˆ‘ä»¬çš„SSEç«¯ç‚¹...")
        self._test_our_sse_endpoint(arxiv_url)
        
        # 3. è·å–æœ€ç»ˆçš„æ–‡çŒ®æ•°æ®è¿›è¡Œåˆ†æ
        if hasattr(self, 'literature_id') and self.literature_id:
            print(f"\nğŸ“– åˆ†ææœ€ç»ˆæ–‡çŒ®æ•°æ®...")
            self._analyze_final_literature_data(self.literature_id)
    
    def _extract_arxiv_id(self, url: str) -> str:
        """ä»URLä¸­æå–arXiv ID"""
        if 'arxiv.org/abs/' in url:
            return url.split('arxiv.org/abs/')[-1]
        return None
    
    def _test_arxiv_api(self, arxiv_id: str):
        """æµ‹è¯•arXivå®˜æ–¹API"""
        print(f"ğŸŒ æµ‹è¯•arXivå®˜æ–¹API...")
        
        try:
            # arXiv API URL
            api_url = f"http://export.arxiv.org/api/query?id_list={arxiv_id}"
            response = requests.get(api_url, timeout=10)
            
            if response.status_code == 200:
                print("âœ… arXiv APIå“åº”æˆåŠŸ")
                
                # ç®€å•è§£æXMLå“åº”
                content = response.text
                if '<title>' in content and '</title>' in content:
                    title_start = content.find('<title>') + 7
                    title_end = content.find('</title>', title_start)
                    title = content[title_start:title_end].strip()
                    print(f"   ğŸ“ æ ‡é¢˜: {title}")
                
                if '<summary>' in content and '</summary>' in content:
                    summary_start = content.find('<summary>') + 9
                    summary_end = content.find('</summary>', summary_start)
                    summary = content[summary_start:summary_end].strip()
                    print(f"   ğŸ“„ æ‘˜è¦: {summary[:100]}...")
                
                # æ£€æŸ¥ä½œè€…ä¿¡æ¯
                author_count = content.count('<name>')
                print(f"   ğŸ‘¥ ä½œè€…æ•°é‡: {author_count}")
                
            else:
                print(f"âŒ arXiv APIå“åº”å¤±è´¥: {response.status_code}")
                
        except Exception as e:
            print(f"âŒ arXiv APIæµ‹è¯•å¼‚å¸¸: {e}")
    
    def _test_our_sse_endpoint(self, arxiv_url: str):
        """æµ‹è¯•æˆ‘ä»¬çš„SSEç«¯ç‚¹"""
        test_data = {
            "source": {
                "url": arxiv_url
            }
        }
        
        try:
            response = requests.post(
                "http://localhost:8000/api/literature/stream",
                json=test_data,
                headers={
                    'Accept': 'text/event-stream',
                    'Cache-Control': 'no-cache'
                },
                stream=True,
                timeout=60
            )
            
            if response.status_code != 200:
                self.error = f"HTTP {response.status_code}: {response.text}"
                print(f"âŒ SSEè¿æ¥å¤±è´¥: {self.error}")
                return
            
            self.is_connected = True
            print("âœ… SSEè¿æ¥å»ºç«‹æˆåŠŸ")
            print("\nğŸ“Š å¤„ç†è¿‡ç¨‹åˆ†æ:")
            print("-" * 50)
            
            for line in response.iter_lines(decode_unicode=True):
                if line:
                    self._process_sse_line(line)
                    
        except Exception as e:
            self.error = str(e)
            print(f"âŒ SSEæµ‹è¯•å¼‚å¸¸: {e}")
    
    def _process_sse_line(self, line: str):
        """å¤„ç†SSEè¡Œæ•°æ®"""
        if line.startswith('event:'):
            event_type = line[6:].strip()
            self.current_event_type = event_type
        elif line.startswith('data:'):
            data = line[5:].strip()
            try:
                event_data = json.loads(data)
                event = {
                    'type': getattr(self, 'current_event_type', 'message'),
                    'data': event_data,
                    'timestamp': time.time()
                }
                self.events.append(event)
                self._analyze_sse_event(event)
            except json.JSONDecodeError:
                print(f"âš ï¸ æ— æ³•è§£æJSONæ•°æ®: {data}")
    
    def _analyze_sse_event(self, event: Dict[str, Any]):
        """åˆ†æSSEäº‹ä»¶"""
        event_type = event['type']
        data = event['data']
        timestamp = time.strftime('%H:%M:%S', time.localtime(event['timestamp']))
        
        if event_type == 'status':
            execution_status = data.get('execution_status')
            stage = data.get('current_stage', 'N/A')
            progress = data.get('overall_progress', 0)
            
            print(f"[{timestamp}] ğŸ“Š {execution_status} - {progress}% - {stage}")
            
            # åˆ†ææ–‡çŒ®çŠ¶æ€è¯¦æƒ…
            lit_status = data.get('literature_status')
            if lit_status:
                comp_status = lit_status.get('component_status', {})
                
                # é‡ç‚¹å…³æ³¨metadataç»„ä»¶
                metadata_comp = comp_status.get('metadata')
                if metadata_comp:
                    meta_status = metadata_comp.get('status')
                    meta_stage = metadata_comp.get('stage', 'N/A')
                    meta_source = metadata_comp.get('source', 'N/A')
                    meta_error = metadata_comp.get('error_info')
                    
                    print(f"           ğŸ” å…ƒæ•°æ®: {meta_status} - {meta_stage} - æ¥æº: {meta_source}")
                    if meta_error:
                        print(f"           âŒ å…ƒæ•°æ®é”™è¯¯: {meta_error}")
                    
                    self.metadata_details = metadata_comp
                
        elif event_type == 'completed':
            literature_id = data.get('literature_id')
            print(f"[{timestamp}] ğŸ‰ ä»»åŠ¡å®Œæˆ! Literature ID: {literature_id}")
            self.literature_id = literature_id
            
        elif event_type == 'error':
            error_msg = data.get('error', 'æœªçŸ¥é”™è¯¯')
            error_type = data.get('error_type', 'UnknownError')
            print(f"[{timestamp}] âŒ é”™è¯¯: {error_type} - {error_msg}")
    
    def _analyze_final_literature_data(self, literature_id: str):
        """åˆ†ææœ€ç»ˆçš„æ–‡çŒ®æ•°æ®"""
        try:
            response = requests.get(f"http://localhost:8000/api/literature/{literature_id}")
            
            if response.status_code == 200:
                lit_data = response.json()
                
                print("ğŸ“‹ æœ€ç»ˆæ–‡çŒ®æ•°æ®åˆ†æ:")
                print(f"   ğŸ“ æ ‡é¢˜: {lit_data.get('title', 'N/A')}")
                print(f"   ğŸ‘¥ ä½œè€…: {lit_data.get('authors', [])}")
                print(f"   ğŸ”— DOI: {lit_data.get('doi', 'N/A')}")
                print(f"   ğŸ“„ arXiv ID: {lit_data.get('arxiv_id', 'N/A')}")
                print(f"   ğŸ“… å‘å¸ƒæ—¥æœŸ: {lit_data.get('published_date', 'N/A')}")
                print(f"   ğŸ“– æ‘˜è¦é•¿åº¦: {len(lit_data.get('abstract', '')) if lit_data.get('abstract') else 0} å­—ç¬¦")
                
                # åˆ†ææ ‡è¯†ç¬¦
                identifiers = lit_data.get('identifiers', {})
                print(f"   ğŸ·ï¸ æ ‡è¯†ç¬¦: {identifiers}")
                
                # åˆ†æå…ƒæ•°æ®æ¥æº
                metadata = lit_data.get('metadata', {})
                if metadata:
                    print(f"   ğŸ“Š å…ƒæ•°æ®å­—æ®µæ•°: {len(metadata)}")
                    print(f"   ğŸ“Š å…ƒæ•°æ®é”®: {list(metadata.keys())}")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å¤„ç†å†å²
                task_info = lit_data.get('task_info', {})
                if task_info:
                    print(f"   âš™ï¸ ä»»åŠ¡çŠ¶æ€: {task_info.get('status', 'N/A')}")
                    print(f"   âš™ï¸ å®Œæˆæ—¶é—´: {task_info.get('completed_at', 'N/A')}")
                
                return lit_data
            else:
                print(f"âŒ æ— æ³•è·å–æ–‡çŒ®æ•°æ®: {response.status_code}")
                
        except Exception as e:
            print(f"âŒ åˆ†ææ–‡çŒ®æ•°æ®å¼‚å¸¸: {e}")
        
        return None
    
    def generate_diagnosis_report(self):
        """ç”Ÿæˆè¯Šæ–­æŠ¥å‘Š"""
        print("\n" + "=" * 70)
        print("ğŸ”¬ è¯Šæ–­æŠ¥å‘Š")
        print("=" * 70)
        
        print(f"ğŸ“Š å¤„ç†ç»Ÿè®¡:")
        print(f"   - æ€»äº‹ä»¶æ•°: {len(self.events)}")
        print(f"   - SSEè¿æ¥: {'âœ… æˆåŠŸ' if self.is_connected else 'âŒ å¤±è´¥'}")
        
        if self.metadata_details:
            print(f"\nğŸ” å…ƒæ•°æ®ç»„ä»¶è¯¦æƒ…:")
            print(f"   - çŠ¶æ€: {self.metadata_details.get('status', 'N/A')}")
            print(f"   - é˜¶æ®µ: {self.metadata_details.get('stage', 'N/A')}")
            print(f"   - æ¥æº: {self.metadata_details.get('source', 'N/A')}")
            print(f"   - å°è¯•æ¬¡æ•°: {self.metadata_details.get('attempts', 'N/A')}")
            
            if self.metadata_details.get('error_info'):
                print(f"   - é”™è¯¯ä¿¡æ¯: {self.metadata_details['error_info']}")
        
        # é—®é¢˜åˆ†æ
        print(f"\nğŸ¯ é—®é¢˜åˆ†æ:")
        
        if self.metadata_details.get('source') == 'fallback':
            print("âš ï¸ å…ƒæ•°æ®ä½¿ç”¨äº†fallbackæ¥æºï¼Œè¯´æ˜ä¸»è¦APIéƒ½å¤±è´¥äº†")
            print("   å¯èƒ½åŸå› :")
            print("   1. CrossRef APIæ— æ³•æ‰¾åˆ°è¯¥è®ºæ–‡")
            print("   2. Semantic Scholar APIæ— æ³•æ‰¾åˆ°è¯¥è®ºæ–‡")
            print("   3. GROBIDè§£æPDFå¤±è´¥")
            print("   4. ç³»ç»Ÿå›é€€åˆ°äº†åŸºç¡€çš„URLè§£æ")
        
        if hasattr(self, 'literature_id'):
            print(f"âœ… ä»»åŠ¡å®Œæˆï¼Œä½†å…ƒæ•°æ®è´¨é‡å¯èƒ½æœ‰é—®é¢˜")
            print(f"   å»ºè®®æ£€æŸ¥å„ä¸ªAPIçš„å“åº”å’Œé”™è¯¯æ—¥å¿—")
        else:
            print(f"âŒ ä»»åŠ¡æœªå®Œæˆæˆ–å‡ºç°ä¸¥é‡é”™è¯¯")


def main():
    """ä¸»è¯Šæ–­å‡½æ•°"""
    print("ğŸš€ å¼€å§‹arXivå…ƒæ•°æ®è¯Šæ–­...")
    
    diagnoser = ArXivMetadataDiagnoser()
    
    # è¯Šæ–­é—®é¢˜è®ºæ–‡
    arxiv_url = "https://arxiv.org/abs/2301.00001"
    diagnoser.diagnose_arxiv_paper(arxiv_url)
    
    # ç”Ÿæˆè¯Šæ–­æŠ¥å‘Š
    diagnoser.generate_diagnosis_report()


if __name__ == "__main__":
    main()

#!/usr/bin/env python3
"""
åˆ«åç³»ç»Ÿå®Œæ•´åŠŸèƒ½æµ‹è¯•

è¿™æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„æµ‹è¯•è„šæœ¬ï¼Œç”¨äºéªŒè¯åˆ«åç³»ç»Ÿçš„æ ¸å¿ƒåŠŸèƒ½ã€‚
"""

import asyncio
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from literature_parser_backend.models.alias import (
    AliasModel,
    AliasType,
    normalize_alias_value,
    extract_aliases_from_source,
)


def test_alias_models():
    """æµ‹è¯•åˆ«åæ•°æ®æ¨¡å‹"""
    print("=== æµ‹è¯•åˆ«åæ•°æ®æ¨¡å‹ ===")
    
    # æµ‹è¯•AliasTypeæšä¸¾
    print(f"æ”¯æŒçš„åˆ«åç±»å‹: {[t.value for t in AliasType]}")
    
    # æµ‹è¯•AliasModelåˆ›å»º
    alias = AliasModel(
        alias_type=AliasType.DOI,
        alias_value="10.48550/arXiv.1706.03762",
        lid="2017-vaswani-aiaynu-a8c4",
        confidence=1.0
    )
    
    print(f"åˆ›å»ºåˆ«åæ¨¡å‹: {alias.alias_type}={alias.alias_value} -> {alias.lid}")
    
    # æµ‹è¯•æ¨¡å‹éªŒè¯
    try:
        invalid_alias = AliasModel(
            alias_type=AliasType.DOI,
            alias_value="",  # ç©ºå€¼åº”è¯¥å¤±è´¥
            lid="test-lid",
            confidence=2.0  # è¶…å‡ºèŒƒå›´åº”è¯¥å¤±è´¥
        )
    except Exception as e:
        print(f"æ¨¡å‹éªŒè¯æ­£å¸¸å·¥ä½œï¼Œæ•è·é”™è¯¯: {type(e).__name__}")
    
    print("âœ“ åˆ«åæ•°æ®æ¨¡å‹æµ‹è¯•é€šè¿‡\n")


def test_normalize_alias_value():
    """æµ‹è¯•åˆ«åå€¼æ ‡å‡†åŒ–"""
    print("=== æµ‹è¯•åˆ«åå€¼æ ‡å‡†åŒ– ===")
    
    test_cases = [
        # DOIæ ‡å‡†åŒ–
        (AliasType.DOI, "https://doi.org/10.1038/nature12345", "10.1038/nature12345"),
        (AliasType.DOI, "http://doi.org/10.1038/nature12345", "10.1038/nature12345"),
        (AliasType.DOI, "doi:10.1038/nature12345", "10.1038/nature12345"),
        (AliasType.DOI, "10.1038/NATURE12345", "10.1038/nature12345"),
        
        # ArXiv IDæ ‡å‡†åŒ–
        (AliasType.ARXIV, "https://arxiv.org/abs/1706.03762", "1706.03762"),
        (AliasType.ARXIV, "arxiv:1706.03762", "1706.03762"),
        (AliasType.ARXIV, "1706.03762V1", "1706.03762v1"),
        
        # URLä¿æŒä¸å˜ï¼ˆé™¤äº†trimï¼‰
        (AliasType.URL, "  https://example.com/paper  ", "https://example.com/paper"),
        
        # æ ‡é¢˜æ ‡å‡†åŒ–
        (AliasType.TITLE, "  Attention Is All You Need  ", "attention is all you need"),
    ]
    
    for alias_type, input_value, expected in test_cases:
        result = normalize_alias_value(alias_type, input_value)
        status = "âœ“" if result == expected else "âœ—"
        print(f"{status} {alias_type.value}: '{input_value}' -> '{result}' (æœŸæœ›: '{expected}')")
    
    print("âœ“ åˆ«åå€¼æ ‡å‡†åŒ–æµ‹è¯•å®Œæˆ\n")


def test_extract_aliases_from_source():
    """æµ‹è¯•ä»æºæ•°æ®æå–åˆ«å"""
    print("=== æµ‹è¯•ä»æºæ•°æ®æå–åˆ«å ===")
    
    # æµ‹è¯•å®Œæ•´çš„æºæ•°æ®
    source_data = {
        "doi": "10.48550/arXiv.1706.03762",
        "arxiv_id": "1706.03762",
        "url": "https://arxiv.org/abs/1706.03762",
        "pdf_url": "https://arxiv.org/pdf/1706.03762.pdf",
        "title": "Attention Is All You Need",
        "pmid": "12345678"
    }
    
    aliases = extract_aliases_from_source(source_data)
    
    print(f"è¾“å…¥æºæ•°æ®åŒ…å« {len(source_data)} ä¸ªå­—æ®µ")
    print(f"æå–åˆ° {len(aliases)} ä¸ªåˆ«å:")
    
    for alias_type, alias_value in aliases.items():
        print(f"  {alias_type.value}: {alias_value}")
    
    # æµ‹è¯•éƒ¨åˆ†æ•°æ®
    partial_data = {
        "url": "https://example.com/paper",
        "title": "Some Research Paper"
    }
    
    partial_aliases = extract_aliases_from_source(partial_data)
    print(f"\néƒ¨åˆ†æ•°æ®æå–åˆ° {len(partial_aliases)} ä¸ªåˆ«å:")
    for alias_type, alias_value in partial_aliases.items():
        print(f"  {alias_type.value}: {alias_value}")
    
    print("âœ“ æºæ•°æ®åˆ«åæå–æµ‹è¯•å®Œæˆ\n")


async def test_alias_dao_simulation():
    """æ¨¡æ‹Ÿæµ‹è¯•åˆ«åDAOåŠŸèƒ½ï¼ˆä¸éœ€è¦çœŸå®æ•°æ®åº“ï¼‰"""
    print("=== æ¨¡æ‹Ÿåˆ«åDAOåŠŸèƒ½æµ‹è¯• ===")
    
    # æ¨¡æ‹Ÿåˆ«åå­˜å‚¨
    alias_storage = {}
    
    async def mock_create_mapping(alias_type, alias_value, lid, confidence=1.0):
        normalized_value = normalize_alias_value(alias_type, alias_value)
        key = f"{alias_type.value}:{normalized_value}"
        
        if key in alias_storage:
            print(f"  åˆ«åæ˜ å°„å·²å­˜åœ¨: {key} -> {alias_storage[key]}")
            return "existing_id"
        
        alias_storage[key] = lid
        print(f"  åˆ›å»ºåˆ«åæ˜ å°„: {key} -> {lid}")
        return "new_mapping_id"
    
    async def mock_lookup_alias(alias_type, alias_value):
        normalized_value = normalize_alias_value(alias_type, alias_value)
        key = f"{alias_type.value}:{normalized_value}"
        return alias_storage.get(key)
    
    # æµ‹è¯•åˆ›å»ºæ˜ å°„
    await mock_create_mapping(AliasType.DOI, "10.1038/nature12345", "2023-smith-paper-a1b2")
    await mock_create_mapping(AliasType.ARXIV, "1706.03762", "2017-vaswani-aiaynu-c3d4")
    await mock_create_mapping(AliasType.URL, "https://example.com/paper", "2023-smith-paper-a1b2")
    
    # æµ‹è¯•æŸ¥æ‰¾
    test_lookups = [
        (AliasType.DOI, "10.1038/nature12345"),
        (AliasType.DOI, "https://doi.org/10.1038/nature12345"),  # åº”è¯¥æ‰¾åˆ°ç›¸åŒçš„æ˜ å°„
        (AliasType.ARXIV, "https://arxiv.org/abs/1706.03762"),  # åº”è¯¥æ‰¾åˆ°ArXivæ˜ å°„
        (AliasType.DOI, "10.1000/nonexistent"),  # ä¸åº”è¯¥æ‰¾åˆ°
    ]
    
    print("\næŸ¥æ‰¾æµ‹è¯•:")
    for alias_type, alias_value in test_lookups:
        result = await mock_lookup_alias(alias_type, alias_value)
        status = "æ‰¾åˆ°" if result else "æœªæ‰¾åˆ°"
        print(f"  æŸ¥æ‰¾ {alias_type.value}='{alias_value}': {status} {result or ''}")
    
    print(f"\nåˆ«åå­˜å‚¨çŠ¶æ€ ({len(alias_storage)} ä¸ªæ˜ å°„):")
    for key, lid in alias_storage.items():
        print(f"  {key} -> {lid}")
    
    print("âœ“ åˆ«åDAOåŠŸèƒ½æ¨¡æ‹Ÿæµ‹è¯•å®Œæˆ\n")


def test_edge_cases():
    """æµ‹è¯•è¾¹ç¼˜æƒ…å†µ"""
    print("=== æµ‹è¯•è¾¹ç¼˜æƒ…å†µ ===")
    
    # æµ‹è¯•ç©ºå€¼å¤„ç†
    empty_source = {}
    empty_aliases = extract_aliases_from_source(empty_source)
    print(f"ç©ºæºæ•°æ®æå–åˆ«åæ•°é‡: {len(empty_aliases)}")
    
    # æµ‹è¯•Noneå€¼
    none_source = {
        "doi": None,
        "url": "",
        "title": "   ",  # åªæœ‰ç©ºæ ¼
    }
    none_aliases = extract_aliases_from_source(none_source)
    print(f"åŒ…å«None/ç©ºå€¼çš„æºæ•°æ®æå–åˆ«åæ•°é‡: {len(none_aliases)}")
    
    # æµ‹è¯•ç‰¹æ®Šå­—ç¬¦
    special_source = {
        "title": "Paper with Special Characters: A Study of AI/ML & NLP!",
        "url": "https://example.com/path?param=value&other=123"
    }
    special_aliases = extract_aliases_from_source(special_source)
    print(f"åŒ…å«ç‰¹æ®Šå­—ç¬¦çš„æ•°æ®:")
    for alias_type, alias_value in special_aliases.items():
        print(f"  {alias_type.value}: '{alias_value}'")
    
    print("âœ“ è¾¹ç¼˜æƒ…å†µæµ‹è¯•å®Œæˆ\n")


def test_workflow_simulation():
    """æ¨¡æ‹Ÿå®Œæ•´å·¥ä½œæµç¨‹"""
    print("=== æ¨¡æ‹Ÿå®Œæ•´å·¥ä½œæµç¨‹ ===")
    
    # åœºæ™¯1: ç”¨æˆ·ç¬¬ä¸€æ¬¡æäº¤DOI
    print("åœºæ™¯1: é¦–æ¬¡æäº¤DOI")
    source_data_1 = {"doi": "10.1038/nature12345"}
    aliases_1 = extract_aliases_from_source(source_data_1)
    print(f"  æå–åˆ«å: {list(aliases_1.keys())}")
    print("  -> æœªæ‰¾åˆ°ç°æœ‰æ˜ å°„ï¼Œåˆ›å»ºæ–°ä»»åŠ¡")
    print("  -> ä»»åŠ¡å®Œæˆååˆ›å»ºåˆ«åæ˜ å°„: DOI -> LID")
    
    # åœºæ™¯2: ç”¨æˆ·ç”¨ç›¸åŒDOIå†æ¬¡æäº¤
    print("\nåœºæ™¯2: ç›¸åŒDOIå†æ¬¡æäº¤")
    source_data_2 = {"doi": "10.1038/nature12345"}
    print("  -> åˆ«åç³»ç»Ÿå‘½ä¸­ï¼Œç«‹å³è¿”å›LID")
    print("  -> æ— éœ€åˆ›å»ºä»»åŠ¡ï¼Œæ€§èƒ½å¤§å¹…æå‡")
    
    # åœºæ™¯3: ç”¨æˆ·ç”¨ä¸åŒæ ‡è¯†ç¬¦ï¼ˆURLï¼‰æäº¤ç›¸åŒæ–‡çŒ®
    print("\nåœºæ™¯3: ç”¨URLæäº¤ç›¸åŒæ–‡çŒ®")
    source_data_3 = {"url": "https://nature.com/articles/nature12345"}
    print("  -> åˆ«åç³»ç»Ÿæœªå‘½ä¸­ï¼ˆURLæœªè®°å½•ï¼‰")
    print("  -> åˆ›å»ºä»»åŠ¡ï¼Œå»é‡å‘ç°ç°æœ‰æ–‡çŒ®")
    print("  -> è®°å½•æ–°çš„åˆ«åæ˜ å°„: URL -> ç°æœ‰LID")
    
    # åœºæ™¯4: åç»­ç”¨è¯¥URLæäº¤
    print("\nåœºæ™¯4: ç”¨ç›¸åŒURLå†æ¬¡æäº¤")
    print("  -> åˆ«åç³»ç»Ÿå‘½ä¸­æ–°è®°å½•çš„URLæ˜ å°„")
    print("  -> ç«‹å³è¿”å›LIDï¼Œæ— éœ€ä»»åŠ¡å¤„ç†")
    
    print("âœ“ å·¥ä½œæµç¨‹æ¨¡æ‹Ÿå®Œæˆ\n")


async def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸ§ª åˆ«åç³»ç»Ÿå®Œæ•´åŠŸèƒ½æµ‹è¯•\n")
    
    test_alias_models()
    test_normalize_alias_value()
    test_extract_aliases_from_source()
    await test_alias_dao_simulation()
    test_edge_cases()
    test_workflow_simulation()
    
    print("ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼åˆ«åç³»ç»ŸåŠŸèƒ½æ­£å¸¸å·¥ä½œã€‚")
    print("\nğŸ“‹ æµ‹è¯•æ€»ç»“:")
    print("âœ“ åˆ«åæ•°æ®æ¨¡å‹åˆ›å»ºå’ŒéªŒè¯")
    print("âœ“ åˆ«åå€¼æ ‡å‡†åŒ–å¤„ç†")
    print("âœ“ æºæ•°æ®åˆ«åæå–")
    print("âœ“ åˆ«åæ˜ å°„åˆ›å»ºå’ŒæŸ¥æ‰¾")
    print("âœ“ è¾¹ç¼˜æƒ…å†µå¤„ç†")
    print("âœ“ å®Œæ•´å·¥ä½œæµç¨‹æ¨¡æ‹Ÿ")


if __name__ == "__main__":
    try:
        asyncio.run(run_all_tests())
    except KeyboardInterrupt:
        print("\næµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\næµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

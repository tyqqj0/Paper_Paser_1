#!/usr/bin/env python3
"""
æµ‹è¯•arXiv APIä¿®å¤æ•ˆæœ

éªŒè¯æ–°å¢çš„arXiv Official APIæ˜¯å¦èƒ½æ­£ç¡®è·å–å…ƒæ•°æ®
"""

import requests
import json
import time
import threading
from typing import Dict, Any


class ArXivAPIFixTester:
    """arXiv APIä¿®å¤æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.events = []
        self.metadata_sources = []
        self.final_literature_data = None
        self.is_connected = False
        self.error = None
        
    def test_arxiv_api_fix(self, arxiv_url: str):
        """æµ‹è¯•arXiv APIä¿®å¤æ•ˆæœ"""
        print(f"ğŸ§ª æµ‹è¯•arXiv APIä¿®å¤: {arxiv_url}")
        print("=" * 70)
        
        # 1. é¦–å…ˆæµ‹è¯•arXivå®˜æ–¹APIç›´æ¥è°ƒç”¨
        print("ğŸ” æ­¥éª¤1: æµ‹è¯•arXivå®˜æ–¹APIç›´æ¥è°ƒç”¨")
        self._test_direct_arxiv_api(arxiv_url)
        
        # 2. æµ‹è¯•æˆ‘ä»¬çš„SSEç«¯ç‚¹
        print(f"\nğŸ” æ­¥éª¤2: æµ‹è¯•æˆ‘ä»¬çš„SSEç«¯ç‚¹å¤„ç†")
        self._test_our_sse_endpoint(arxiv_url)
        
        # 3. åˆ†ææœ€ç»ˆç»“æœ
        print(f"\nğŸ” æ­¥éª¤3: åˆ†æå¤„ç†ç»“æœ")
        self._analyze_results()
    
    def _test_direct_arxiv_api(self, arxiv_url: str):
        """ç›´æ¥æµ‹è¯•arXiv API"""
        # æå–arXiv ID
        arxiv_id = None
        if 'arxiv.org/abs/' in arxiv_url:
            arxiv_id = arxiv_url.split('arxiv.org/abs/')[-1]
        
        if not arxiv_id:
            print("âŒ æ— æ³•ä»URLä¸­æå–arXiv ID")
            return
        
        print(f"ğŸ“‹ arXiv ID: {arxiv_id}")
        
        try:
            # è°ƒç”¨arXivå®˜æ–¹API
            api_url = f"http://export.arxiv.org/api/query?id_list={arxiv_id}"
            response = requests.get(api_url, timeout=10)
            
            if response.status_code == 200:
                print("âœ… arXivå®˜æ–¹APIå“åº”æˆåŠŸ")
                
                # è§£æå“åº”
                content = response.text
                
                # æå–æ ‡é¢˜
                if '<title>' in content:
                    title_start = content.find('<title>') + 7
                    title_end = content.find('</title>', title_start)
                    title = content[title_start:title_end].strip()
                    print(f"   ğŸ“ æ ‡é¢˜: {title}")
                
                # æå–ä½œè€…æ•°é‡
                author_count = content.count('<name>')
                print(f"   ğŸ‘¥ ä½œè€…æ•°é‡: {author_count}")
                
                # æå–æ‘˜è¦é•¿åº¦
                if '<summary>' in content:
                    summary_start = content.find('<summary>') + 9
                    summary_end = content.find('</summary>', summary_start)
                    summary = content[summary_start:summary_end].strip()
                    print(f"   ğŸ“„ æ‘˜è¦é•¿åº¦: {len(summary)} å­—ç¬¦")
                
                print("âœ… arXivå®˜æ–¹APIèƒ½å¤Ÿæ­£å¸¸è·å–å…ƒæ•°æ®")
            else:
                print(f"âŒ arXivå®˜æ–¹APIå“åº”å¤±è´¥: {response.status_code}")
                
        except Exception as e:
            print(f"âŒ arXivå®˜æ–¹APIæµ‹è¯•å¼‚å¸¸: {e}")
    
    def _test_our_sse_endpoint(self, arxiv_url: str):
        """æµ‹è¯•æˆ‘ä»¬çš„SSEç«¯ç‚¹"""
        test_data = {
            "source": {
                "url": arxiv_url
            }
        }
        
        try:
            response = requests.post(
                "http://localhost:8000/api/literature/stream",
                json=test_data,
                headers={
                    'Accept': 'text/event-stream',
                    'Cache-Control': 'no-cache'
                },
                stream=True,
                timeout=90  # å¢åŠ è¶…æ—¶æ—¶é—´
            )
            
            if response.status_code != 200:
                self.error = f"HTTP {response.status_code}: {response.text}"
                print(f"âŒ SSEè¿æ¥å¤±è´¥: {self.error}")
                return
            
            self.is_connected = True
            print("âœ… SSEè¿æ¥å»ºç«‹æˆåŠŸ")
            print("\nğŸ“Š å¤„ç†è¿‡ç¨‹ç›‘æ§:")
            print("-" * 50)
            
            for line in response.iter_lines(decode_unicode=True):
                if line:
                    self._process_sse_line(line)
                    
        except Exception as e:
            self.error = str(e)
            print(f"âŒ SSEæµ‹è¯•å¼‚å¸¸: {e}")
    
    def _process_sse_line(self, line: str):
        """å¤„ç†SSEè¡Œæ•°æ®"""
        if line.startswith('event:'):
            event_type = line[6:].strip()
            self.current_event_type = event_type
        elif line.startswith('data:'):
            data = line[5:].strip()
            try:
                event_data = json.loads(data)
                event = {
                    'type': getattr(self, 'current_event_type', 'message'),
                    'data': event_data,
                    'timestamp': time.time()
                }
                self.events.append(event)
                self._analyze_sse_event(event)
            except json.JSONDecodeError:
                print(f"âš ï¸ æ— æ³•è§£æJSONæ•°æ®: {data}")
    
    def _analyze_sse_event(self, event: Dict[str, Any]):
        """åˆ†æSSEäº‹ä»¶"""
        event_type = event['type']
        data = event['data']
        timestamp = time.strftime('%H:%M:%S', time.localtime(event['timestamp']))
        
        if event_type == 'status':
            execution_status = data.get('execution_status')
            stage = data.get('current_stage', 'N/A')
            progress = data.get('overall_progress', 0)
            
            print(f"[{timestamp}] ğŸ“Š {execution_status} - {progress}% - {stage}")
            
            # é‡ç‚¹å…³æ³¨å…ƒæ•°æ®ç»„ä»¶
            lit_status = data.get('literature_status')
            if lit_status:
                comp_status = lit_status.get('component_status', {})
                metadata_comp = comp_status.get('metadata')
                
                if metadata_comp:
                    meta_status = metadata_comp.get('status')
                    meta_stage = metadata_comp.get('stage', 'N/A')
                    meta_source = metadata_comp.get('source')
                    
                    if meta_source and meta_source not in self.metadata_sources:
                        self.metadata_sources.append(meta_source)
                        print(f"           ğŸ” å…ƒæ•°æ®æ¥æº: {meta_source}")
                    
                    if meta_status == 'success' and meta_source:
                        print(f"           âœ… å…ƒæ•°æ®è·å–æˆåŠŸï¼Œæ¥æº: {meta_source}")
                        
        elif event_type == 'completed':
            literature_id = data.get('literature_id')
            print(f"[{timestamp}] ğŸ‰ ä»»åŠ¡å®Œæˆ! Literature ID: {literature_id}")
            self.literature_id = literature_id
            
        elif event_type == 'error':
            error_msg = data.get('error', 'æœªçŸ¥é”™è¯¯')
            error_type = data.get('error_type', 'UnknownError')
            print(f"[{timestamp}] âŒ é”™è¯¯: {error_type} - {error_msg}")
    
    def _analyze_results(self):
        """åˆ†ææœ€ç»ˆç»“æœ"""
        if not hasattr(self, 'literature_id'):
            print("âŒ ä»»åŠ¡æœªå®Œæˆï¼Œæ— æ³•åˆ†æç»“æœ")
            return
        
        try:
            # è·å–æœ€ç»ˆçš„æ–‡çŒ®æ•°æ®
            response = requests.get(f"http://localhost:8000/api/literature/{self.literature_id}")
            
            if response.status_code == 200:
                self.final_literature_data = response.json()
                
                print("ğŸ“‹ æœ€ç»ˆæ–‡çŒ®æ•°æ®åˆ†æ:")
                print(f"   ğŸ“ æ ‡é¢˜: {self.final_literature_data.get('title', 'N/A')}")
                print(f"   ğŸ‘¥ ä½œè€…æ•°é‡: {len(self.final_literature_data.get('authors', []))}")
                print(f"   ğŸ”— DOI: {self.final_literature_data.get('doi', 'N/A')}")
                print(f"   ğŸ“„ arXiv ID: {self.final_literature_data.get('arxiv_id', 'N/A')}")
                print(f"   ğŸ“… å¹´ä»½: {self.final_literature_data.get('year', 'N/A')}")
                
                abstract = self.final_literature_data.get('abstract', '')
                print(f"   ğŸ“– æ‘˜è¦é•¿åº¦: {len(abstract) if abstract else 0} å­—ç¬¦")
                
                # æ£€æŸ¥æ ‡é¢˜è´¨é‡
                title = self.final_literature_data.get('title', '')
                if title.startswith('Processing:') or title.startswith('https://'):
                    print("   âŒ æ ‡é¢˜è´¨é‡å·®ï¼Œä»ç„¶æ˜¯URLæ ¼å¼")
                else:
                    print("   âœ… æ ‡é¢˜è´¨é‡è‰¯å¥½")
                
            else:
                print(f"âŒ æ— æ³•è·å–æ–‡çŒ®æ•°æ®: {response.status_code}")
                
        except Exception as e:
            print(f"âŒ åˆ†æç»“æœå¼‚å¸¸: {e}")
    
    def generate_fix_report(self):
        """ç”Ÿæˆä¿®å¤æ•ˆæœæŠ¥å‘Š"""
        print("\n" + "=" * 70)
        print("ğŸ”¬ arXiv APIä¿®å¤æ•ˆæœæŠ¥å‘Š")
        print("=" * 70)
        
        print(f"ğŸ“Š å¤„ç†ç»Ÿè®¡:")
        print(f"   - æ€»äº‹ä»¶æ•°: {len(self.events)}")
        print(f"   - SSEè¿æ¥: {'âœ… æˆåŠŸ' if self.is_connected else 'âŒ å¤±è´¥'}")
        print(f"   - å…ƒæ•°æ®æ¥æº: {self.metadata_sources}")
        
        # è¯„ä¼°ä¿®å¤æ•ˆæœ
        fix_success = False
        
        if self.final_literature_data:
            title = self.final_literature_data.get('title', '')
            authors = self.final_literature_data.get('authors', [])
            abstract = self.final_literature_data.get('abstract', '')
            
            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†arXiv API
            used_arxiv_api = 'arXiv Official API' in self.metadata_sources or 'arxiv_api' in self.metadata_sources
            
            # æ£€æŸ¥æ•°æ®è´¨é‡
            good_title = not (title.startswith('Processing:') or title.startswith('https://'))
            has_authors = len(authors) > 0
            has_abstract = len(abstract) > 100  # è‡³å°‘100å­—ç¬¦çš„æ‘˜è¦
            
            print(f"\nğŸ¯ ä¿®å¤æ•ˆæœè¯„ä¼°:")
            print(f"   - ä½¿ç”¨arXiv API: {'âœ…' if used_arxiv_api else 'âŒ'}")
            print(f"   - æ ‡é¢˜è´¨é‡: {'âœ…' if good_title else 'âŒ'}")
            print(f"   - åŒ…å«ä½œè€…: {'âœ…' if has_authors else 'âŒ'}")
            print(f"   - åŒ…å«æ‘˜è¦: {'âœ…' if has_abstract else 'âŒ'}")
            
            fix_success = used_arxiv_api and good_title and has_authors and has_abstract
            
            if fix_success:
                print("\nğŸ‰ arXiv APIä¿®å¤æˆåŠŸï¼")
                print("   ç³»ç»Ÿç°åœ¨èƒ½å¤Ÿæ­£ç¡®è·å–arXivè®ºæ–‡çš„å®Œæ•´å…ƒæ•°æ®")
            else:
                print("\nâš ï¸ arXiv APIä¿®å¤éƒ¨åˆ†æˆåŠŸ")
                print("   ä»æœ‰ä¸€äº›é—®é¢˜éœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")
        else:
            print("\nâŒ æ— æ³•è¯„ä¼°ä¿®å¤æ•ˆæœï¼Œä»»åŠ¡æœªå®Œæˆ")
        
        return fix_success


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹arXiv APIä¿®å¤æ•ˆæœæµ‹è¯•...")
    
    tester = ArXivAPIFixTester()
    
    # æµ‹è¯•ä¸€ä¸ªæ–°çš„arXivè®ºæ–‡
    arxiv_url = "https://arxiv.org/abs/2301.00003"  # ä½¿ç”¨ä¸€ä¸ªä¸åŒçš„ID
    tester.test_arxiv_api_fix(arxiv_url)
    
    # ç”Ÿæˆä¿®å¤æŠ¥å‘Š
    success = tester.generate_fix_report()
    
    if success:
        print("\nâœ… arXivå…ƒæ•°æ®è·å–é—®é¢˜å·²ä¿®å¤ï¼")
    else:
        print("\nâš ï¸ éœ€è¦è¿›ä¸€æ­¥è°ƒè¯•arXiv APIé›†æˆ")


if __name__ == "__main__":
    main()

#!/usr/bin/env python3
"""
æ•°æ®åº“è¿ç§»è„šæœ¬
å°†ç°æœ‰æ•°æ®ä»adminæ•°æ®åº“è¿ç§»åˆ°literature_parseræ•°æ®åº“
"""

import pymongo
from bson import ObjectId
import logging
from datetime import datetime

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def migrate_database():
    """æ‰§è¡Œæ•°æ®åº“è¿ç§»"""
    
    # è¿æ¥MongoDB
    client = pymongo.MongoClient(
        "mongodb://literature_parser_backend:literature_parser_backend@localhost:27017/admin"
    )
    
    try:
        # æºæ•°æ®åº“å’Œé›†åˆ
        source_db = client["admin"]
        target_db = client["literature_parser"]
        
        # æ£€æŸ¥æºæ•°æ®
        source_collections = ["literature", "literatures"]
        total_migrated = 0
        
        for collection_name in source_collections:
            if collection_name in source_db.list_collection_names():
                source_collection = source_db[collection_name]
                count = source_collection.count_documents({})
                
                if count > 0:
                    logger.info(f"å‘ç° {count} ä¸ªæ–‡æ¡£åœ¨ admin.{collection_name}")
                    
                    # ç›®æ ‡é›†åˆï¼ˆç»Ÿä¸€ä½¿ç”¨literaturesï¼‰
                    target_collection = target_db["literatures"]
                    
                    # è¿ç§»æ•°æ®
                    documents = list(source_collection.find({}))
                    
                    for doc in documents:
                        # æ£€æŸ¥ç›®æ ‡æ•°æ®åº“ä¸­æ˜¯å¦å·²å­˜åœ¨ç›¸åŒçš„æ–‡æ¡£
                        existing = target_collection.find_one({"_id": doc["_id"]})
                        
                        if not existing:
                            # æ’å…¥åˆ°ç›®æ ‡æ•°æ®åº“
                            target_collection.insert_one(doc)
                            logger.info(f"è¿ç§»æ–‡æ¡£: {doc['_id']}")
                            total_migrated += 1
                        else:
                            logger.info(f"è·³è¿‡å·²å­˜åœ¨çš„æ–‡æ¡£: {doc['_id']}")
        
        # éªŒè¯è¿ç§»ç»“æœ
        target_count = target_db["literatures"].count_documents({})
        logger.info(f"âœ… è¿ç§»å®Œæˆï¼è¿ç§»äº† {total_migrated} ä¸ªæ–‡æ¡£")
        logger.info(f"ğŸ“Š ç›®æ ‡æ•°æ®åº“ç°åœ¨æœ‰ {target_count} ä¸ªæ–‡æ¡£")
        
        # åˆ›å»ºç´¢å¼•
        logger.info("ğŸ”§ åˆ›å»ºç´¢å¼•...")
        target_collection = target_db["literatures"]
        
        indexes = [
            ("identifiers.doi", 1),
            ("identifiers.arxiv_id", 1),
            ("identifiers.fingerprint", 1),
            ("task_info.task_id", 1),
            ("created_at", -1),
        ]
        
        for index_spec in indexes:
            try:
                target_collection.create_index(index_spec)
                logger.info(f"åˆ›å»ºç´¢å¼•: {index_spec}")
            except Exception as e:
                logger.warning(f"ç´¢å¼•åˆ›å»ºå¤±è´¥ {index_spec}: {e}")
        
        # åˆ›å»ºæ–‡æœ¬æœç´¢ç´¢å¼•
        try:
            target_collection.create_index([
                ("metadata.title", "text"),
                ("metadata.authors.full_name", "text")
            ])
            logger.info("åˆ›å»ºæ–‡æœ¬æœç´¢ç´¢å¼•")
        except Exception as e:
            logger.warning(f"æ–‡æœ¬ç´¢å¼•åˆ›å»ºå¤±è´¥: {e}")
        
        logger.info("âœ… æ•°æ®åº“è¿ç§»å’Œç´¢å¼•åˆ›å»ºå®Œæˆï¼")
        
    except Exception as e:
        logger.error(f"âŒ è¿ç§»å¤±è´¥: {e}")
        raise
    finally:
        client.close()

if __name__ == "__main__":
    migrate_database() 
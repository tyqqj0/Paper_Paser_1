#!/usr/bin/env python3
"""
ä¸šåŠ¡é€»è¾‘å»é‡ç´¢å¼•ä¼˜åŒ–è„šæœ¬

ç§»é™¤æ‰€æœ‰å”¯ä¸€çº¦æŸï¼Œåˆ›å»ºçº¯æŸ¥è¯¢æ€§èƒ½ç´¢å¼•ï¼Œå®Œå…¨ä¾èµ–ä¸šåŠ¡é€»è¾‘è¿›è¡Œå»é‡ã€‚
è¿™æ˜¯å®ç°æ–¹æ¡ˆCçš„å…³é”®æ­¥éª¤ï¼šæ•°æ®åº“ç´¢å¼•ç®€åŒ–ï¼Œä¸šåŠ¡é€»è¾‘å»é‡ã€‚
"""

import asyncio
from motor.motor_asyncio import AsyncIOMotorClient
from pymongo import IndexModel, ASCENDING, TEXT
from pymongo.errors import OperationFailure


async def optimize_business_logic_indexes():
    """ä¼˜åŒ–ç´¢å¼•ä»¥æ”¯æŒçº¯ä¸šåŠ¡é€»è¾‘å»é‡ã€‚"""
    print("ğŸš€ å¼€å§‹ä¼˜åŒ–ç´¢å¼•ä»¥æ”¯æŒä¸šåŠ¡é€»è¾‘å»é‡...")

    # è¿æ¥æ•°æ®åº“ (ä½¿ç”¨å®¹å™¨å†…çš„æœåŠ¡å)
    client = AsyncIOMotorClient(
        "mongodb://literature_parser_backend:literature_parser_backend@db:27017/admin"
    )
    db = client.literature_parser
    collection = db.literatures

    try:
        # 1. åˆ†æå½“å‰ç´¢å¼•çŠ¶æ€
        print("\nğŸ“‹ åˆ†æå½“å‰ç´¢å¼•çŠ¶æ€...")
        existing_indexes = await collection.list_indexes().to_list(length=None)

        print("å½“å‰ç´¢å¼•:")
        unique_indexes = []
        for idx in existing_indexes:
            name = idx.get('name', 'unnamed')
            unique = idx.get('unique', False)
            partial = 'partialFilterExpression' in idx
            
            status = ""
            if unique:
                status += " [UNIQUE]"
                unique_indexes.append(name)
            if partial:
                status += " [PARTIAL]"
                
            print(f"  - {name}: {idx.get('key', {})}{status}")

        # 2. ç§»é™¤æ‰€æœ‰å”¯ä¸€çº¦æŸç´¢å¼•
        print(f"\nğŸ—‘ï¸  ç§»é™¤ {len(unique_indexes)} ä¸ªå”¯ä¸€çº¦æŸç´¢å¼•...")
        
        for index_name in unique_indexes:
            if index_name != "_id_":  # ä¿ç•™MongoDBé»˜è®¤ä¸»é”®ç´¢å¼•
                try:
                    await collection.drop_index(index_name)
                    print(f"  âœ… å·²ç§»é™¤å”¯ä¸€ç´¢å¼•: {index_name}")
                except OperationFailure as e:
                    print(f"  âš ï¸  ç§»é™¤ç´¢å¼•å¤±è´¥ {index_name}: {e}")

        # 3. åˆ›å»ºçº¯æŸ¥è¯¢æ€§èƒ½ç´¢å¼•ï¼ˆæ— å”¯ä¸€çº¦æŸï¼‰
        print("\nğŸ”¨ åˆ›å»ºä¸šåŠ¡é€»è¾‘å»é‡æŸ¥è¯¢ç´¢å¼•...")

        # æ ¸å¿ƒæ ‡è¯†ç¬¦æŸ¥è¯¢ç´¢å¼•ï¼ˆéå”¯ä¸€ï¼‰
        core_query_indexes = [
            IndexModel(
                [("identifiers.doi", ASCENDING)],
                name="doi_query_index",
                background=True,
                partialFilterExpression={"identifiers.doi": {"$type": "string"}}
            ),
            IndexModel(
                [("identifiers.arxiv_id", ASCENDING)],
                name="arxiv_query_index",
                background=True,
                partialFilterExpression={"identifiers.arxiv_id": {"$type": "string"}}
            ),
            IndexModel(
                [("identifiers.pmid", ASCENDING)],
                name="pmid_query_index",
                background=True,
                partialFilterExpression={"identifiers.pmid": {"$type": "string"}}
            ),
        ]

        # å†…å®¹æŒ‡çº¹æŸ¥è¯¢ç´¢å¼•ï¼ˆéå”¯ä¸€ï¼‰
        content_query_indexes = [
            IndexModel(
                [("identifiers.fingerprint", ASCENDING)],
                name="fingerprint_query_index",
                background=True,
                partialFilterExpression={"identifiers.fingerprint": {"$type": "string"}}
            ),
        ]

        # URLæŸ¥è¯¢ç´¢å¼•
        url_query_indexes = [
            IndexModel(
                [("identifiers.source_urls", ASCENDING)], 
                name="source_urls_query_index",
                background=True
            ),
            IndexModel(
                [("content.pdf_url", ASCENDING)],
                name="pdf_url_query_index",
                background=True,
                partialFilterExpression={"content.pdf_url": {"$type": "string"}}
            ),
            IndexModel(
                [("content.source_page_url", ASCENDING)],
                name="source_page_url_query_index",
                background=True,
                partialFilterExpression={"content.source_page_url": {"$type": "string"}}
            ),
        ]

        # ä»»åŠ¡çŠ¶æ€æŸ¥è¯¢ç´¢å¼•
        task_query_indexes = [
            IndexModel(
                [("task_info.task_id", ASCENDING)], 
                name="task_id_query_index",
                background=True
            ),
            IndexModel(
                [("task_info.status", ASCENDING)], 
                name="task_status_query_index",
                background=True
            ),
        ]

        # å…ƒæ•°æ®æŸ¥è¯¢ç´¢å¼•
        metadata_query_indexes = [
            IndexModel(
                [("metadata.title", TEXT)], 
                name="title_text_search_index",
                background=True
            ),
            IndexModel(
                [("metadata.title", ASCENDING)], 
                name="title_exact_query_index",
                background=True
            ),
            IndexModel(
                [("metadata.authors.name", ASCENDING)], 
                name="author_name_query_index",
                background=True
            ),
        ]

        # æ—¶é—´æŸ¥è¯¢ç´¢å¼•
        time_query_indexes = [
            IndexModel(
                [("created_at", ASCENDING)], 
                name="created_at_query_index",
                background=True
            ),
            IndexModel(
                [("updated_at", ASCENDING)], 
                name="updated_at_query_index",
                background=True
            ),
        ]

        # åˆ›å»ºæ‰€æœ‰æŸ¥è¯¢ç´¢å¼•
        all_query_indexes = (
            core_query_indexes + 
            content_query_indexes + 
            url_query_indexes + 
            task_query_indexes + 
            metadata_query_indexes + 
            time_query_indexes
        )

        print(f"åˆ›å»º {len(all_query_indexes)} ä¸ªæŸ¥è¯¢æ€§èƒ½ç´¢å¼•...")

        for index in all_query_indexes:
            try:
                await collection.create_indexes([index])
                print(f"  âœ… åˆ›å»ºæŸ¥è¯¢ç´¢å¼•: {index.document.get('name', 'unnamed')}")
            except OperationFailure as e:
                if "already exists" in str(e).lower():
                    print(f"  â„¹ï¸  ç´¢å¼•å·²å­˜åœ¨: {index.document.get('name', 'unnamed')}")
                else:
                    print(f"  âš ï¸  åˆ›å»ºç´¢å¼•å¤±è´¥ {index.document.get('name', 'unnamed')}: {e}")

        # 4. éªŒè¯æœ€ç»ˆç´¢å¼•çŠ¶æ€
        print("\nğŸ” éªŒè¯æœ€ç»ˆç´¢å¼•çŠ¶æ€...")
        final_indexes = await collection.list_indexes().to_list(length=None)

        unique_count = 0
        query_count = 0
        
        print("æœ€ç»ˆç´¢å¼•åˆ—è¡¨:")
        for idx in final_indexes:
            name = idx.get("name", "unnamed")
            unique = idx.get("unique", False)
            partial = "partialFilterExpression" in idx
            
            if unique and name != "_id_":
                unique_count += 1
                status = " [âš ï¸ UNIQUE]"
            else:
                query_count += 1
                status = " [âœ… QUERY]"
                
            if partial:
                status += " [PARTIAL]"
                
            print(f"  â€¢ {name}{status}")

        print(f"\nğŸ“Š ç´¢å¼•ç»Ÿè®¡:")
        print(f"  â€¢ æŸ¥è¯¢ç´¢å¼•: {query_count} ä¸ª")
        print(f"  â€¢ å”¯ä¸€çº¦æŸ: {unique_count} ä¸ª")
        
        if unique_count <= 1:  # åªæœ‰_id_ç´¢å¼•
            print("  âœ… æˆåŠŸç§»é™¤æ‰€æœ‰ä¸šåŠ¡å”¯ä¸€çº¦æŸ!")
        else:
            print("  âš ï¸  ä»æœ‰ä¸šåŠ¡å”¯ä¸€çº¦æŸå­˜åœ¨")

        print("\nâœ… ä¸šåŠ¡é€»è¾‘å»é‡ç´¢å¼•ä¼˜åŒ–å®Œæˆ!")
        print("\nğŸ“ˆ ä¼˜åŒ–æ•ˆæœ:")
        print("  â€¢ ç§»é™¤æ•°æ®åº“å±‚é¢çš„å”¯ä¸€çº¦æŸå†²çª")
        print("  â€¢ ä¿æŒé«˜æ•ˆçš„æŸ¥è¯¢æ€§èƒ½")
        print("  â€¢ å®Œå…¨ä¾èµ–ä¸šåŠ¡é€»è¾‘è¿›è¡Œå»é‡")
        print("  â€¢ æ”¯æŒå¤æ‚çš„å»é‡ç­–ç•¥å’Œè¾¹ç¼˜æƒ…å†µå¤„ç†")

    except Exception as e:
        print(f"âŒ ç´¢å¼•ä¼˜åŒ–è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

    finally:
        client.close()


if __name__ == "__main__":
    asyncio.run(optimize_business_logic_indexes())

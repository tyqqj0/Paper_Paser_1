#!/usr/bin/env python3
"""
ç´¢å¼•ç»“æ„æœ€ç»ˆç®€åŒ–è„šæœ¬

ç§»é™¤å¤æ‚çš„å¤åˆç´¢å¼•å’Œä¸å¿…è¦çš„ç´¢å¼•ï¼Œåªä¿ç•™æœ€åŸºæœ¬çš„æŸ¥è¯¢æ€§èƒ½ç´¢å¼•ã€‚
å®ç°çœŸæ­£çš„"ç®€åŒ–ç´¢å¼•ï¼Œä¸šåŠ¡é€»è¾‘å»é‡"æ–¹æ¡ˆã€‚
"""

import asyncio
from motor.motor_asyncio import AsyncIOMotorClient
from pymongo import IndexModel, ASCENDING, TEXT
from pymongo.errors import OperationFailure


async def simplify_index_structure():
    """ç®€åŒ–ç´¢å¼•ç»“æ„ï¼Œåªä¿ç•™æ ¸å¿ƒæŸ¥è¯¢ç´¢å¼•ã€‚"""
    print("ğŸš€ å¼€å§‹ç®€åŒ–ç´¢å¼•ç»“æ„...")

    # è¿æ¥æ•°æ®åº“
    client = AsyncIOMotorClient(
        "mongodb://literature_parser_backend:literature_parser_backend@db:27017/admin"
    )
    db = client.literature_parser
    collection = db.literatures

    try:
        # 1. åˆ†æå½“å‰ç´¢å¼•
        print("\nğŸ“‹ åˆ†æå½“å‰ç´¢å¼•ç»“æ„...")
        existing_indexes = await collection.list_indexes().to_list(length=None)

        print("å½“å‰ç´¢å¼•:")
        current_indexes = []
        for idx in existing_indexes:
            name = idx.get('name', 'unnamed')
            current_indexes.append(name)
            unique = idx.get('unique', False)
            partial = 'partialFilterExpression' in idx
            
            status = ""
            if unique:
                status += " [UNIQUE]"
            if partial:
                status += " [PARTIAL]"
                
            print(f"  - {name}: {idx.get('key', {})}{status}")

        # 2. å®šä¹‰æ ¸å¿ƒå¿…éœ€ç´¢å¼•
        print("\nğŸ¯ å®šä¹‰æ ¸å¿ƒå¿…éœ€ç´¢å¼•...")
        
        # æ ¸å¿ƒå¿…éœ€ç´¢å¼•åˆ—è¡¨
        essential_indexes = {
            "_id_": "MongoDBé»˜è®¤ä¸»é”®ç´¢å¼•",
            "doi_query_index": "DOIæŸ¥è¯¢ç´¢å¼•",
            "arxiv_query_index": "ArXiv IDæŸ¥è¯¢ç´¢å¼•", 
            "fingerprint_query_index": "å†…å®¹æŒ‡çº¹æŸ¥è¯¢ç´¢å¼•",
            "task_id_query_index": "ä»»åŠ¡IDæŸ¥è¯¢ç´¢å¼•",
            "title_text_search_index": "æ ‡é¢˜å…¨æ–‡æœç´¢ç´¢å¼•"
        }
        
        print("æ ¸å¿ƒå¿…éœ€ç´¢å¼•:")
        for name, desc in essential_indexes.items():
            print(f"  âœ… {name}: {desc}")

        # 3. è¯†åˆ«å¯ç§»é™¤çš„ç´¢å¼•
        removable_indexes = []
        for idx_name in current_indexes:
            if idx_name not in essential_indexes:
                removable_indexes.append(idx_name)
        
        print(f"\nğŸ—‘ï¸  è¯†åˆ«åˆ° {len(removable_indexes)} ä¸ªå¯ç§»é™¤çš„ç´¢å¼•:")
        for idx_name in removable_indexes:
            print(f"  - {idx_name}")

        # 4. ç§»é™¤éå¿…éœ€ç´¢å¼•
        if removable_indexes:
            print(f"\nğŸ§¹ ç§»é™¤ {len(removable_indexes)} ä¸ªéå¿…éœ€ç´¢å¼•...")
            
            for idx_name in removable_indexes:
                try:
                    await collection.drop_index(idx_name)
                    print(f"  âœ… å·²ç§»é™¤: {idx_name}")
                except OperationFailure as e:
                    print(f"  âš ï¸  ç§»é™¤å¤±è´¥ {idx_name}: {e}")
        else:
            print("\nâœ¨ å½“å‰ç´¢å¼•ç»“æ„å·²ç»æ˜¯æœ€ç®€åŒ–çš„!")

        # 5. ç¡®ä¿æ ¸å¿ƒç´¢å¼•å­˜åœ¨
        print("\nğŸ”§ ç¡®ä¿æ ¸å¿ƒç´¢å¼•å­˜åœ¨...")
        
        # æ£€æŸ¥å¹¶åˆ›å»ºç¼ºå¤±çš„æ ¸å¿ƒç´¢å¼•
        final_indexes = await collection.list_indexes().to_list(length=None)
        existing_names = {idx.get('name') for idx in final_indexes}
        
        missing_indexes = []
        
        # DOIæŸ¥è¯¢ç´¢å¼•
        if "doi_query_index" not in existing_names:
            missing_indexes.append(IndexModel(
                [("identifiers.doi", ASCENDING)], 
                name="doi_query_index",
                background=True,
                partialFilterExpression={"identifiers.doi": {"$type": "string"}}
            ))
        
        # ArXivæŸ¥è¯¢ç´¢å¼•
        if "arxiv_query_index" not in existing_names:
            missing_indexes.append(IndexModel(
                [("identifiers.arxiv_id", ASCENDING)], 
                name="arxiv_query_index",
                background=True,
                partialFilterExpression={"identifiers.arxiv_id": {"$type": "string"}}
            ))
        
        # æŒ‡çº¹æŸ¥è¯¢ç´¢å¼•
        if "fingerprint_query_index" not in existing_names:
            missing_indexes.append(IndexModel(
                [("identifiers.fingerprint", ASCENDING)], 
                name="fingerprint_query_index",
                background=True,
                partialFilterExpression={"identifiers.fingerprint": {"$type": "string"}}
            ))
        
        # ä»»åŠ¡IDæŸ¥è¯¢ç´¢å¼•
        if "task_id_query_index" not in existing_names:
            missing_indexes.append(IndexModel(
                [("task_info.task_id", ASCENDING)], 
                name="task_id_query_index",
                background=True
            ))
        
        # æ ‡é¢˜å…¨æ–‡æœç´¢ç´¢å¼•
        if "title_text_search_index" not in existing_names:
            missing_indexes.append(IndexModel(
                [("metadata.title", TEXT)], 
                name="title_text_search_index",
                background=True
            ))
        
        # åˆ›å»ºç¼ºå¤±çš„ç´¢å¼•
        if missing_indexes:
            print(f"åˆ›å»º {len(missing_indexes)} ä¸ªç¼ºå¤±çš„æ ¸å¿ƒç´¢å¼•...")
            for index in missing_indexes:
                try:
                    await collection.create_indexes([index])
                    print(f"  âœ… åˆ›å»º: {index.document.get('name', 'unnamed')}")
                except OperationFailure as e:
                    print(f"  âš ï¸  åˆ›å»ºå¤±è´¥ {index.document.get('name', 'unnamed')}: {e}")
        else:
            print("æ‰€æœ‰æ ¸å¿ƒç´¢å¼•éƒ½å·²å­˜åœ¨!")

        # 6. éªŒè¯æœ€ç»ˆç´¢å¼•ç»“æ„
        print("\nğŸ” éªŒè¯æœ€ç»ˆç®€åŒ–çš„ç´¢å¼•ç»“æ„...")
        final_indexes = await collection.list_indexes().to_list(length=None)

        print("æœ€ç»ˆç´¢å¼•ç»“æ„:")
        total_indexes = 0
        essential_count = 0
        
        for idx in final_indexes:
            name = idx.get("name", "unnamed")
            total_indexes += 1
            
            if name in essential_indexes:
                essential_count += 1
                status = " [âœ… æ ¸å¿ƒ]"
                desc = essential_indexes[name]
                print(f"  â€¢ {name}: {desc}{status}")
            else:
                status = " [âš ï¸ é¢å¤–]"
                print(f"  â€¢ {name}: é¢å¤–ç´¢å¼•{status}")

        print(f"\nğŸ“Š ç´¢å¼•ç»“æ„ç»Ÿè®¡:")
        print(f"  â€¢ æ€»ç´¢å¼•æ•°: {total_indexes}")
        print(f"  â€¢ æ ¸å¿ƒç´¢å¼•: {essential_count}")
        print(f"  â€¢ é¢å¤–ç´¢å¼•: {total_indexes - essential_count}")
        
        # 7. æ€§èƒ½å»ºè®®
        print(f"\nğŸ’¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®:")
        if total_indexes <= 6:
            print("  âœ… ç´¢å¼•ç»“æ„å·²é«˜åº¦ä¼˜åŒ–")
            print("  âœ… æŸ¥è¯¢æ€§èƒ½ä¸å­˜å‚¨ç©ºé—´è¾¾åˆ°æœ€ä½³å¹³è¡¡")
            print("  âœ… å®Œå…¨ä¾èµ–ä¸šåŠ¡é€»è¾‘è¿›è¡Œå»é‡")
        elif total_indexes <= 10:
            print("  âš ï¸  ç´¢å¼•æ•°é‡é€‚ä¸­ï¼Œå¯è€ƒè™‘è¿›ä¸€æ­¥ç®€åŒ–")
        else:
            print("  âŒ ç´¢å¼•æ•°é‡è¾ƒå¤šï¼Œå»ºè®®è¿›ä¸€æ­¥ç®€åŒ–")

        print("\nâœ… ç´¢å¼•ç»“æ„ç®€åŒ–å®Œæˆ!")
        print("\nğŸ¯ ç®€åŒ–æ•ˆæœ:")
        print("  â€¢ ç§»é™¤äº†æ‰€æœ‰å¤æ‚çš„å¤åˆç´¢å¼•")
        print("  â€¢ ä¿ç•™äº†æ ¸å¿ƒæŸ¥è¯¢æ€§èƒ½ç´¢å¼•")
        print("  â€¢ å®Œå…¨ä¾èµ–ä¸šåŠ¡é€»è¾‘è¿›è¡Œå»é‡")
        print("  â€¢ å‡å°‘äº†ç´¢å¼•ç»´æŠ¤å¼€é”€")
        print("  â€¢ æé«˜äº†å†™å…¥æ€§èƒ½")

    except Exception as e:
        print(f"âŒ ç´¢å¼•ç®€åŒ–è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

    finally:
        client.close()


async def analyze_query_performance():
    """åˆ†ææŸ¥è¯¢æ€§èƒ½"""
    print("\nğŸ“ˆ åˆ†ææŸ¥è¯¢æ€§èƒ½...")
    
    client = AsyncIOMotorClient(
        "mongodb://literature_parser_backend:literature_parser_backend@db:27017/admin"
    )
    db = client.literature_parser
    collection = db.literatures
    
    try:
        # ç»Ÿè®¡æ–‡æ¡£æ•°é‡
        doc_count = await collection.count_documents({})
        print(f"æ–‡æ¡£æ€»æ•°: {doc_count}")
        
        # æµ‹è¯•å…³é”®æŸ¥è¯¢çš„æ€§èƒ½
        queries = [
            {"identifiers.doi": {"$exists": True}},
            {"identifiers.arxiv_id": {"$exists": True}},
            {"identifiers.fingerprint": {"$exists": True}},
            {"task_info.task_id": {"$exists": True}}
        ]
        
        for i, query in enumerate(queries, 1):
            try:
                count = await collection.count_documents(query)
                print(f"æŸ¥è¯¢ {i}: {count} ä¸ªåŒ¹é…æ–‡æ¡£")
            except Exception as e:
                print(f"æŸ¥è¯¢ {i} å¤±è´¥: {e}")
                
    except Exception as e:
        print(f"æ€§èƒ½åˆ†æå¤±è´¥: {e}")
    finally:
        client.close()


if __name__ == "__main__":
    asyncio.run(simplify_index_structure())
    asyncio.run(analyze_query_performance())
